{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0TjSUeLNFyxC",
        "orGk8mkCGfPx",
        "i8Dm8J4IH1Ll",
        "EP9VE1VOH_-I",
        "OIZmEqHFIcK8",
        "VMpoXW28LNrd",
        "OXMX8AG5LTvT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "kZPBCD2vE9Uf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka0Tu62-Etdg",
        "outputId": "b2989c10-1a53-4f8e-b6ed-1193ef290e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=253875ba62c9f489b75ef6793ae2bf6a70851cb67777616897aed2411158851a\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO6AAZNLEzSa",
        "outputId": "8daca384-f250-4e5a-fb38-31efad7d58d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lg_WRJ-E2AH",
        "outputId": "fd001303-d6a9-4b25-e163-2a18e65c373e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-29 11:09:40--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M   148MB/s    in 0.2s    \n",
            "\n",
            "2022-11-29 11:09:40 (148 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hd1qZFlE43F",
        "outputId": "5572804e-22f1-412b-d57c-859e239a19bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Nov 29 11:09 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Nov 22 00:14 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('answers_subsample.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3AiqKn6nFDr1",
        "outputId": "57303745-7b73-4616-835b-71d34056b4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aca2fd10-72dd-4d1b-afce-19168ad182db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aca2fd10-72dd-4d1b-afce-19168ad182db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aca2fd10-72dd-4d1b-afce-19168ad182db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aca2fd10-72dd-4d1b-afce-19168ad182db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLM2MqYoFHBm",
        "outputId": "d74a7921-bcc1-4b76-ec0b-01c639b6d074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предобученные эмбеддинги"
      ],
      "metadata": {
        "id": "jplWyIZ1FKaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McgzzFI2FJdX",
        "outputId": "40819c20-4af8-4a33-a6f2-307cd87e16c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-29 11:10:55--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  39.0MB/s    in 34s     \n",
            "\n",
            "2022-11-29 11:11:29 (36.6 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS-GsAdTFS56",
        "outputId": "c7f18c62-df2c-48bf-ceee-f26f3478ba5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Nov 29 11:09 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Nov 22 00:14 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lFQ-F0yWFbDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ],
      "metadata": {
        "id": "1Djo2JC2Fc3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpcUC-A5Fg2g",
        "outputId": "523e85cb-584b-4c7a-881a-0f751b042efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:03<00:00, 77111.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "NfHSfLVXFngK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "K0NnwBBtFpt2",
        "outputId": "ebc565ac-4578-4ce6-d7e4-e7dc3a003f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f771c1467d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qEU7jIVaFruB",
        "outputId": "c2385b74-1881-48f9-9cc2-570a53f54ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yPAuByVFvAC",
        "outputId": "5da0b355-eba8-4816-d4af-d1ec1acaf0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vjT0bLI9FwoL",
        "outputId": "77986764-adba-48d4-a60a-5aef35ce753a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Читаем файл с эмбеддингами\n",
        "\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "\n",
        "Поэтому прочитаем только те слова, которые мы знаем "
      ],
      "metadata": {
        "id": "0TjSUeLNFyxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "BC2ko9_XF50f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNNrB377F-jA",
        "outputId": "4c8ffb76-6613-4fb8-98b7-025a16a70291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:16<00:00, 26125.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evbeeLeIGan0",
        "outputId": "fa86356f-764a-4c8b-bff8-f33136a1066e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpkojeG2GcnK",
        "outputId": "44231b30-5d71-48f0-8bd1-93f3f6e69c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ],
      "metadata": {
        "id": "orGk8mkCGfPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.rand(128, 64, 1024)"
      ],
      "metadata": {
        "id": "AzGRXcoPGkW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ],
      "metadata": {
        "id": "Y2lKgipNGnr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8yHl0UpGpov",
        "outputId": "697f8a97-0a17-4dbe-b39b-0f7aaaa625b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.36 s ± 373 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче\n",
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "\n",
        "(seq_len, batch, input_size)\n",
        "Сделано это с целью оптимизации на более низком уровне.\n",
        "Мы оперируем такими объектами:\n",
        "\n",
        "(batch, seq_len, input_size)\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр batch_first=True во время инициализации слоя, либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.\n",
        "Подробнее про LSTM\n",
        "\n",
        "128 - размер батча\n",
        "64 - количество слов\n",
        "1024 - эмбеддинг слова"
      ],
      "metadata": {
        "id": "i8Dm8J4IH1Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ],
      "metadata": {
        "id": "zXIQJCU5G6hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yVTXF7PH5sD",
        "outputId": "54d2494c-21ff-43f9-d527-2e440b4e4263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ],
      "metadata": {
        "id": "Qfm70gdeH8TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-mH7xAPH-Lc",
        "outputId": "6655d885-20e6-4a66-e256-dbc0b83373be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyzU2apbH-s7",
        "outputId": "30913178-6ab2-4600-97aa-4c7d98236ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conv1d & MaxPool1d\n",
        "\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.\n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.\n",
        "- https://pytorch.org/docs/stable/nn.html#conv1d\n",
        "- https://pytorch.org/docs/stable/nn.html#maxpool1d\n",
        "Ожидается такая размерность:\n",
        "\n",
        "(batch, input_size, seq_len)\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "\n",
        "(batch, seq_len, input_size)\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ],
      "metadata": {
        "id": "EP9VE1VOH_-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnjyugIAIIph",
        "outputId": "c1a7442c-077c-44c3-c46d-658d0e487fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "128 - размер батча\n",
        "64 - количество слов\n",
        "1024 - эмбеддинг слова"
      ],
      "metadata": {
        "id": "DStbeuxgINYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ],
      "metadata": {
        "id": "UbNYgZHFIPYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = cnn(x) -> RuntimeError"
      ],
      "metadata": {
        "id": "mlP8T-B4ICj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-bxNpKaIVtr",
        "outputId": "90562c30-d738-44ef-ee65-c374360beea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H1BiW1mIXec",
        "outputId": "fc52fd63-673a-42d6-c5ab-c1eb3ed4653e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGTXdeTJIad0",
        "outputId": "1c53b79b-0047-4f8a-eeb2-50e62450b678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовим данные в DataLoader"
      ],
      "metadata": {
        "id": "OIZmEqHFIcK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "nsagiLRNIefa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'UNK' in word2index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xADKY9ZOLGRP",
        "outputId": "3806d64c-1c41-424d-c238-79a7126a58dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "J7YUY36xLHzL",
        "outputId": "911c842b-5ce2-4887-9966-4d712d382574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5130c2d2-ab31-42fe-9ace-dcf192e940c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5130c2d2-ab31-42fe-9ace-dcf192e940c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5130c2d2-ab31-42fe-9ace-dcf192e940c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5130c2d2-ab31-42fe-9ace-dcf192e940c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замапим категории в индексы"
      ],
      "metadata": {
        "id": "VMpoXW28LNrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}\n",
        "cat_mapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VwysvaMLK_k",
        "outputId": "f0d7a9a3-20b9-4539-eef3-b4fc21f9f743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ],
      "metadata": {
        "id": "aF_OUnmbLR8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Читалка данных\n",
        "###Что происходит ниже\n",
        "\n",
        "Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "###Загружаем данные:\n",
        " - Проходимся по датасету\n",
        " - Предобрабатываем каждый текст в датасете\n",
        " - Индексируем его\n",
        " - Паддим до нужной длины\n",
        "\n",
        "Когда нам нужно достать пример из датасета мы берем индексированный x и соответствующий этому индексу y, наш x также паддим (или ограничиваем длину) и переводим в torch.Tensor(x).long(). Для y этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами."
      ],
      "metadata": {
        "id": "OXMX8AG5LTvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ],
      "metadata": {
        "id": "KGqt3QYaLhGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "aSD7EIEHLbHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM8UOo5KLlH2",
        "outputId": "1d9e78d6-9819-4cd9-ebcf-c362707ffe7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading data:   0%|          | 0/214001 [00:00<?, ?it/s]\u001b[A\n",
            "Loading data:   1%|          | 2081/214001 [00:00<00:10, 19507.13it/s]\u001b[A\n",
            "Loading data:   2%|▏         | 5102/214001 [00:00<00:08, 25629.79it/s]\u001b[A\n",
            "Loading data:   5%|▍         | 9997/214001 [00:00<00:05, 36116.87it/s]\u001b[A\n",
            "Loading data:   7%|▋         | 14347/214001 [00:00<00:05, 39002.89it/s]\u001b[A\n",
            "Loading data:   9%|▉         | 19993/214001 [00:00<00:04, 45258.76it/s]\u001b[A\n",
            "Loading data:  12%|█▏        | 25076/214001 [00:00<00:04, 47143.34it/s]\u001b[A\n",
            "Loading data:  14%|█▍        | 29801/214001 [00:00<00:03, 46872.21it/s]\u001b[A\n",
            "Loading data:  17%|█▋        | 35471/214001 [00:00<00:03, 49977.99it/s]\u001b[A\n",
            "Loading data:  19%|█▉        | 41126/214001 [00:00<00:03, 52021.50it/s]\u001b[A\n",
            "Loading data:  22%|██▏       | 46537/214001 [00:01<00:03, 52120.64it/s]\u001b[A\n",
            "Loading data:  24%|██▍       | 52376/214001 [00:01<00:02, 54018.93it/s]\u001b[A\n",
            "Loading data:  27%|██▋       | 58352/214001 [00:01<00:02, 55751.13it/s]\u001b[A\n",
            "Loading data:  30%|███       | 64589/214001 [00:01<00:02, 57744.42it/s]\u001b[A\n",
            "Loading data:  33%|███▎      | 71404/214001 [00:01<00:02, 60874.02it/s]\u001b[A\n",
            "Loading data:  36%|███▌      | 77496/214001 [00:02<00:05, 23067.20it/s]\u001b[A\n",
            "Loading data:  39%|███▉      | 84435/214001 [00:02<00:04, 29550.83it/s]\u001b[A\n",
            "Loading data:  42%|████▏     | 90829/214001 [00:02<00:03, 35280.40it/s]\u001b[A\n",
            "Loading data:  45%|████▌     | 97077/214001 [00:02<00:02, 40508.23it/s]\u001b[A\n",
            "Loading data:  48%|████▊     | 103483/214001 [00:02<00:02, 45582.02it/s]\u001b[A\n",
            "Loading data:  52%|█████▏    | 110588/214001 [00:02<00:02, 51573.58it/s]\u001b[A\n",
            "Loading data:  55%|█████▍    | 116905/214001 [00:02<00:01, 54429.88it/s]\u001b[A\n",
            "Loading data:  58%|█████▊    | 123213/214001 [00:02<00:01, 55602.59it/s]\u001b[A\n",
            "Loading data:  61%|██████    | 130044/214001 [00:02<00:01, 59032.68it/s]\u001b[A\n",
            "Loading data:  64%|██████▎   | 136416/214001 [00:02<00:01, 58767.10it/s]\u001b[A\n",
            "Loading data:  67%|██████▋   | 143063/214001 [00:03<00:01, 60915.26it/s]\u001b[A\n",
            "Loading data:  70%|██████▉   | 149648/214001 [00:03<00:01, 62319.06it/s]\u001b[A\n",
            "Loading data:  73%|███████▎  | 156059/214001 [00:03<00:00, 61814.48it/s]\u001b[A\n",
            "Loading data:  76%|███████▌  | 162596/214001 [00:03<00:00, 62837.66it/s]\u001b[A\n",
            "Loading data:  79%|███████▉  | 169024/214001 [00:03<00:00, 63256.22it/s]\u001b[A\n",
            "Loading data:  82%|████████▏ | 175682/214001 [00:03<00:00, 64230.26it/s]\u001b[A\n",
            "Loading data:  85%|████████▌ | 182679/214001 [00:03<00:00, 65926.52it/s]\u001b[A\n",
            "Loading data:  89%|████████▊ | 189462/214001 [00:03<00:00, 66050.29it/s]\u001b[A\n",
            "Loading data:  92%|█████████▏| 196092/214001 [00:03<00:00, 65971.98it/s]\u001b[A\n",
            "Loading data:  95%|█████████▍| 202707/214001 [00:04<00:00, 61420.40it/s]\u001b[A\n",
            "Loading data: 100%|██████████| 214001/214001 [00:04<00:00, 46795.54it/s]\n",
            "\n",
            "Loading data:   0%|          | 0/23778 [00:00<?, ?it/s]\u001b[A\n",
            "Loading data:  14%|█▍        | 3397/23778 [00:00<00:00, 33963.96it/s]\u001b[A\n",
            "Loading data:  39%|███▉      | 9246/23778 [00:00<00:00, 48384.31it/s]\u001b[A\n",
            "Loading data:  67%|██████▋   | 15844/23778 [00:00<00:00, 56413.28it/s]\u001b[A\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 53783.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ],
      "metadata": {
        "id": "my_40WkzkhAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX7bqXcEkiCM",
        "outputId": "0a61130f-dfc7-476c-e1d1-077ea9c18fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  516,     4,  9976,  ...,     0,     0,     0],\n",
              "        [   24,  1281,  1655,  ...,     0,     0,     0],\n",
              "        [ 6342, 12102,   380,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [ 2695,   608,    80,  ...,     0,     0,     0],\n",
              "        [    4,  2062,  1031,  ...,     0,     0,     0],\n",
              "        [   19,    32,    28,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laDvBNbUmIQd",
        "outputId": "a167ec20-04b0-40d8-bd39-9fba03ed8426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 3, 1, 2, 1, 2, 3, 0, 2, 3, 1, 0, 2, 1, 4, 0, 1, 3, 2, 1, 3, 0, 4, 3,\n",
              "        4, 0, 4, 2, 2, 1, 0, 3, 1, 1, 2, 4, 3, 3, 4, 3, 1, 1, 1, 3, 3, 0, 1, 3,\n",
              "        4, 4, 2, 4, 1, 4, 3, 0, 1, 3, 4, 4, 3, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучаем Нейронку"
      ],
      "metadata": {
        "id": "E3e8I3N6kk5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "    def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "      super().__init__()\n",
        "\n",
        "      self.n = n\n",
        "\n",
        "      self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "      # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "      self.LSTM = torch.nn.LSTM(matrix_w.shape[1], 256, bidirectional=True) \n",
        "\n",
        "      self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "      self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "      self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "      self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "      # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "      self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,)) \n",
        "      self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "      self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "      # сверху накидываем два полносвязных слоя для классификации\n",
        "      self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n",
        "      self.relu = torch.nn.ReLU()\n",
        "      self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "      #примените эмбеддинги\n",
        "      x_emb = self.emb_layer(x)\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      x_q = self.q_proj(x) # применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) /  math.sqrt(x_q.size(-1))\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      # тут тоже что то с чем то нужно перемножить :)\n",
        "      attention_vectors = torch.bmm(att_dist, x_v)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      \n",
        "      x =  self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ],
      "metadata": {
        "id": "sgFEviw-Lmr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_with_att(vectors, n_classes)"
      ],
      "metadata": {
        "id": "d6h_DAWlPn9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4OBDx9uPpdB",
        "outputId": "fb8d037f-0cea-4737-9488-80dab6899cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ],
      "metadata": {
        "id": "che-LO3LQNwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnWOIlZilg_0",
        "outputId": "2926f977-d2b5-4e87-9502-a3fda2584772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "SKj-TgZ4ll52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "_GPgFsVJlx6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9i9JsKKlzrX",
        "outputId": "5a225a7b-efb3-4760-c96b-86d192c730a3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1:  25%|██▌       | 54080/214001 [09:21<27:54, 95.51it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54080/214001 [09:21<27:54, 95.51it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54144/214001 [09:21<27:45, 95.99it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54144/214001 [09:22<27:45, 95.99it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54208/214001 [09:22<27:43, 96.05it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54208/214001 [09:23<27:43, 96.05it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54272/214001 [09:23<27:26, 97.01it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54272/214001 [09:23<27:26, 97.01it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54336/214001 [09:23<27:41, 96.11it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54336/214001 [09:24<27:41, 96.11it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54400/214001 [09:24<27:38, 96.24it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54400/214001 [09:25<27:38, 96.24it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54464/214001 [09:25<27:24, 97.01it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54464/214001 [09:25<27:24, 97.01it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54528/214001 [09:25<27:07, 97.98it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54528/214001 [09:26<27:07, 97.98it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54592/214001 [09:26<27:05, 98.06it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54592/214001 [09:26<27:05, 98.06it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54656/214001 [09:26<27:09, 97.77it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54656/214001 [09:27<27:09, 97.77it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54720/214001 [09:27<27:16, 97.33it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54720/214001 [09:28<27:16, 97.33it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54784/214001 [09:28<27:29, 96.50it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54784/214001 [09:28<27:29, 96.50it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54848/214001 [09:28<27:17, 97.22it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54848/214001 [09:29<27:17, 97.22it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54912/214001 [09:29<27:14, 97.32it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54912/214001 [09:30<27:14, 97.32it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54976/214001 [09:30<27:14, 97.32it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54976/214001 [09:30<27:14, 97.32it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55040/214001 [09:30<27:05, 97.79it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55040/214001 [09:31<27:05, 97.79it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55104/214001 [09:31<27:04, 97.81it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55104/214001 [09:32<27:04, 97.81it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55168/214001 [09:32<27:04, 97.78it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55168/214001 [09:32<27:04, 97.78it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55232/214001 [09:32<27:00, 98.00it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55232/214001 [09:33<27:00, 98.00it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55296/214001 [09:33<27:07, 97.49it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55296/214001 [09:34<27:07, 97.49it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55360/214001 [09:34<27:08, 97.44it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55360/214001 [09:34<27:08, 97.44it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55424/214001 [09:34<27:05, 97.58it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55424/214001 [09:35<27:05, 97.58it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55488/214001 [09:35<27:44, 95.25it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55488/214001 [09:36<27:44, 95.25it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55552/214001 [09:36<27:45, 95.13it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55552/214001 [09:36<27:45, 95.13it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55616/214001 [09:36<27:35, 95.69it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55616/214001 [09:37<27:35, 95.69it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55680/214001 [09:37<27:30, 95.90it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55680/214001 [09:38<27:30, 95.90it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55744/214001 [09:38<27:25, 96.15it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55744/214001 [09:38<27:25, 96.15it/s, train_loss=0.6]  \u001b[A\n",
            "Epoch 1:  26%|██▌       | 55808/214001 [09:38<27:31, 95.80it/s, train_loss=0.6]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55808/214001 [09:39<27:31, 95.80it/s, train_loss=0.6]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55872/214001 [09:39<27:40, 95.21it/s, train_loss=0.6]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55872/214001 [09:40<27:40, 95.21it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55936/214001 [09:40<27:27, 95.93it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55936/214001 [09:40<27:27, 95.93it/s, train_loss=0.6]  \u001b[A\n",
            "Epoch 1:  26%|██▌       | 56000/214001 [09:40<27:35, 95.43it/s, train_loss=0.6]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56000/214001 [09:41<27:35, 95.43it/s, train_loss=0.6]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56064/214001 [09:41<27:30, 95.68it/s, train_loss=0.6]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56064/214001 [09:42<27:30, 95.68it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56128/214001 [09:42<27:15, 96.55it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56128/214001 [09:42<27:15, 96.55it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56192/214001 [09:42<27:37, 95.19it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56192/214001 [09:43<27:37, 95.19it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56256/214001 [09:43<27:31, 95.53it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56256/214001 [09:44<27:31, 95.53it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56320/214001 [09:44<27:49, 94.47it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56320/214001 [09:44<27:49, 94.47it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56384/214001 [09:44<27:38, 95.01it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56384/214001 [09:45<27:38, 95.01it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56448/214001 [09:45<27:40, 94.88it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56448/214001 [09:46<27:40, 94.88it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56512/214001 [09:46<27:27, 95.61it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56512/214001 [09:46<27:27, 95.61it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56576/214001 [09:46<27:41, 94.74it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56576/214001 [09:47<27:41, 94.74it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56640/214001 [09:47<27:25, 95.60it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56640/214001 [09:48<27:25, 95.60it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56704/214001 [09:48<27:04, 96.85it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56704/214001 [09:48<27:04, 96.85it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56768/214001 [09:48<26:59, 97.08it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56768/214001 [09:49<26:59, 97.08it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56832/214001 [09:49<27:04, 96.77it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56832/214001 [09:50<27:04, 96.77it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56896/214001 [09:50<27:28, 95.29it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56896/214001 [09:50<27:28, 95.29it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56960/214001 [09:51<28:08, 93.02it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56960/214001 [09:51<28:08, 93.02it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57024/214001 [09:51<27:46, 94.20it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57024/214001 [09:52<27:46, 94.20it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57088/214001 [09:52<27:39, 94.58it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57088/214001 [09:52<27:39, 94.58it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57152/214001 [09:53<27:23, 95.41it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57152/214001 [09:53<27:23, 95.41it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57216/214001 [09:53<27:38, 94.55it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57216/214001 [09:54<27:38, 94.55it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57280/214001 [09:54<27:50, 93.81it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57280/214001 [09:55<27:50, 93.81it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57344/214001 [09:55<27:48, 93.91it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57344/214001 [09:55<27:48, 93.91it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57408/214001 [09:55<27:48, 93.86it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57408/214001 [09:56<27:48, 93.86it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57472/214001 [09:56<27:53, 93.56it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57472/214001 [09:57<27:53, 93.56it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57536/214001 [09:57<27:51, 93.58it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57536/214001 [09:57<27:51, 93.58it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57600/214001 [09:57<27:36, 94.39it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57600/214001 [09:58<27:36, 94.39it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57664/214001 [09:58<27:20, 95.31it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57664/214001 [09:59<27:20, 95.31it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57728/214001 [09:59<27:46, 93.79it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57728/214001 [09:59<27:46, 93.79it/s, train_loss=0.594]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57792/214001 [09:59<27:45, 93.78it/s, train_loss=0.594]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57792/214001 [10:00<27:45, 93.78it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57856/214001 [10:00<27:36, 94.29it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57856/214001 [10:01<27:36, 94.29it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57920/214001 [10:01<27:23, 94.98it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57920/214001 [10:01<27:23, 94.98it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57984/214001 [10:01<26:48, 97.00it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57984/214001 [10:02<26:48, 97.00it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58048/214001 [10:02<26:31, 98.00it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58048/214001 [10:03<26:31, 98.00it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58112/214001 [10:03<26:27, 98.22it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58112/214001 [10:03<26:27, 98.22it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58176/214001 [10:03<26:29, 98.01it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58176/214001 [10:04<26:29, 98.01it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58240/214001 [10:04<26:46, 96.98it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58240/214001 [10:05<26:46, 96.98it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58304/214001 [10:05<26:43, 97.08it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58304/214001 [10:05<26:43, 97.08it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58368/214001 [10:05<26:40, 97.24it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58368/214001 [10:06<26:40, 97.24it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58432/214001 [10:06<26:50, 96.61it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58432/214001 [10:07<26:50, 96.61it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58496/214001 [10:07<27:20, 94.77it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58496/214001 [10:07<27:20, 94.77it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58560/214001 [10:07<27:25, 94.46it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58560/214001 [10:08<27:25, 94.46it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58624/214001 [10:08<27:17, 94.88it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58624/214001 [10:09<27:17, 94.88it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58688/214001 [10:09<26:58, 95.95it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58688/214001 [10:09<26:58, 95.95it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58752/214001 [10:09<26:54, 96.14it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58752/214001 [10:10<26:54, 96.14it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58816/214001 [10:10<26:45, 96.69it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58816/214001 [10:11<26:45, 96.69it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58880/214001 [10:11<27:05, 95.45it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58880/214001 [10:11<27:05, 95.45it/s, train_loss=0.59] \u001b[A\n",
            "Epoch 1:  28%|██▊       | 58944/214001 [10:11<26:59, 95.72it/s, train_loss=0.59]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58944/214001 [10:12<26:59, 95.72it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59008/214001 [10:12<26:48, 96.37it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59008/214001 [10:13<26:48, 96.37it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59072/214001 [10:13<26:43, 96.60it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59072/214001 [10:13<26:43, 96.60it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59136/214001 [10:13<26:46, 96.37it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59136/214001 [10:14<26:46, 96.37it/s, train_loss=0.59] \u001b[A\n",
            "Epoch 1:  28%|██▊       | 59200/214001 [10:14<26:48, 96.23it/s, train_loss=0.59]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59200/214001 [10:15<26:48, 96.23it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59264/214001 [10:15<27:08, 95.00it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59264/214001 [10:15<27:08, 95.00it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59328/214001 [10:15<27:03, 95.25it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59328/214001 [10:16<27:03, 95.25it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59392/214001 [10:16<26:56, 95.64it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59392/214001 [10:17<26:56, 95.64it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59456/214001 [10:17<26:54, 95.74it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59456/214001 [10:17<26:54, 95.74it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59520/214001 [10:17<27:05, 95.04it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59520/214001 [10:18<27:05, 95.04it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59584/214001 [10:18<27:25, 93.83it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59584/214001 [10:19<27:25, 93.83it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59648/214001 [10:19<27:46, 92.63it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59648/214001 [10:19<27:46, 92.63it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59712/214001 [10:19<27:38, 93.04it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59712/214001 [10:20<27:38, 93.04it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59776/214001 [10:20<28:05, 91.50it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59776/214001 [10:21<28:05, 91.50it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59840/214001 [10:21<28:36, 89.79it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59840/214001 [10:22<28:36, 89.79it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59904/214001 [10:22<28:40, 89.54it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59904/214001 [10:22<28:40, 89.54it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59968/214001 [10:22<28:40, 89.55it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59968/214001 [10:23<28:40, 89.55it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60032/214001 [10:23<28:18, 90.64it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60032/214001 [10:24<28:18, 90.64it/s, train_loss=0.587]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60096/214001 [10:24<27:44, 92.47it/s, train_loss=0.587]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60096/214001 [10:24<27:44, 92.47it/s, train_loss=0.587]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60160/214001 [10:24<28:01, 91.49it/s, train_loss=0.587]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60160/214001 [10:25<28:01, 91.49it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60224/214001 [10:25<27:44, 92.37it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60224/214001 [10:26<27:44, 92.37it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60288/214001 [10:26<27:21, 93.62it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60288/214001 [10:26<27:21, 93.62it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60352/214001 [10:26<27:04, 94.59it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60352/214001 [10:27<27:04, 94.59it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60416/214001 [10:27<27:01, 94.71it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60416/214001 [10:28<27:01, 94.71it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60480/214001 [10:28<27:05, 94.47it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60480/214001 [10:28<27:05, 94.47it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60544/214001 [10:28<26:58, 94.79it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60544/214001 [10:29<26:58, 94.79it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60608/214001 [10:29<26:41, 95.77it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60608/214001 [10:30<26:41, 95.77it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60672/214001 [10:30<26:47, 95.36it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60672/214001 [10:30<26:47, 95.36it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60736/214001 [10:30<26:41, 95.70it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60736/214001 [10:31<26:41, 95.70it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60800/214001 [10:31<26:36, 95.97it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60800/214001 [10:32<26:36, 95.97it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60864/214001 [10:32<26:29, 96.35it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60864/214001 [10:32<26:29, 96.35it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60928/214001 [10:32<26:32, 96.12it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60928/214001 [10:33<26:32, 96.12it/s, train_loss=0.585]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 60992/214001 [10:33<27:11, 93.79it/s, train_loss=0.585]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 60992/214001 [10:34<27:11, 93.79it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61056/214001 [10:34<27:12, 93.68it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61056/214001 [10:34<27:12, 93.68it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61120/214001 [10:34<26:55, 94.66it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61120/214001 [10:35<26:55, 94.66it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61184/214001 [10:35<27:00, 94.31it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61184/214001 [10:36<27:00, 94.31it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61248/214001 [10:36<27:19, 93.18it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61248/214001 [10:36<27:19, 93.18it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61312/214001 [10:36<26:59, 94.26it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61312/214001 [10:37<26:59, 94.26it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61376/214001 [10:37<26:45, 95.07it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61376/214001 [10:38<26:45, 95.07it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61440/214001 [10:38<26:47, 94.89it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61440/214001 [10:38<26:47, 94.89it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61504/214001 [10:38<26:50, 94.71it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61504/214001 [10:39<26:50, 94.71it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61568/214001 [10:39<26:38, 95.34it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61568/214001 [10:40<26:38, 95.34it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61632/214001 [10:40<26:20, 96.39it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61632/214001 [10:40<26:20, 96.39it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61696/214001 [10:40<26:33, 95.58it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61696/214001 [10:41<26:33, 95.58it/s, train_loss=0.58] \u001b[A\n",
            "Epoch 1:  29%|██▉       | 61760/214001 [10:41<26:45, 94.81it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61760/214001 [10:42<26:45, 94.81it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61824/214001 [10:42<26:55, 94.21it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61824/214001 [10:43<26:55, 94.21it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61888/214001 [10:43<26:49, 94.53it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61888/214001 [10:43<26:49, 94.53it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61952/214001 [10:43<26:53, 94.26it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61952/214001 [10:44<26:53, 94.26it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62016/214001 [10:44<26:58, 93.93it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62016/214001 [10:45<26:58, 93.93it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62080/214001 [10:45<26:47, 94.49it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62080/214001 [10:45<26:47, 94.49it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62144/214001 [10:45<26:36, 95.11it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62144/214001 [10:46<26:36, 95.11it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62208/214001 [10:46<26:47, 94.44it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62208/214001 [10:47<26:47, 94.44it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62272/214001 [10:47<26:26, 95.64it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62272/214001 [10:47<26:26, 95.64it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62336/214001 [10:47<26:43, 94.60it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62336/214001 [10:48<26:43, 94.60it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62400/214001 [10:48<26:26, 95.53it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62400/214001 [10:49<26:26, 95.53it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62464/214001 [10:49<26:13, 96.32it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62464/214001 [10:49<26:13, 96.32it/s, train_loss=0.58] \u001b[A\n",
            "Epoch 1:  29%|██▉       | 62528/214001 [10:49<26:20, 95.83it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62528/214001 [10:50<26:20, 95.83it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62592/214001 [10:50<26:12, 96.27it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62592/214001 [10:51<26:12, 96.27it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62656/214001 [10:51<25:52, 97.51it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62656/214001 [10:51<25:52, 97.51it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62720/214001 [10:51<26:11, 96.24it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62720/214001 [10:52<26:11, 96.24it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62784/214001 [10:52<26:31, 95.04it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62784/214001 [10:53<26:31, 95.04it/s, train_loss=0.578]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62848/214001 [10:53<26:21, 95.58it/s, train_loss=0.578]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62848/214001 [10:53<26:21, 95.58it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62912/214001 [10:53<26:08, 96.35it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62912/214001 [10:54<26:08, 96.35it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62976/214001 [10:54<26:04, 96.55it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62976/214001 [10:55<26:04, 96.55it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63040/214001 [10:55<25:44, 97.76it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63040/214001 [10:55<25:44, 97.76it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63104/214001 [10:55<25:42, 97.85it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63104/214001 [10:56<25:42, 97.85it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63168/214001 [10:56<25:29, 98.59it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63168/214001 [10:56<25:29, 98.59it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63232/214001 [10:56<25:38, 98.01it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63232/214001 [10:57<25:38, 98.01it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63296/214001 [10:57<25:57, 96.74it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63296/214001 [10:58<25:57, 96.74it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63360/214001 [10:58<25:43, 97.57it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63360/214001 [10:58<25:43, 97.57it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63424/214001 [10:58<25:29, 98.43it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63424/214001 [10:59<25:29, 98.43it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63488/214001 [10:59<25:28, 98.44it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63488/214001 [11:00<25:28, 98.44it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63552/214001 [11:00<25:32, 98.16it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63552/214001 [11:00<25:32, 98.16it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63616/214001 [11:00<25:35, 97.95it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63616/214001 [11:01<25:35, 97.95it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63680/214001 [11:01<25:35, 97.91it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63680/214001 [11:02<25:35, 97.91it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63744/214001 [11:02<25:39, 97.60it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63744/214001 [11:02<25:39, 97.60it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63808/214001 [11:02<25:44, 97.23it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63808/214001 [11:03<25:44, 97.23it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63872/214001 [11:03<25:42, 97.30it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63872/214001 [11:04<25:42, 97.30it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63936/214001 [11:04<25:45, 97.09it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63936/214001 [11:04<25:45, 97.09it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64000/214001 [11:04<25:43, 97.19it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64000/214001 [11:05<25:43, 97.19it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64064/214001 [11:05<25:40, 97.31it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64064/214001 [11:06<25:40, 97.31it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64128/214001 [11:06<25:38, 97.42it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64128/214001 [11:06<25:38, 97.42it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64192/214001 [11:06<25:30, 97.88it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64192/214001 [11:07<25:30, 97.88it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64256/214001 [11:07<25:19, 98.55it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64256/214001 [11:08<25:19, 98.55it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64320/214001 [11:08<25:14, 98.83it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64320/214001 [11:08<25:14, 98.83it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64384/214001 [11:08<25:17, 98.60it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64384/214001 [11:09<25:17, 98.60it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64448/214001 [11:09<25:12, 98.91it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64448/214001 [11:10<25:12, 98.91it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64512/214001 [11:10<25:16, 98.56it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64512/214001 [11:10<25:16, 98.56it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64576/214001 [11:10<25:22, 98.13it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64576/214001 [11:11<25:22, 98.13it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64640/214001 [11:11<25:33, 97.41it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  30%|███       | 64640/214001 [11:12<25:33, 97.41it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 64704/214001 [11:12<25:31, 97.51it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 64704/214001 [11:12<25:31, 97.51it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 64768/214001 [11:12<25:29, 97.60it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 64768/214001 [11:13<25:29, 97.60it/s, train_loss=0.57] \u001b[A\n",
            "Epoch 1:  30%|███       | 64832/214001 [11:13<25:46, 96.46it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  30%|███       | 64832/214001 [11:13<25:46, 96.46it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  30%|███       | 64896/214001 [11:14<25:26, 97.69it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  30%|███       | 64896/214001 [11:14<25:26, 97.69it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 64960/214001 [11:14<25:19, 98.10it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 64960/214001 [11:15<25:19, 98.10it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65024/214001 [11:15<25:30, 97.32it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65024/214001 [11:15<25:30, 97.32it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65088/214001 [11:15<25:19, 97.97it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65088/214001 [11:16<25:19, 97.97it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65152/214001 [11:16<25:07, 98.74it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65152/214001 [11:17<25:07, 98.74it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65216/214001 [11:17<25:05, 98.81it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  30%|███       | 65216/214001 [11:17<25:05, 98.81it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65280/214001 [11:17<25:05, 98.77it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65280/214001 [11:18<25:05, 98.77it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65344/214001 [11:18<25:18, 97.93it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65344/214001 [11:19<25:18, 97.93it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65408/214001 [11:19<25:26, 97.34it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65408/214001 [11:19<25:26, 97.34it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65472/214001 [11:19<25:31, 96.98it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65472/214001 [11:20<25:31, 96.98it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65536/214001 [11:20<25:35, 96.69it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65536/214001 [11:21<25:35, 96.69it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65600/214001 [11:21<25:28, 97.08it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65600/214001 [11:21<25:28, 97.08it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65664/214001 [11:21<25:27, 97.12it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65664/214001 [11:22<25:27, 97.12it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65728/214001 [11:22<28:02, 88.15it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65728/214001 [11:23<28:02, 88.15it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65792/214001 [11:23<32:27, 76.09it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65792/214001 [11:24<32:27, 76.09it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65856/214001 [11:24<35:41, 69.19it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65856/214001 [11:26<35:41, 69.19it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65920/214001 [11:26<38:01, 64.89it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65920/214001 [11:27<38:01, 64.89it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65984/214001 [11:27<42:56, 57.46it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 65984/214001 [11:28<42:56, 57.46it/s, train_loss=0.57] \u001b[A\n",
            "Epoch 1:  31%|███       | 66048/214001 [11:28<40:47, 60.44it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66048/214001 [11:29<40:47, 60.44it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66112/214001 [11:29<36:17, 67.91it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66112/214001 [11:29<36:17, 67.91it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 66176/214001 [11:29<33:07, 74.39it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 66176/214001 [11:30<33:07, 74.39it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 66240/214001 [11:30<30:41, 80.25it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 66240/214001 [11:31<30:41, 80.25it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 66304/214001 [11:31<29:01, 84.79it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  31%|███       | 66304/214001 [11:31<29:01, 84.79it/s, train_loss=0.57] \u001b[A\n",
            "Epoch 1:  31%|███       | 66368/214001 [11:31<27:56, 88.04it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66368/214001 [11:32<27:56, 88.04it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66432/214001 [11:32<26:59, 91.12it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66432/214001 [11:33<26:59, 91.12it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66496/214001 [11:33<26:24, 93.11it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66496/214001 [11:33<26:24, 93.11it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66560/214001 [11:33<26:10, 93.87it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66560/214001 [11:34<26:10, 93.87it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66624/214001 [11:34<25:43, 95.49it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66624/214001 [11:35<25:43, 95.49it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66688/214001 [11:35<25:35, 95.95it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66688/214001 [11:35<25:35, 95.95it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66752/214001 [11:35<25:42, 95.45it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66752/214001 [11:36<25:42, 95.45it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66816/214001 [11:36<25:41, 95.45it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███       | 66816/214001 [11:37<25:41, 95.45it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66880/214001 [11:37<25:33, 95.93it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66880/214001 [11:37<25:33, 95.93it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66944/214001 [11:37<25:25, 96.38it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66944/214001 [11:38<25:25, 96.38it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67008/214001 [11:38<25:25, 96.35it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67008/214001 [11:39<25:25, 96.35it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67072/214001 [11:39<25:39, 95.47it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67072/214001 [11:39<25:39, 95.47it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67136/214001 [11:39<25:29, 96.03it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67136/214001 [11:40<25:29, 96.03it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67200/214001 [11:40<25:31, 95.83it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67200/214001 [11:41<25:31, 95.83it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67264/214001 [11:41<25:31, 95.78it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67264/214001 [11:41<25:31, 95.78it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67328/214001 [11:41<25:33, 95.63it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67328/214001 [11:42<25:33, 95.63it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67392/214001 [11:42<25:33, 95.57it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67392/214001 [11:43<25:33, 95.57it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67456/214001 [11:43<25:25, 96.04it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67456/214001 [11:43<25:25, 96.04it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67520/214001 [11:43<25:20, 96.37it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67520/214001 [11:44<25:20, 96.37it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67584/214001 [11:44<25:45, 94.74it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67584/214001 [11:45<25:45, 94.74it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67648/214001 [11:45<25:45, 94.68it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67648/214001 [11:45<25:45, 94.68it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67712/214001 [11:45<26:10, 93.16it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67712/214001 [11:46<26:10, 93.16it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67776/214001 [11:46<26:26, 92.17it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67776/214001 [11:47<26:26, 92.17it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67840/214001 [11:47<26:10, 93.06it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67840/214001 [11:47<26:10, 93.06it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67904/214001 [11:47<26:00, 93.60it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67904/214001 [11:48<26:00, 93.60it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67968/214001 [11:48<25:48, 94.29it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67968/214001 [11:49<25:48, 94.29it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68032/214001 [11:49<25:33, 95.20it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68032/214001 [11:49<25:33, 95.20it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68096/214001 [11:49<25:39, 94.77it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68096/214001 [11:50<25:39, 94.77it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68160/214001 [11:50<25:34, 95.06it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68160/214001 [11:51<25:34, 95.06it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68224/214001 [11:51<25:27, 95.44it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68224/214001 [11:51<25:27, 95.44it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68288/214001 [11:51<25:19, 95.92it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68288/214001 [11:52<25:19, 95.92it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68352/214001 [11:52<25:17, 95.99it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68352/214001 [11:53<25:17, 95.99it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68416/214001 [11:53<25:12, 96.23it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68416/214001 [11:53<25:12, 96.23it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68480/214001 [11:53<25:24, 95.43it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68480/214001 [11:54<25:24, 95.43it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68544/214001 [11:54<25:21, 95.60it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68544/214001 [11:55<25:21, 95.60it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68608/214001 [11:55<25:21, 95.58it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68608/214001 [11:55<25:21, 95.58it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68672/214001 [11:55<25:18, 95.70it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68672/214001 [11:56<25:18, 95.70it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68736/214001 [11:56<25:18, 95.64it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68736/214001 [11:57<25:18, 95.64it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68800/214001 [11:57<25:11, 96.03it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68800/214001 [11:57<25:11, 96.03it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68864/214001 [11:57<25:12, 95.99it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68864/214001 [11:58<25:12, 95.99it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68928/214001 [11:58<25:02, 96.55it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68928/214001 [11:59<25:02, 96.55it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68992/214001 [11:59<24:59, 96.72it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68992/214001 [11:59<24:59, 96.72it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69056/214001 [11:59<25:07, 96.17it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69056/214001 [12:00<25:07, 96.17it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69120/214001 [12:00<25:29, 94.70it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69120/214001 [12:01<25:29, 94.70it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69184/214001 [12:01<25:22, 95.11it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69184/214001 [12:01<25:22, 95.11it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69248/214001 [12:01<25:23, 94.99it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69248/214001 [12:02<25:23, 94.99it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69312/214001 [12:02<25:22, 95.06it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69312/214001 [12:03<25:22, 95.06it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69376/214001 [12:03<25:17, 95.31it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69376/214001 [12:03<25:17, 95.31it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69440/214001 [12:03<25:26, 94.73it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69440/214001 [12:04<25:26, 94.73it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69504/214001 [12:04<25:22, 94.88it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69504/214001 [12:05<25:22, 94.88it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69568/214001 [12:05<25:16, 95.23it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69568/214001 [12:05<25:16, 95.23it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69632/214001 [12:05<25:36, 93.95it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69632/214001 [12:06<25:36, 93.95it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69696/214001 [12:06<26:19, 91.35it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69696/214001 [12:07<26:19, 91.35it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69760/214001 [12:07<26:45, 89.86it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69760/214001 [12:08<26:45, 89.86it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69824/214001 [12:08<26:27, 90.80it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69824/214001 [12:08<26:27, 90.80it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69888/214001 [12:08<26:07, 91.95it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69888/214001 [12:09<26:07, 91.95it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69952/214001 [12:09<25:59, 92.37it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69952/214001 [12:10<25:59, 92.37it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70016/214001 [12:10<25:43, 93.30it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70016/214001 [12:10<25:43, 93.30it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70080/214001 [12:10<25:41, 93.37it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70080/214001 [12:11<25:41, 93.37it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70144/214001 [12:11<25:30, 93.96it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70144/214001 [12:12<25:30, 93.96it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70208/214001 [12:12<25:58, 92.23it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70208/214001 [12:12<25:58, 92.23it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70272/214001 [12:12<25:54, 92.48it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70272/214001 [12:13<25:54, 92.48it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70336/214001 [12:13<25:39, 93.30it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70336/214001 [12:14<25:39, 93.30it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70400/214001 [12:14<25:47, 92.81it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70400/214001 [12:15<25:47, 92.81it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70464/214001 [12:15<26:19, 90.89it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70464/214001 [12:15<26:19, 90.89it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 70528/214001 [12:15<26:07, 91.55it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70528/214001 [12:16<26:07, 91.55it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70592/214001 [12:16<25:50, 92.49it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70592/214001 [12:17<25:50, 92.49it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70656/214001 [12:17<25:20, 94.29it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70656/214001 [12:17<25:20, 94.29it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 70720/214001 [12:17<25:33, 93.44it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70720/214001 [12:18<25:33, 93.44it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70784/214001 [12:18<26:03, 91.61it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70784/214001 [12:19<26:03, 91.61it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70848/214001 [12:19<25:42, 92.81it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70848/214001 [12:19<25:42, 92.81it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70912/214001 [12:19<25:23, 93.89it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70912/214001 [12:20<25:23, 93.89it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70976/214001 [12:20<25:26, 93.69it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70976/214001 [12:21<25:26, 93.69it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71040/214001 [12:21<25:19, 94.10it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71040/214001 [12:21<25:19, 94.10it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71104/214001 [12:21<25:25, 93.70it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71104/214001 [12:22<25:25, 93.70it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71168/214001 [12:22<25:34, 93.11it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71168/214001 [12:23<25:34, 93.11it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 71232/214001 [12:23<25:49, 92.16it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71232/214001 [12:23<25:49, 92.16it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71296/214001 [12:23<25:36, 92.89it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71296/214001 [12:24<25:36, 92.89it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71360/214001 [12:24<25:41, 92.55it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71360/214001 [12:25<25:41, 92.55it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71424/214001 [12:25<25:17, 93.94it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71424/214001 [12:25<25:17, 93.94it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71488/214001 [12:26<25:29, 93.18it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71488/214001 [12:26<25:29, 93.18it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71552/214001 [12:26<25:32, 92.96it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71552/214001 [12:27<25:32, 92.96it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71616/214001 [12:27<25:17, 93.83it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71616/214001 [12:28<25:17, 93.83it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 71680/214001 [12:28<25:07, 94.39it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71680/214001 [12:28<25:07, 94.39it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71744/214001 [12:28<25:08, 94.32it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71744/214001 [12:29<25:08, 94.32it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71808/214001 [12:29<25:08, 94.29it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71808/214001 [12:30<25:08, 94.29it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71872/214001 [12:30<25:15, 93.79it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71872/214001 [12:30<25:15, 93.79it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71936/214001 [12:30<25:08, 94.18it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71936/214001 [12:31<25:08, 94.18it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72000/214001 [12:31<24:54, 95.03it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72000/214001 [12:32<24:54, 95.03it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72064/214001 [12:32<24:39, 95.93it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72064/214001 [12:33<24:39, 95.93it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72128/214001 [12:33<27:55, 84.69it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72128/214001 [12:34<27:55, 84.69it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72192/214001 [12:34<30:25, 77.69it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72192/214001 [12:34<30:25, 77.69it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72256/214001 [12:34<32:10, 73.42it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72256/214001 [12:36<32:10, 73.42it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72320/214001 [12:36<35:13, 67.03it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72320/214001 [12:37<35:13, 67.03it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72384/214001 [12:37<35:20, 66.77it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72384/214001 [12:38<35:20, 66.77it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72448/214001 [12:38<37:23, 63.10it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72448/214001 [12:39<37:23, 63.10it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72512/214001 [12:39<37:19, 63.18it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72512/214001 [12:40<37:19, 63.18it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72576/214001 [12:40<43:09, 54.62it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72576/214001 [12:41<43:09, 54.62it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72640/214001 [12:41<37:22, 63.02it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72640/214001 [12:42<37:22, 63.02it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72704/214001 [12:42<33:41, 69.90it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72704/214001 [12:42<33:41, 69.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72768/214001 [12:42<31:14, 75.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72768/214001 [12:43<31:14, 75.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72832/214001 [12:43<29:09, 80.67it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72832/214001 [12:44<29:09, 80.67it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72896/214001 [12:44<27:36, 85.20it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72896/214001 [12:44<27:36, 85.20it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72960/214001 [12:44<26:45, 87.86it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72960/214001 [12:45<26:45, 87.86it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73024/214001 [12:45<26:23, 89.04it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73024/214001 [12:46<26:23, 89.04it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73088/214001 [12:46<26:13, 89.56it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73088/214001 [12:46<26:13, 89.56it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73152/214001 [12:46<25:46, 91.07it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73152/214001 [12:47<25:46, 91.07it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73216/214001 [12:47<25:22, 92.49it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73216/214001 [12:48<25:22, 92.49it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73280/214001 [12:48<24:56, 94.05it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73280/214001 [12:48<24:56, 94.05it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73344/214001 [12:48<24:34, 95.38it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73344/214001 [12:49<24:34, 95.38it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73408/214001 [12:49<24:19, 96.34it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73408/214001 [12:50<24:19, 96.34it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73472/214001 [12:50<24:08, 97.04it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73472/214001 [12:50<24:08, 97.04it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73536/214001 [12:50<24:17, 96.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73536/214001 [12:51<24:17, 96.36it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73600/214001 [12:51<24:08, 96.92it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73600/214001 [12:52<24:08, 96.92it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73664/214001 [12:52<23:57, 97.60it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73664/214001 [12:52<23:57, 97.60it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73728/214001 [12:52<24:07, 96.88it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73728/214001 [12:53<24:07, 96.88it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73792/214001 [12:53<24:05, 97.00it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73792/214001 [12:54<24:05, 97.00it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73856/214001 [12:54<23:55, 97.64it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73856/214001 [12:54<23:55, 97.64it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73920/214001 [12:54<23:48, 98.04it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73920/214001 [12:55<23:48, 98.04it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73984/214001 [12:55<23:48, 97.99it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73984/214001 [12:56<23:48, 97.99it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74048/214001 [12:56<23:49, 97.93it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74048/214001 [12:56<23:49, 97.93it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74112/214001 [12:56<23:58, 97.23it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74112/214001 [12:57<23:58, 97.23it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74176/214001 [12:57<24:09, 96.47it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74176/214001 [12:58<24:09, 96.47it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74240/214001 [12:58<24:14, 96.08it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74240/214001 [12:58<24:14, 96.08it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74304/214001 [12:58<24:00, 96.96it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74304/214001 [12:59<24:00, 96.96it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74368/214001 [12:59<23:58, 97.08it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74368/214001 [13:00<23:58, 97.08it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74432/214001 [13:00<23:58, 97.01it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74432/214001 [13:00<23:58, 97.01it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74496/214001 [13:00<23:54, 97.26it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74496/214001 [13:01<23:54, 97.26it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74560/214001 [13:01<24:06, 96.40it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74560/214001 [13:02<24:06, 96.40it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74624/214001 [13:02<23:55, 97.11it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74624/214001 [13:02<23:55, 97.11it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74688/214001 [13:02<23:55, 97.03it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74688/214001 [13:03<23:55, 97.03it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74752/214001 [13:03<23:53, 97.15it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74752/214001 [13:03<23:53, 97.15it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74816/214001 [13:03<23:42, 97.84it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74816/214001 [13:04<23:42, 97.84it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74880/214001 [13:04<23:44, 97.65it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74880/214001 [13:05<23:44, 97.65it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 74944/214001 [13:05<23:54, 96.95it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 74944/214001 [13:05<23:54, 96.95it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75008/214001 [13:05<23:44, 97.58it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75008/214001 [13:06<23:44, 97.58it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75072/214001 [13:06<23:48, 97.28it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75072/214001 [13:07<23:48, 97.28it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75136/214001 [13:07<23:34, 98.19it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75136/214001 [13:07<23:34, 98.19it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75200/214001 [13:07<23:35, 98.06it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75200/214001 [13:08<23:35, 98.06it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75264/214001 [13:08<23:48, 97.10it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75264/214001 [13:09<23:48, 97.10it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75328/214001 [13:09<23:37, 97.81it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75328/214001 [13:09<23:37, 97.81it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75392/214001 [13:09<24:00, 96.25it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75392/214001 [13:10<24:00, 96.25it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75456/214001 [13:10<23:50, 96.84it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75456/214001 [13:11<23:50, 96.84it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75520/214001 [13:11<23:45, 97.13it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75520/214001 [13:11<23:45, 97.13it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75584/214001 [13:11<23:49, 96.81it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75584/214001 [13:12<23:49, 96.81it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75648/214001 [13:12<24:05, 95.72it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75648/214001 [13:13<24:05, 95.72it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75712/214001 [13:13<23:48, 96.81it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75712/214001 [13:13<23:48, 96.81it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75776/214001 [13:13<23:41, 97.24it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75776/214001 [13:14<23:41, 97.24it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75840/214001 [13:14<23:26, 98.26it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75840/214001 [13:15<23:26, 98.26it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75904/214001 [13:15<23:22, 98.45it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75904/214001 [13:15<23:22, 98.45it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75968/214001 [13:15<23:24, 98.27it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75968/214001 [13:16<23:24, 98.27it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76032/214001 [13:16<23:26, 98.12it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76032/214001 [13:17<23:26, 98.12it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76096/214001 [13:17<23:37, 97.27it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76096/214001 [13:17<23:37, 97.27it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76160/214001 [13:17<23:42, 96.91it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76160/214001 [13:18<23:42, 96.91it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76224/214001 [13:18<23:38, 97.10it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76224/214001 [13:19<23:38, 97.10it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76288/214001 [13:19<23:46, 96.56it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76288/214001 [13:19<23:46, 96.56it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76352/214001 [13:19<23:36, 97.17it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76352/214001 [13:20<23:36, 97.17it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76416/214001 [13:20<23:30, 97.53it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76416/214001 [13:21<23:30, 97.53it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76480/214001 [13:21<23:27, 97.72it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76480/214001 [13:21<23:27, 97.72it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76544/214001 [13:21<23:50, 96.06it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76544/214001 [13:22<23:50, 96.06it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76608/214001 [13:22<23:38, 96.86it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76608/214001 [13:23<23:38, 96.86it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76672/214001 [13:23<23:59, 95.39it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76672/214001 [13:23<23:59, 95.39it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76736/214001 [13:23<23:59, 95.35it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76736/214001 [13:24<23:59, 95.35it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76800/214001 [13:24<23:48, 96.07it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76800/214001 [13:25<23:48, 96.07it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76864/214001 [13:25<23:48, 95.98it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76864/214001 [13:25<23:48, 95.98it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76928/214001 [13:25<23:46, 96.06it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76928/214001 [13:26<23:46, 96.06it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76992/214001 [13:26<23:40, 96.43it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76992/214001 [13:27<23:40, 96.43it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77056/214001 [13:27<23:51, 95.65it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77056/214001 [13:27<23:51, 95.65it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77120/214001 [13:27<23:48, 95.85it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77120/214001 [13:28<23:48, 95.85it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77184/214001 [13:28<23:44, 96.06it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77184/214001 [13:29<23:44, 96.06it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77248/214001 [13:29<23:33, 96.75it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77248/214001 [13:29<23:33, 96.75it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77312/214001 [13:29<23:44, 95.93it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77312/214001 [13:30<23:44, 95.93it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77376/214001 [13:30<23:48, 95.67it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77376/214001 [13:31<23:48, 95.67it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77440/214001 [13:31<23:34, 96.56it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77440/214001 [13:31<23:34, 96.56it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77504/214001 [13:31<23:35, 96.46it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77504/214001 [13:32<23:35, 96.46it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77568/214001 [13:32<23:30, 96.75it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77568/214001 [13:33<23:30, 96.75it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77632/214001 [13:33<23:19, 97.44it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77632/214001 [13:33<23:19, 97.44it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77696/214001 [13:33<23:23, 97.10it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77696/214001 [13:34<23:23, 97.10it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77760/214001 [13:34<23:24, 96.98it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77760/214001 [13:35<23:24, 96.98it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77824/214001 [13:35<23:35, 96.22it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77824/214001 [13:35<23:35, 96.22it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77888/214001 [13:35<24:05, 94.17it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77888/214001 [13:36<24:05, 94.17it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77952/214001 [13:36<23:53, 94.90it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77952/214001 [13:37<23:53, 94.90it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78016/214001 [13:37<23:37, 95.91it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78016/214001 [13:37<23:37, 95.91it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78080/214001 [13:37<23:46, 95.28it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78080/214001 [13:38<23:46, 95.28it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78144/214001 [13:38<23:34, 96.06it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78144/214001 [13:39<23:34, 96.06it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78208/214001 [13:39<23:33, 96.09it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78208/214001 [13:39<23:33, 96.09it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78272/214001 [13:39<23:33, 96.01it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78272/214001 [13:40<23:33, 96.01it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78336/214001 [13:40<23:49, 94.90it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78336/214001 [13:41<23:49, 94.90it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78400/214001 [13:41<23:43, 95.28it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78400/214001 [13:41<23:43, 95.28it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78464/214001 [13:41<23:39, 95.50it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78464/214001 [13:42<23:39, 95.50it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78528/214001 [13:42<23:41, 95.30it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78528/214001 [13:43<23:41, 95.30it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78592/214001 [13:43<23:45, 95.01it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78592/214001 [13:43<23:45, 95.01it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78656/214001 [13:43<23:36, 95.57it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78656/214001 [13:44<23:36, 95.57it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78720/214001 [13:44<24:05, 93.56it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78720/214001 [13:45<24:05, 93.56it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78784/214001 [13:45<24:10, 93.25it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78784/214001 [13:45<24:10, 93.25it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78848/214001 [13:45<24:10, 93.16it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78848/214001 [13:46<24:10, 93.16it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78912/214001 [13:46<24:32, 91.76it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78912/214001 [13:47<24:32, 91.76it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78976/214001 [13:47<24:25, 92.14it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78976/214001 [13:47<24:25, 92.14it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79040/214001 [13:47<24:09, 93.11it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79040/214001 [13:48<24:09, 93.11it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79104/214001 [13:48<24:05, 93.34it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79104/214001 [13:49<24:05, 93.34it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79168/214001 [13:49<23:45, 94.58it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79168/214001 [13:49<23:45, 94.58it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79232/214001 [13:49<23:40, 94.91it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79232/214001 [13:50<23:40, 94.91it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79296/214001 [13:50<23:56, 93.80it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79296/214001 [13:51<23:56, 93.80it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79360/214001 [13:51<23:35, 95.14it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79360/214001 [13:52<23:35, 95.14it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79424/214001 [13:52<23:32, 95.29it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79424/214001 [13:52<23:32, 95.29it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79488/214001 [13:52<23:27, 95.59it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79488/214001 [13:53<23:27, 95.59it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79552/214001 [13:53<23:25, 95.66it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79552/214001 [13:54<23:25, 95.66it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79616/214001 [13:54<23:26, 95.58it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79616/214001 [13:54<23:26, 95.58it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79680/214001 [13:54<23:42, 94.41it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79680/214001 [13:55<23:42, 94.41it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79744/214001 [13:55<23:30, 95.18it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79744/214001 [13:56<23:30, 95.18it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79808/214001 [13:56<23:16, 96.13it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79808/214001 [13:56<23:16, 96.13it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79872/214001 [13:56<23:12, 96.33it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79872/214001 [13:57<23:12, 96.33it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79936/214001 [13:57<23:05, 96.77it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79936/214001 [13:58<23:05, 96.77it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80000/214001 [13:58<23:41, 94.28it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80000/214001 [13:58<23:41, 94.28it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80064/214001 [13:58<23:31, 94.87it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80064/214001 [13:59<23:31, 94.87it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80128/214001 [13:59<23:31, 94.85it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80128/214001 [14:00<23:31, 94.85it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80192/214001 [14:00<23:31, 94.79it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80192/214001 [14:00<23:31, 94.79it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80256/214001 [14:00<23:15, 95.87it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80256/214001 [14:01<23:15, 95.87it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80320/214001 [14:01<23:15, 95.81it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80320/214001 [14:02<23:15, 95.81it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80384/214001 [14:02<23:02, 96.66it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80384/214001 [14:02<23:02, 96.66it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80448/214001 [14:02<23:02, 96.57it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80448/214001 [14:03<23:02, 96.57it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80512/214001 [14:03<23:08, 96.12it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80512/214001 [14:04<23:08, 96.12it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80576/214001 [14:04<23:15, 95.64it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80576/214001 [14:04<23:15, 95.64it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80640/214001 [14:04<23:11, 95.86it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80640/214001 [14:05<23:11, 95.86it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80704/214001 [14:05<23:00, 96.55it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80704/214001 [14:06<23:00, 96.55it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80768/214001 [14:06<23:01, 96.41it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80768/214001 [14:06<23:01, 96.41it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80832/214001 [14:06<23:02, 96.32it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80832/214001 [14:07<23:02, 96.32it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80896/214001 [14:07<23:19, 95.08it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80896/214001 [14:08<23:19, 95.08it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80960/214001 [14:08<23:21, 94.94it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80960/214001 [14:08<23:21, 94.94it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81024/214001 [14:08<23:22, 94.78it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81024/214001 [14:09<23:22, 94.78it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81088/214001 [14:09<23:25, 94.55it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81088/214001 [14:10<23:25, 94.55it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81152/214001 [14:10<23:23, 94.64it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81152/214001 [14:10<23:23, 94.64it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81216/214001 [14:10<23:20, 94.83it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81216/214001 [14:11<23:20, 94.83it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81280/214001 [14:11<23:21, 94.71it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81280/214001 [14:12<23:21, 94.71it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81344/214001 [14:12<23:14, 95.10it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81344/214001 [14:12<23:14, 95.10it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81408/214001 [14:12<23:07, 95.54it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81408/214001 [14:13<23:07, 95.54it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81472/214001 [14:13<23:02, 95.84it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81472/214001 [14:14<23:02, 95.84it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81536/214001 [14:14<22:55, 96.29it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81536/214001 [14:14<22:55, 96.29it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81600/214001 [14:14<22:58, 96.03it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81600/214001 [14:15<22:58, 96.03it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81664/214001 [14:15<22:53, 96.33it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81664/214001 [14:16<22:53, 96.33it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81728/214001 [14:16<23:00, 95.83it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81728/214001 [14:16<23:00, 95.83it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81792/214001 [14:16<23:17, 94.60it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81792/214001 [14:17<23:17, 94.60it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81856/214001 [14:17<23:15, 94.72it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81856/214001 [14:18<23:15, 94.72it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81920/214001 [14:18<23:09, 95.07it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81920/214001 [14:18<23:09, 95.07it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81984/214001 [14:18<23:03, 95.42it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81984/214001 [14:19<23:03, 95.42it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82048/214001 [14:19<23:01, 95.49it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82048/214001 [14:20<23:01, 95.49it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82112/214001 [14:20<23:13, 94.66it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82112/214001 [14:20<23:13, 94.66it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82176/214001 [14:20<23:23, 93.92it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82176/214001 [14:21<23:23, 93.92it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82240/214001 [14:21<23:32, 93.31it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82240/214001 [14:22<23:32, 93.31it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82304/214001 [14:22<23:09, 94.75it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82304/214001 [14:22<23:09, 94.75it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82368/214001 [14:22<23:00, 95.36it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82368/214001 [14:23<23:00, 95.36it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82432/214001 [14:23<22:58, 95.46it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82432/214001 [14:24<22:58, 95.46it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82496/214001 [14:24<22:59, 95.32it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82496/214001 [14:24<22:59, 95.32it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82560/214001 [14:24<23:01, 95.17it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82560/214001 [14:25<23:01, 95.17it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82624/214001 [14:25<23:01, 95.11it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82624/214001 [14:26<23:01, 95.11it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82688/214001 [14:26<23:16, 94.05it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82688/214001 [14:26<23:16, 94.05it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82752/214001 [14:26<23:02, 94.91it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82752/214001 [14:27<23:02, 94.91it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82816/214001 [14:27<22:51, 95.67it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82816/214001 [14:28<22:51, 95.67it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82880/214001 [14:28<22:40, 96.37it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82880/214001 [14:28<22:40, 96.37it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 82944/214001 [14:28<22:35, 96.67it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 82944/214001 [14:29<22:35, 96.67it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83008/214001 [14:29<22:35, 96.65it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83008/214001 [14:30<22:35, 96.65it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83072/214001 [14:30<22:34, 96.67it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83072/214001 [14:30<22:34, 96.67it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83136/214001 [14:30<22:51, 95.40it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83136/214001 [14:31<22:51, 95.40it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83200/214001 [14:31<22:49, 95.53it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83200/214001 [14:32<22:49, 95.53it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83264/214001 [14:32<22:45, 95.71it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83264/214001 [14:32<22:45, 95.71it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83328/214001 [14:32<23:13, 93.77it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83328/214001 [14:33<23:13, 93.77it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83392/214001 [14:33<23:11, 93.87it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83392/214001 [14:34<23:11, 93.87it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83456/214001 [14:34<23:17, 93.43it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83456/214001 [14:34<23:17, 93.43it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83520/214001 [14:34<23:04, 94.22it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83520/214001 [14:35<23:04, 94.22it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83584/214001 [14:35<23:05, 94.16it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83584/214001 [14:36<23:05, 94.16it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83648/214001 [14:36<23:10, 93.73it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83648/214001 [14:37<23:10, 93.73it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83712/214001 [14:37<23:10, 93.67it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83712/214001 [14:37<23:10, 93.67it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83776/214001 [14:37<23:11, 93.58it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83776/214001 [14:38<23:11, 93.58it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83840/214001 [14:38<23:16, 93.19it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83840/214001 [14:39<23:16, 93.19it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83904/214001 [14:39<23:01, 94.14it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83904/214001 [14:39<23:01, 94.14it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83968/214001 [14:39<22:58, 94.33it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83968/214001 [14:40<22:58, 94.33it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84032/214001 [14:40<23:01, 94.08it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84032/214001 [14:41<23:01, 94.08it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84096/214001 [14:41<22:48, 94.92it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84096/214001 [14:41<22:48, 94.92it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84160/214001 [14:41<22:42, 95.28it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84160/214001 [14:42<22:42, 95.28it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84224/214001 [14:42<22:36, 95.69it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84224/214001 [14:43<22:36, 95.69it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84288/214001 [14:43<22:39, 95.44it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84288/214001 [14:43<22:39, 95.44it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84352/214001 [14:43<22:43, 95.10it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84352/214001 [14:44<22:43, 95.10it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84416/214001 [14:44<22:54, 94.28it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84416/214001 [14:45<22:54, 94.28it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84480/214001 [14:45<22:53, 94.30it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84480/214001 [14:45<22:53, 94.30it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84544/214001 [14:45<22:46, 94.75it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84544/214001 [14:46<22:46, 94.75it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84608/214001 [14:46<22:48, 94.58it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84608/214001 [14:47<22:48, 94.58it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84672/214001 [14:47<22:33, 95.56it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84672/214001 [14:47<22:33, 95.56it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84736/214001 [14:47<22:23, 96.24it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84736/214001 [14:48<22:23, 96.24it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84800/214001 [14:48<22:21, 96.33it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84800/214001 [14:49<22:21, 96.33it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84864/214001 [14:49<22:12, 96.91it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84864/214001 [14:49<22:12, 96.91it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84928/214001 [14:49<22:20, 96.32it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84928/214001 [14:50<22:20, 96.32it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84992/214001 [14:50<22:29, 95.59it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84992/214001 [14:51<22:29, 95.59it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85056/214001 [14:51<22:28, 95.59it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85056/214001 [14:51<22:28, 95.59it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85120/214001 [14:51<22:23, 95.92it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85120/214001 [14:52<22:23, 95.92it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85184/214001 [14:52<22:23, 95.87it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85184/214001 [14:53<22:23, 95.87it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85248/214001 [14:53<22:21, 96.01it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85248/214001 [14:53<22:21, 96.01it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85312/214001 [14:53<22:23, 95.76it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85312/214001 [14:54<22:23, 95.76it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85376/214001 [14:54<22:29, 95.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85376/214001 [14:55<22:29, 95.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85440/214001 [14:55<23:01, 93.08it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85440/214001 [14:55<23:01, 93.08it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85504/214001 [14:55<23:02, 92.94it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85504/214001 [14:56<23:02, 92.94it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  40%|███▉      | 85568/214001 [14:56<23:30, 91.07it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85568/214001 [14:57<23:30, 91.07it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 85632/214001 [14:57<23:18, 91.82it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 85632/214001 [14:58<23:18, 91.82it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 85696/214001 [14:58<23:46, 89.94it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 85696/214001 [14:58<23:46, 89.94it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85760/214001 [14:58<23:56, 89.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85760/214001 [14:59<23:56, 89.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85824/214001 [14:59<23:42, 90.12it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85824/214001 [15:00<23:42, 90.12it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85888/214001 [15:00<23:43, 90.02it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85888/214001 [15:00<23:43, 90.02it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85952/214001 [15:00<23:51, 89.47it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 85952/214001 [15:01<23:51, 89.47it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86016/214001 [15:01<23:50, 89.48it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86016/214001 [15:02<23:50, 89.48it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86080/214001 [15:02<23:26, 90.97it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86080/214001 [15:03<23:26, 90.97it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86144/214001 [15:03<23:13, 91.74it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86144/214001 [15:03<23:13, 91.74it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  40%|████      | 86208/214001 [15:03<23:03, 92.36it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 86208/214001 [15:04<23:03, 92.36it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 86272/214001 [15:04<23:26, 90.81it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 86272/214001 [15:05<23:26, 90.81it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86336/214001 [15:05<23:44, 89.63it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86336/214001 [15:05<23:44, 89.63it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  40%|████      | 86400/214001 [15:05<23:39, 89.87it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  40%|████      | 86400/214001 [15:06<23:39, 89.87it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86464/214001 [15:06<23:23, 90.86it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86464/214001 [15:07<23:23, 90.86it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86528/214001 [15:07<23:07, 91.90it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86528/214001 [15:07<23:07, 91.90it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86592/214001 [15:07<23:02, 92.15it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86592/214001 [15:08<23:02, 92.15it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86656/214001 [15:08<23:26, 90.53it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  40%|████      | 86656/214001 [15:09<23:26, 90.53it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86720/214001 [15:09<23:29, 90.30it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86720/214001 [15:10<23:29, 90.30it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86784/214001 [15:10<23:33, 90.03it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86784/214001 [15:10<23:33, 90.03it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86848/214001 [15:10<23:18, 90.95it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86848/214001 [15:11<23:18, 90.95it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86912/214001 [15:11<23:17, 90.96it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86912/214001 [15:12<23:17, 90.96it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86976/214001 [15:12<23:08, 91.50it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 86976/214001 [15:12<23:08, 91.50it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87040/214001 [15:12<23:12, 91.19it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87040/214001 [15:13<23:12, 91.19it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87104/214001 [15:13<23:13, 91.08it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87104/214001 [15:14<23:13, 91.08it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87168/214001 [15:14<23:00, 91.86it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87168/214001 [15:14<23:00, 91.86it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87232/214001 [15:14<22:46, 92.79it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87232/214001 [15:15<22:46, 92.79it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87296/214001 [15:15<22:35, 93.48it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87296/214001 [15:16<22:35, 93.48it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87360/214001 [15:16<22:36, 93.36it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87360/214001 [15:17<22:36, 93.36it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87424/214001 [15:17<22:48, 92.51it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87424/214001 [15:17<22:48, 92.51it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87488/214001 [15:17<22:54, 92.02it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87488/214001 [15:18<22:54, 92.02it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87552/214001 [15:18<22:42, 92.79it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87552/214001 [15:19<22:42, 92.79it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87616/214001 [15:19<22:40, 92.91it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87616/214001 [15:19<22:40, 92.91it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87680/214001 [15:19<22:38, 92.96it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87680/214001 [15:20<22:38, 92.96it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87744/214001 [15:20<22:35, 93.16it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  41%|████      | 87744/214001 [15:21<22:35, 93.16it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  41%|████      | 87808/214001 [15:21<22:48, 92.18it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  41%|████      | 87808/214001 [15:21<22:48, 92.18it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  41%|████      | 87872/214001 [15:21<23:33, 89.23it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  41%|████      | 87872/214001 [15:22<23:33, 89.23it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  41%|████      | 87936/214001 [15:22<23:12, 90.51it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  41%|████      | 87936/214001 [15:23<23:12, 90.51it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  41%|████      | 88000/214001 [15:23<23:00, 91.29it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  41%|████      | 88000/214001 [15:24<23:00, 91.29it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88064/214001 [15:24<23:21, 89.83it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88064/214001 [15:24<23:21, 89.83it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88128/214001 [15:24<23:33, 89.08it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88128/214001 [15:25<23:33, 89.08it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88192/214001 [15:25<23:23, 89.64it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88192/214001 [15:26<23:23, 89.64it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88256/214001 [15:26<22:59, 91.16it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████      | 88256/214001 [15:26<22:59, 91.16it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88320/214001 [15:26<22:56, 91.33it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88320/214001 [15:27<22:56, 91.33it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88384/214001 [15:27<23:25, 89.38it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88384/214001 [15:28<23:25, 89.38it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88448/214001 [15:28<23:09, 90.33it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88448/214001 [15:28<23:09, 90.33it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88512/214001 [15:29<23:11, 90.16it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88512/214001 [15:29<23:11, 90.16it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88576/214001 [15:29<23:29, 89.00it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88576/214001 [15:30<23:29, 89.00it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88640/214001 [15:30<23:06, 90.45it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88640/214001 [15:31<23:06, 90.45it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88704/214001 [15:31<23:21, 89.40it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88704/214001 [15:31<23:21, 89.40it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88768/214001 [15:31<23:14, 89.81it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88768/214001 [15:32<23:14, 89.81it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88832/214001 [15:32<23:04, 90.38it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88832/214001 [15:33<23:04, 90.38it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88896/214001 [15:33<23:01, 90.55it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88896/214001 [15:33<23:01, 90.55it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88960/214001 [15:33<23:03, 90.41it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88960/214001 [15:34<23:03, 90.41it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89024/214001 [15:34<22:55, 90.83it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89024/214001 [15:35<22:55, 90.83it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89088/214001 [15:35<22:48, 91.27it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89088/214001 [15:36<22:48, 91.27it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89152/214001 [15:36<22:51, 91.03it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89152/214001 [15:36<22:51, 91.03it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89216/214001 [15:36<22:50, 91.06it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89216/214001 [15:37<22:50, 91.06it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89280/214001 [15:37<22:43, 91.45it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89280/214001 [15:38<22:43, 91.45it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89344/214001 [15:38<22:27, 92.52it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89344/214001 [15:38<22:27, 92.52it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89408/214001 [15:38<22:11, 93.54it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89408/214001 [15:39<22:11, 93.54it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89472/214001 [15:39<22:14, 93.28it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89472/214001 [15:40<22:14, 93.28it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89536/214001 [15:40<22:27, 92.33it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89536/214001 [15:40<22:27, 92.33it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89600/214001 [15:40<22:21, 92.77it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89600/214001 [15:41<22:21, 92.77it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89664/214001 [15:41<22:25, 92.41it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89664/214001 [15:42<22:25, 92.41it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89728/214001 [15:42<22:10, 93.42it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89728/214001 [15:42<22:10, 93.42it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89792/214001 [15:42<22:01, 93.96it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89792/214001 [15:43<22:01, 93.96it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89856/214001 [15:43<22:17, 92.85it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89856/214001 [15:44<22:17, 92.85it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89920/214001 [15:44<22:29, 91.97it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89920/214001 [15:45<22:29, 91.97it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89984/214001 [15:45<22:18, 92.68it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89984/214001 [15:45<22:18, 92.68it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90048/214001 [15:45<22:30, 91.76it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90048/214001 [15:46<22:30, 91.76it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90112/214001 [15:46<22:48, 90.55it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90112/214001 [15:47<22:48, 90.55it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90176/214001 [15:47<22:43, 90.80it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90176/214001 [15:47<22:43, 90.80it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90240/214001 [15:47<22:33, 91.41it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90240/214001 [15:48<22:33, 91.41it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90304/214001 [15:48<22:34, 91.33it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90304/214001 [15:49<22:34, 91.33it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90368/214001 [15:49<22:37, 91.05it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90368/214001 [15:49<22:37, 91.05it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90432/214001 [15:49<22:15, 92.52it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90432/214001 [15:50<22:15, 92.52it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90496/214001 [15:50<22:23, 91.91it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90496/214001 [15:51<22:23, 91.91it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90560/214001 [15:51<22:09, 92.86it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90560/214001 [15:51<22:09, 92.86it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90624/214001 [15:51<22:04, 93.15it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90624/214001 [15:52<22:04, 93.15it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90688/214001 [15:52<22:27, 91.50it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90688/214001 [15:53<22:27, 91.50it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90752/214001 [15:53<22:30, 91.26it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90752/214001 [15:54<22:30, 91.26it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90816/214001 [15:54<22:08, 92.74it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90816/214001 [15:54<22:08, 92.74it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90880/214001 [15:54<22:01, 93.18it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90880/214001 [15:55<22:01, 93.18it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90944/214001 [15:55<21:53, 93.67it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90944/214001 [15:56<21:53, 93.67it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91008/214001 [15:56<21:50, 93.86it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91008/214001 [15:56<21:50, 93.86it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91072/214001 [15:56<21:44, 94.25it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91072/214001 [15:57<21:44, 94.25it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91136/214001 [15:57<21:37, 94.69it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91136/214001 [15:58<21:37, 94.69it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91200/214001 [15:58<21:34, 94.84it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91200/214001 [15:58<21:34, 94.84it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91264/214001 [15:58<21:50, 93.67it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91264/214001 [15:59<21:50, 93.67it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91328/214001 [15:59<22:02, 92.73it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91328/214001 [16:00<22:02, 92.73it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91392/214001 [16:00<21:59, 92.91it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91392/214001 [16:00<21:59, 92.91it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91456/214001 [16:00<22:00, 92.77it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91456/214001 [16:01<22:00, 92.77it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91520/214001 [16:01<22:29, 90.77it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91520/214001 [16:02<22:29, 90.77it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91584/214001 [16:02<22:54, 89.06it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91584/214001 [16:03<22:54, 89.06it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91648/214001 [16:03<22:51, 89.18it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91648/214001 [16:03<22:51, 89.18it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91712/214001 [16:03<22:38, 89.99it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91712/214001 [16:04<22:38, 89.99it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91776/214001 [16:04<22:38, 90.00it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91776/214001 [16:05<22:38, 90.00it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91840/214001 [16:05<22:35, 90.12it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91840/214001 [16:05<22:35, 90.12it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91904/214001 [16:05<22:25, 90.72it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91904/214001 [16:06<22:25, 90.72it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91968/214001 [16:06<22:28, 90.50it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91968/214001 [16:07<22:28, 90.50it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92032/214001 [16:07<22:10, 91.69it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92032/214001 [16:07<22:10, 91.69it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92096/214001 [16:08<21:53, 92.84it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92096/214001 [16:08<21:53, 92.84it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92160/214001 [16:08<21:55, 92.65it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92160/214001 [16:09<21:55, 92.65it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92224/214001 [16:09<21:52, 92.81it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92224/214001 [16:10<21:52, 92.81it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92288/214001 [16:10<21:35, 93.92it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92288/214001 [16:10<21:35, 93.92it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92352/214001 [16:10<21:14, 95.45it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92352/214001 [16:11<21:14, 95.45it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92416/214001 [16:11<21:17, 95.19it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92416/214001 [16:12<21:17, 95.19it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92480/214001 [16:12<21:22, 94.76it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92480/214001 [16:12<21:22, 94.76it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92544/214001 [16:12<21:23, 94.59it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92544/214001 [16:13<21:23, 94.59it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92608/214001 [16:13<21:25, 94.42it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92608/214001 [16:14<21:25, 94.42it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92672/214001 [16:14<21:25, 94.39it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92672/214001 [16:14<21:25, 94.39it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92736/214001 [16:14<21:28, 94.12it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92736/214001 [16:15<21:28, 94.12it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92800/214001 [16:15<21:24, 94.37it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92800/214001 [16:16<21:24, 94.37it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92864/214001 [16:16<21:19, 94.66it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92864/214001 [16:16<21:19, 94.66it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92928/214001 [16:16<21:05, 95.67it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92928/214001 [16:17<21:05, 95.67it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92992/214001 [16:17<21:30, 93.76it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92992/214001 [16:18<21:30, 93.76it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 93056/214001 [16:18<21:27, 93.96it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 93056/214001 [16:18<21:27, 93.96it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93120/214001 [16:18<21:14, 94.88it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93120/214001 [16:19<21:14, 94.88it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93184/214001 [16:19<21:07, 95.33it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93184/214001 [16:20<21:07, 95.33it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93248/214001 [16:20<20:59, 95.88it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93248/214001 [16:20<20:59, 95.88it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93312/214001 [16:20<20:59, 95.84it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93312/214001 [16:21<20:59, 95.84it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93376/214001 [16:21<21:07, 95.19it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93376/214001 [16:22<21:07, 95.19it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93440/214001 [16:22<21:09, 94.93it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93440/214001 [16:22<21:09, 94.93it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93504/214001 [16:22<21:08, 94.99it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93504/214001 [16:23<21:08, 94.99it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93568/214001 [16:23<21:15, 94.46it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93568/214001 [16:24<21:15, 94.46it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93632/214001 [16:24<21:40, 92.58it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93632/214001 [16:24<21:40, 92.58it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93696/214001 [16:24<21:24, 93.69it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93696/214001 [16:25<21:24, 93.69it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93760/214001 [16:25<21:14, 94.31it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93760/214001 [16:26<21:14, 94.31it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93824/214001 [16:26<21:13, 94.34it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93824/214001 [16:26<21:13, 94.34it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93888/214001 [16:26<20:58, 95.44it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93888/214001 [16:27<20:58, 95.44it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93952/214001 [16:27<21:03, 95.00it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93952/214001 [16:28<21:03, 95.00it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94016/214001 [16:28<21:02, 95.06it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94016/214001 [16:28<21:02, 95.06it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94080/214001 [16:28<21:00, 95.11it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94080/214001 [16:29<21:00, 95.11it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94144/214001 [16:29<21:04, 94.78it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94144/214001 [16:30<21:04, 94.78it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94208/214001 [16:30<21:11, 94.22it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94208/214001 [16:31<21:11, 94.22it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94272/214001 [16:31<21:23, 93.32it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94272/214001 [16:31<21:23, 93.32it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94336/214001 [16:31<21:19, 93.53it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94336/214001 [16:32<21:19, 93.53it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94400/214001 [16:32<21:47, 91.44it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94400/214001 [16:33<21:47, 91.44it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94464/214001 [16:33<21:33, 92.43it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94464/214001 [16:33<21:33, 92.43it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94528/214001 [16:33<21:25, 92.94it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94528/214001 [16:34<21:25, 92.94it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94592/214001 [16:34<21:36, 92.10it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94592/214001 [16:35<21:36, 92.10it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94656/214001 [16:35<21:25, 92.85it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94656/214001 [16:35<21:25, 92.85it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94720/214001 [16:35<21:38, 91.86it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94720/214001 [16:36<21:38, 91.86it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94784/214001 [16:36<21:44, 91.39it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94784/214001 [16:37<21:44, 91.39it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94848/214001 [16:37<21:19, 93.10it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94848/214001 [16:37<21:19, 93.10it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  44%|████▍     | 94912/214001 [16:37<21:06, 94.06it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94912/214001 [16:38<21:06, 94.06it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94976/214001 [16:38<21:20, 92.93it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94976/214001 [16:39<21:20, 92.93it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95040/214001 [16:39<21:25, 92.53it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95040/214001 [16:39<21:25, 92.53it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95104/214001 [16:40<21:20, 92.83it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95104/214001 [16:40<21:20, 92.83it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95168/214001 [16:40<21:17, 93.04it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95168/214001 [16:41<21:17, 93.04it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95232/214001 [16:41<21:18, 92.92it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95232/214001 [16:42<21:18, 92.92it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95296/214001 [16:42<21:38, 91.42it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95296/214001 [16:42<21:38, 91.42it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95360/214001 [16:42<22:03, 89.64it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95360/214001 [16:43<22:03, 89.64it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95424/214001 [16:43<21:44, 90.88it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95424/214001 [16:44<21:44, 90.88it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95488/214001 [16:44<21:54, 90.16it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95488/214001 [16:45<21:54, 90.16it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95552/214001 [16:45<22:25, 88.05it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95552/214001 [16:45<22:25, 88.05it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95616/214001 [16:45<22:14, 88.70it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95616/214001 [16:46<22:14, 88.70it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95680/214001 [16:46<22:12, 88.80it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95680/214001 [16:47<22:12, 88.80it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95744/214001 [16:47<22:02, 89.41it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95744/214001 [16:47<22:02, 89.41it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95808/214001 [16:47<21:33, 91.34it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95808/214001 [16:48<21:33, 91.34it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95872/214001 [16:48<21:16, 92.52it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95872/214001 [16:49<21:16, 92.52it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95936/214001 [16:49<21:24, 91.91it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95936/214001 [16:49<21:24, 91.91it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96000/214001 [16:49<21:32, 91.33it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96000/214001 [16:50<21:32, 91.33it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96064/214001 [16:50<21:48, 90.13it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96064/214001 [16:51<21:48, 90.13it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96128/214001 [16:51<21:57, 89.48it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96128/214001 [16:52<21:57, 89.48it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  45%|████▍     | 96192/214001 [16:52<22:01, 89.13it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96192/214001 [16:52<22:01, 89.13it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96256/214001 [16:52<21:42, 90.43it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96256/214001 [16:53<21:42, 90.43it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  45%|████▌     | 96320/214001 [16:53<21:15, 92.23it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96320/214001 [16:54<21:15, 92.23it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96384/214001 [16:54<21:21, 91.77it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96384/214001 [16:54<21:21, 91.77it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96448/214001 [16:54<21:41, 90.34it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96448/214001 [16:55<21:41, 90.34it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96512/214001 [16:55<21:34, 90.79it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96512/214001 [16:56<21:34, 90.79it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96576/214001 [16:56<21:51, 89.52it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96576/214001 [16:57<21:51, 89.52it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96640/214001 [16:57<21:56, 89.14it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96640/214001 [16:57<21:56, 89.14it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96704/214001 [16:57<21:40, 90.20it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96704/214001 [16:58<21:40, 90.20it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96768/214001 [16:58<21:36, 90.43it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96768/214001 [16:59<21:36, 90.43it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96832/214001 [16:59<22:03, 88.55it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96832/214001 [16:59<22:03, 88.55it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96896/214001 [16:59<21:47, 89.55it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96896/214001 [17:00<21:47, 89.55it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96960/214001 [17:00<21:39, 90.04it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96960/214001 [17:01<21:39, 90.04it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  45%|████▌     | 97024/214001 [17:01<21:40, 89.96it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97024/214001 [17:02<21:40, 89.96it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97088/214001 [17:02<21:57, 88.74it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97088/214001 [17:02<21:57, 88.74it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97152/214001 [17:02<21:48, 89.29it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97152/214001 [17:03<21:48, 89.29it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97216/214001 [17:03<21:54, 88.81it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97216/214001 [17:04<21:54, 88.81it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97280/214001 [17:04<22:10, 87.71it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97280/214001 [17:04<22:10, 87.71it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97344/214001 [17:04<22:18, 87.16it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97344/214001 [17:05<22:18, 87.16it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97408/214001 [17:05<22:21, 86.92it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97408/214001 [17:06<22:21, 86.92it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97472/214001 [17:06<22:38, 85.78it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97472/214001 [17:07<22:38, 85.78it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97536/214001 [17:07<22:13, 87.35it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97536/214001 [17:07<22:13, 87.35it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97600/214001 [17:07<22:17, 87.03it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97600/214001 [17:08<22:17, 87.03it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97664/214001 [17:08<22:08, 87.59it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97664/214001 [17:09<22:08, 87.59it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97728/214001 [17:09<22:24, 86.49it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97728/214001 [17:10<22:24, 86.49it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97792/214001 [17:10<22:07, 87.54it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97792/214001 [17:10<22:07, 87.54it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97856/214001 [17:10<21:59, 87.99it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97856/214001 [17:11<21:59, 87.99it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97920/214001 [17:11<22:00, 87.93it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97920/214001 [17:12<22:00, 87.93it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97984/214001 [17:12<21:49, 88.62it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97984/214001 [17:12<21:49, 88.62it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98048/214001 [17:13<21:50, 88.46it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98048/214001 [17:13<21:50, 88.46it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98112/214001 [17:13<21:53, 88.22it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98112/214001 [17:14<21:53, 88.22it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98176/214001 [17:14<21:44, 88.81it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98176/214001 [17:15<21:44, 88.81it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98240/214001 [17:15<21:33, 89.47it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98240/214001 [17:15<21:33, 89.47it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98304/214001 [17:15<21:23, 90.13it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98304/214001 [17:16<21:23, 90.13it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98368/214001 [17:16<21:18, 90.41it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98368/214001 [17:17<21:18, 90.41it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98432/214001 [17:17<21:06, 91.29it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98432/214001 [17:17<21:06, 91.29it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98496/214001 [17:17<21:17, 90.43it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98496/214001 [17:18<21:17, 90.43it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98560/214001 [17:18<21:02, 91.46it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98560/214001 [17:19<21:02, 91.46it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98624/214001 [17:19<21:07, 91.05it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98624/214001 [17:20<21:07, 91.05it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98688/214001 [17:20<20:59, 91.56it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98688/214001 [17:20<20:59, 91.56it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98752/214001 [17:20<21:32, 89.16it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98752/214001 [17:21<21:32, 89.16it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98816/214001 [17:21<21:41, 88.53it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98816/214001 [17:22<21:41, 88.53it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98880/214001 [17:22<21:27, 89.42it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98880/214001 [17:22<21:27, 89.42it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98944/214001 [17:22<21:08, 90.73it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98944/214001 [17:23<21:08, 90.73it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99008/214001 [17:23<21:19, 89.85it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99008/214001 [17:24<21:19, 89.85it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99072/214001 [17:24<21:16, 90.06it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99072/214001 [17:25<21:16, 90.06it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99136/214001 [17:25<20:57, 91.37it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99136/214001 [17:25<20:57, 91.37it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99200/214001 [17:25<20:48, 91.97it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99200/214001 [17:26<20:48, 91.97it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99264/214001 [17:26<20:41, 92.41it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99264/214001 [17:27<20:41, 92.41it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99328/214001 [17:27<20:25, 93.61it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99328/214001 [17:27<20:25, 93.61it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99392/214001 [17:27<20:22, 93.74it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99392/214001 [17:28<20:22, 93.74it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99456/214001 [17:28<20:15, 94.20it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99456/214001 [17:29<20:15, 94.20it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99520/214001 [17:29<20:21, 93.74it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99520/214001 [17:29<20:21, 93.74it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99584/214001 [17:29<20:52, 91.37it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99584/214001 [17:30<20:52, 91.37it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99648/214001 [17:30<20:37, 92.42it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99648/214001 [17:31<20:37, 92.42it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99712/214001 [17:31<20:26, 93.18it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99712/214001 [17:31<20:26, 93.18it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99776/214001 [17:31<20:21, 93.51it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99776/214001 [17:32<20:21, 93.51it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99840/214001 [17:32<20:27, 93.03it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99840/214001 [17:33<20:27, 93.03it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99904/214001 [17:33<20:13, 94.05it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99904/214001 [17:33<20:13, 94.05it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99968/214001 [17:33<20:13, 93.98it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99968/214001 [17:34<20:13, 93.98it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100032/214001 [17:34<20:21, 93.27it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100032/214001 [17:35<20:21, 93.27it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100096/214001 [17:35<20:15, 93.74it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100096/214001 [17:35<20:15, 93.74it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100160/214001 [17:35<20:27, 92.72it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100160/214001 [17:36<20:27, 92.72it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100224/214001 [17:36<20:27, 92.68it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100224/214001 [17:37<20:27, 92.68it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100288/214001 [17:37<20:06, 94.22it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100288/214001 [17:38<20:06, 94.22it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100352/214001 [17:38<20:08, 94.03it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100352/214001 [17:38<20:08, 94.03it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100416/214001 [17:38<20:20, 93.07it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100416/214001 [17:39<20:20, 93.07it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100480/214001 [17:39<20:09, 93.88it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100480/214001 [17:40<20:09, 93.88it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100544/214001 [17:40<20:01, 94.40it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100544/214001 [17:40<20:01, 94.40it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100608/214001 [17:40<20:01, 94.36it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100608/214001 [17:41<20:01, 94.36it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100672/214001 [17:41<19:56, 94.69it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100672/214001 [17:42<19:56, 94.69it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100736/214001 [17:42<19:54, 94.84it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100736/214001 [17:42<19:54, 94.84it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100800/214001 [17:42<20:05, 93.89it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100800/214001 [17:43<20:05, 93.89it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100864/214001 [17:43<20:09, 93.55it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100864/214001 [17:44<20:09, 93.55it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100928/214001 [17:44<20:42, 91.03it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100928/214001 [17:44<20:42, 91.03it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100992/214001 [17:44<20:38, 91.21it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100992/214001 [17:45<20:38, 91.21it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101056/214001 [17:45<20:27, 92.05it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101056/214001 [17:46<20:27, 92.05it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101120/214001 [17:46<20:11, 93.16it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101120/214001 [17:47<20:11, 93.16it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101184/214001 [17:47<21:08, 88.95it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101184/214001 [17:48<21:08, 88.95it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101248/214001 [17:48<23:52, 78.70it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101248/214001 [17:49<23:52, 78.70it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101312/214001 [17:49<25:50, 72.68it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101312/214001 [17:50<25:50, 72.68it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101376/214001 [17:50<27:29, 68.26it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101376/214001 [17:51<27:29, 68.26it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101440/214001 [17:51<29:22, 63.88it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101440/214001 [17:52<29:22, 63.88it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101504/214001 [17:52<30:49, 60.83it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101504/214001 [17:53<30:49, 60.83it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101568/214001 [17:53<29:34, 63.36it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101568/214001 [17:54<29:34, 63.36it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101632/214001 [17:54<26:48, 69.86it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101632/214001 [17:54<26:48, 69.86it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101696/214001 [17:54<25:08, 74.47it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101696/214001 [17:55<25:08, 74.47it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101760/214001 [17:55<23:31, 79.54it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101760/214001 [17:56<23:31, 79.54it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101824/214001 [17:56<22:31, 83.03it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101824/214001 [17:56<22:31, 83.03it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101888/214001 [17:56<21:51, 85.46it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101888/214001 [17:57<21:51, 85.46it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101952/214001 [17:57<21:18, 87.65it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101952/214001 [17:58<21:18, 87.65it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102016/214001 [17:58<20:51, 89.49it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102016/214001 [17:58<20:51, 89.49it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102080/214001 [17:58<20:39, 90.33it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102080/214001 [17:59<20:39, 90.33it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102144/214001 [17:59<20:25, 91.29it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102144/214001 [18:00<20:25, 91.29it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102208/214001 [18:00<20:18, 91.76it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102208/214001 [18:01<20:18, 91.76it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102272/214001 [18:01<20:13, 92.08it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102272/214001 [18:01<20:13, 92.08it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102336/214001 [18:01<20:12, 92.13it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102336/214001 [18:02<20:12, 92.13it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  48%|████▊     | 102400/214001 [18:02<20:11, 92.11it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102400/214001 [18:03<20:11, 92.11it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102464/214001 [18:03<20:21, 91.31it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102464/214001 [18:03<20:21, 91.31it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102528/214001 [18:03<20:29, 90.67it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102528/214001 [18:04<20:29, 90.67it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102592/214001 [18:04<21:00, 88.40it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102592/214001 [18:05<21:00, 88.40it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102656/214001 [18:05<20:47, 89.27it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102656/214001 [18:06<20:47, 89.27it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102720/214001 [18:06<20:40, 89.74it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102720/214001 [18:06<20:40, 89.74it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102784/214001 [18:06<20:32, 90.25it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102784/214001 [18:07<20:32, 90.25it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102848/214001 [18:07<20:53, 88.68it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102848/214001 [18:08<20:53, 88.68it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102912/214001 [18:08<20:58, 88.24it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102912/214001 [18:08<20:58, 88.24it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102976/214001 [18:08<20:55, 88.45it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102976/214001 [18:09<20:55, 88.45it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103040/214001 [18:09<20:36, 89.77it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103040/214001 [18:10<20:36, 89.77it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103104/214001 [18:10<20:23, 90.65it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103104/214001 [18:11<20:23, 90.65it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103168/214001 [18:11<20:16, 91.07it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103168/214001 [18:11<20:16, 91.07it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103232/214001 [18:11<21:01, 87.79it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103232/214001 [18:12<21:01, 87.79it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103296/214001 [18:12<20:46, 88.84it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103296/214001 [18:13<20:46, 88.84it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103360/214001 [18:13<20:35, 89.56it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103360/214001 [18:13<20:35, 89.56it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103424/214001 [18:13<20:28, 90.03it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103424/214001 [18:14<20:28, 90.03it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103488/214001 [18:14<20:44, 88.77it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103488/214001 [18:15<20:44, 88.77it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103552/214001 [18:15<20:44, 88.74it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103552/214001 [18:16<20:44, 88.74it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103616/214001 [18:16<20:36, 89.25it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103616/214001 [18:16<20:36, 89.25it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103680/214001 [18:16<20:44, 88.68it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103680/214001 [18:17<20:44, 88.68it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103744/214001 [18:17<20:44, 88.62it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103744/214001 [18:18<20:44, 88.62it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103808/214001 [18:18<20:52, 87.96it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103808/214001 [18:18<20:52, 87.96it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103872/214001 [18:18<20:43, 88.57it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103872/214001 [18:19<20:43, 88.57it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103936/214001 [18:19<20:24, 89.91it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103936/214001 [18:20<20:24, 89.91it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104000/214001 [18:20<20:45, 88.30it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104000/214001 [18:21<20:45, 88.30it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104064/214001 [18:21<20:32, 89.20it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104064/214001 [18:21<20:32, 89.20it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104128/214001 [18:21<20:12, 90.62it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104128/214001 [18:22<20:12, 90.62it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104192/214001 [18:22<20:09, 90.80it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104192/214001 [18:23<20:09, 90.80it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104256/214001 [18:23<19:57, 91.64it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104256/214001 [18:23<19:57, 91.64it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  49%|████▊     | 104320/214001 [18:23<19:40, 92.88it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104320/214001 [18:24<19:40, 92.88it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104384/214001 [18:24<19:43, 92.61it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104384/214001 [18:25<19:43, 92.61it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104448/214001 [18:25<19:44, 92.51it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104448/214001 [18:25<19:44, 92.51it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104512/214001 [18:25<19:48, 92.10it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104512/214001 [18:26<19:48, 92.10it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  49%|████▉     | 104576/214001 [18:26<20:26, 89.18it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104576/214001 [18:27<20:26, 89.18it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104640/214001 [18:27<20:25, 89.24it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104640/214001 [18:28<20:25, 89.24it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104704/214001 [18:28<20:01, 90.97it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104704/214001 [18:28<20:01, 90.97it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104768/214001 [18:28<19:55, 91.38it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104768/214001 [18:29<19:55, 91.38it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104832/214001 [18:29<19:49, 91.74it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104832/214001 [18:30<19:49, 91.74it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104896/214001 [18:30<19:33, 93.01it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104896/214001 [18:30<19:33, 93.01it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104960/214001 [18:30<19:38, 92.51it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104960/214001 [18:31<19:38, 92.51it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105024/214001 [18:31<19:32, 92.95it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105024/214001 [18:32<19:32, 92.95it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  49%|████▉     | 105088/214001 [18:32<19:21, 93.74it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105088/214001 [18:32<19:21, 93.74it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105152/214001 [18:32<19:37, 92.44it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105152/214001 [18:33<19:37, 92.44it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105216/214001 [18:33<19:41, 92.09it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105216/214001 [18:34<19:41, 92.09it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105280/214001 [18:34<19:39, 92.20it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105280/214001 [18:35<19:39, 92.20it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105344/214001 [18:35<19:47, 91.53it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105344/214001 [18:35<19:47, 91.53it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105408/214001 [18:35<19:52, 91.07it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105408/214001 [18:36<19:52, 91.07it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105472/214001 [18:36<19:48, 91.29it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105472/214001 [18:37<19:48, 91.29it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105536/214001 [18:37<19:39, 91.95it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105536/214001 [18:37<19:39, 91.95it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105600/214001 [18:37<19:37, 92.08it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105600/214001 [18:38<19:37, 92.08it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105664/214001 [18:38<19:42, 91.63it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105664/214001 [18:39<19:42, 91.63it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105728/214001 [18:39<19:40, 91.74it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105728/214001 [18:39<19:40, 91.74it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105792/214001 [18:39<19:25, 92.84it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105792/214001 [18:40<19:25, 92.84it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  49%|████▉     | 105856/214001 [18:40<19:28, 92.57it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105856/214001 [18:41<19:28, 92.57it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105920/214001 [18:41<19:38, 91.72it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105920/214001 [18:42<19:38, 91.72it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 105984/214001 [18:42<19:58, 90.12it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 105984/214001 [18:42<19:58, 90.12it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106048/214001 [18:42<20:04, 89.65it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106048/214001 [18:43<20:04, 89.65it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106112/214001 [18:43<20:14, 88.82it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106112/214001 [18:44<20:14, 88.82it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106176/214001 [18:44<19:56, 90.13it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106176/214001 [18:44<19:56, 90.13it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106240/214001 [18:44<20:08, 89.17it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106240/214001 [18:45<20:08, 89.17it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106304/214001 [18:45<19:54, 90.17it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106304/214001 [18:46<19:54, 90.17it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  50%|████▉     | 106368/214001 [18:46<20:01, 89.57it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106368/214001 [18:47<20:01, 89.57it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106432/214001 [18:47<20:07, 89.07it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106432/214001 [18:47<20:07, 89.07it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106496/214001 [18:47<20:42, 86.50it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106496/214001 [18:48<20:42, 86.50it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106560/214001 [18:48<20:38, 86.74it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106560/214001 [18:49<20:38, 86.74it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106624/214001 [18:49<20:19, 88.02it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106624/214001 [18:49<20:19, 88.02it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106688/214001 [18:49<19:50, 90.15it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106688/214001 [18:50<19:50, 90.15it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106752/214001 [18:50<19:57, 89.55it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106752/214001 [18:51<19:57, 89.55it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106816/214001 [18:51<20:08, 88.67it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106816/214001 [18:52<20:08, 88.67it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106880/214001 [18:52<19:44, 90.45it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106880/214001 [18:52<19:44, 90.45it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106944/214001 [18:52<19:32, 91.29it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106944/214001 [18:53<19:32, 91.29it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107008/214001 [18:53<19:32, 91.25it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107008/214001 [18:54<19:32, 91.25it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107072/214001 [18:54<19:26, 91.63it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107072/214001 [18:54<19:26, 91.63it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107136/214001 [18:54<19:39, 90.58it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107136/214001 [18:55<19:39, 90.58it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107200/214001 [18:55<19:26, 91.54it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107200/214001 [18:56<19:26, 91.54it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107264/214001 [18:56<19:14, 92.46it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107264/214001 [18:56<19:14, 92.46it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107328/214001 [18:56<19:17, 92.20it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107328/214001 [18:57<19:17, 92.20it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107392/214001 [18:57<19:09, 92.73it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107392/214001 [18:58<19:09, 92.73it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107456/214001 [18:58<19:34, 90.73it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107456/214001 [18:59<19:34, 90.73it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107520/214001 [18:59<19:38, 90.39it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107520/214001 [18:59<19:38, 90.39it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107584/214001 [18:59<19:46, 89.68it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107584/214001 [19:00<19:46, 89.68it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107648/214001 [19:00<19:47, 89.55it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107648/214001 [19:01<19:47, 89.55it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107712/214001 [19:01<19:28, 90.98it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107712/214001 [19:01<19:28, 90.98it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107776/214001 [19:01<19:24, 91.24it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107776/214001 [19:02<19:24, 91.24it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107840/214001 [19:02<19:35, 90.27it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107840/214001 [19:03<19:35, 90.27it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107904/214001 [19:03<19:19, 91.48it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107904/214001 [19:04<19:19, 91.48it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107968/214001 [19:04<19:32, 90.40it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107968/214001 [19:04<19:32, 90.40it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 108032/214001 [19:04<20:04, 87.98it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  50%|█████     | 108032/214001 [19:05<20:04, 87.98it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108096/214001 [19:05<20:38, 85.50it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108096/214001 [19:06<20:38, 85.50it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108160/214001 [19:06<22:27, 78.55it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108160/214001 [19:07<22:27, 78.55it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108224/214001 [19:07<22:05, 79.79it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108224/214001 [19:08<22:05, 79.79it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108288/214001 [19:08<21:19, 82.61it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108288/214001 [19:08<21:19, 82.61it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108352/214001 [19:08<21:09, 83.23it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108352/214001 [19:09<21:09, 83.23it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108416/214001 [19:09<21:34, 81.55it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108416/214001 [19:10<21:34, 81.55it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108480/214001 [19:10<21:17, 82.60it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108480/214001 [19:11<21:17, 82.60it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108544/214001 [19:11<20:49, 84.41it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108544/214001 [19:11<20:49, 84.41it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108608/214001 [19:11<20:25, 85.99it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108608/214001 [19:12<20:25, 85.99it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108672/214001 [19:12<20:10, 87.01it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108672/214001 [19:13<20:10, 87.01it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108736/214001 [19:13<20:12, 86.81it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108736/214001 [19:13<20:12, 86.81it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108800/214001 [19:14<20:02, 87.47it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108800/214001 [19:14<20:02, 87.47it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108864/214001 [19:14<19:55, 87.96it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108864/214001 [19:15<19:55, 87.96it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108928/214001 [19:15<19:56, 87.83it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108928/214001 [19:16<19:56, 87.83it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108992/214001 [19:16<19:39, 89.02it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 108992/214001 [19:16<19:39, 89.02it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109056/214001 [19:16<19:21, 90.35it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109056/214001 [19:17<19:21, 90.35it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109120/214001 [19:17<19:20, 90.35it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109120/214001 [19:18<19:20, 90.35it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109184/214001 [19:18<19:19, 90.40it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109184/214001 [19:18<19:19, 90.40it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109248/214001 [19:18<19:08, 91.23it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109248/214001 [19:19<19:08, 91.23it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109312/214001 [19:19<18:53, 92.36it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109312/214001 [19:20<18:53, 92.36it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109376/214001 [19:20<18:49, 92.60it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109376/214001 [19:20<18:49, 92.60it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109440/214001 [19:20<18:46, 92.81it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109440/214001 [19:21<18:46, 92.81it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109504/214001 [19:21<19:07, 91.08it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109504/214001 [19:22<19:07, 91.08it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109568/214001 [19:22<19:21, 89.89it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109568/214001 [19:23<19:21, 89.89it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109632/214001 [19:23<19:17, 90.16it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████     | 109632/214001 [19:23<19:17, 90.16it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109696/214001 [19:23<19:03, 91.24it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109696/214001 [19:24<19:03, 91.24it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109760/214001 [19:24<18:59, 91.47it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109760/214001 [19:25<18:59, 91.47it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109824/214001 [19:25<19:05, 90.94it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109824/214001 [19:25<19:05, 90.94it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109888/214001 [19:25<18:59, 91.41it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109888/214001 [19:26<18:59, 91.41it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109952/214001 [19:26<18:59, 91.32it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 109952/214001 [19:27<18:59, 91.32it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110016/214001 [19:27<18:53, 91.71it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110016/214001 [19:27<18:53, 91.71it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110080/214001 [19:28<18:44, 92.43it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110080/214001 [19:28<18:44, 92.43it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110144/214001 [19:28<18:56, 91.34it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110144/214001 [19:29<18:56, 91.34it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110208/214001 [19:29<18:50, 91.79it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 110208/214001 [19:30<18:50, 91.79it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110272/214001 [19:30<18:39, 92.65it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110272/214001 [19:30<18:39, 92.65it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110336/214001 [19:30<18:41, 92.47it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110336/214001 [19:31<18:41, 92.47it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110400/214001 [19:31<18:45, 92.08it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110400/214001 [19:32<18:45, 92.08it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110464/214001 [19:32<18:52, 91.40it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110464/214001 [19:32<18:52, 91.40it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110528/214001 [19:32<18:54, 91.21it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110528/214001 [19:33<18:54, 91.21it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110592/214001 [19:33<18:58, 90.81it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110592/214001 [19:34<18:58, 90.81it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110656/214001 [19:34<18:50, 91.40it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110656/214001 [19:34<18:50, 91.40it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110720/214001 [19:35<18:48, 91.51it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110720/214001 [19:35<18:48, 91.51it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110784/214001 [19:35<18:55, 90.91it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110784/214001 [19:36<18:55, 90.91it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110848/214001 [19:36<18:52, 91.05it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110848/214001 [19:37<18:52, 91.05it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110912/214001 [19:37<18:47, 91.46it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110912/214001 [19:37<18:47, 91.46it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110976/214001 [19:37<18:54, 90.81it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 110976/214001 [19:38<18:54, 90.81it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111040/214001 [19:38<18:55, 90.66it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111040/214001 [19:39<18:55, 90.66it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111104/214001 [19:39<18:37, 92.04it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111104/214001 [19:39<18:37, 92.04it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111168/214001 [19:39<18:42, 91.60it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111168/214001 [19:40<18:42, 91.60it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111232/214001 [19:40<18:50, 90.92it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111232/214001 [19:41<18:50, 90.92it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111296/214001 [19:41<18:38, 91.81it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111296/214001 [19:41<18:38, 91.81it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111360/214001 [19:41<18:30, 92.39it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111360/214001 [19:42<18:30, 92.39it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111424/214001 [19:42<18:30, 92.34it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111424/214001 [19:43<18:30, 92.34it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111488/214001 [19:43<18:17, 93.44it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111488/214001 [19:44<18:17, 93.44it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111552/214001 [19:44<18:10, 93.93it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111552/214001 [19:44<18:10, 93.93it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111616/214001 [19:44<18:12, 93.70it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111616/214001 [19:45<18:12, 93.70it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111680/214001 [19:45<18:15, 93.42it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111680/214001 [19:46<18:15, 93.42it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111744/214001 [19:46<18:14, 93.44it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111744/214001 [19:46<18:14, 93.44it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111808/214001 [19:46<18:04, 94.21it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111808/214001 [19:47<18:04, 94.21it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111872/214001 [19:47<18:04, 94.16it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111872/214001 [19:48<18:04, 94.16it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111936/214001 [19:48<18:05, 94.03it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 111936/214001 [19:48<18:05, 94.03it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112000/214001 [19:48<18:05, 93.94it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112000/214001 [19:49<18:05, 93.94it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112064/214001 [19:49<18:09, 93.55it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112064/214001 [19:50<18:09, 93.55it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112128/214001 [19:50<18:10, 93.45it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112128/214001 [19:50<18:10, 93.45it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112192/214001 [19:50<18:03, 93.99it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112192/214001 [19:51<18:03, 93.99it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112256/214001 [19:51<18:01, 94.06it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112256/214001 [19:52<18:01, 94.06it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112320/214001 [19:52<17:57, 94.36it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 112320/214001 [19:52<17:57, 94.36it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112384/214001 [19:52<18:01, 93.94it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112384/214001 [19:53<18:01, 93.94it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112448/214001 [19:53<18:16, 92.64it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112448/214001 [19:54<18:16, 92.64it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112512/214001 [19:54<18:14, 92.74it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112512/214001 [19:54<18:14, 92.74it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112576/214001 [19:54<18:02, 93.67it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112576/214001 [19:55<18:02, 93.67it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112640/214001 [19:55<18:07, 93.21it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112640/214001 [19:56<18:07, 93.21it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112704/214001 [19:56<18:10, 92.87it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112704/214001 [19:57<18:10, 92.87it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112768/214001 [19:57<18:13, 92.59it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112768/214001 [19:57<18:13, 92.59it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112832/214001 [19:57<18:06, 93.11it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112832/214001 [19:58<18:06, 93.11it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112896/214001 [19:58<18:00, 93.57it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112896/214001 [19:59<18:00, 93.57it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112960/214001 [19:59<17:52, 94.23it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 112960/214001 [19:59<17:52, 94.23it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113024/214001 [19:59<17:52, 94.18it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113024/214001 [20:00<17:52, 94.18it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113088/214001 [20:00<17:55, 93.83it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113088/214001 [20:01<17:55, 93.83it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113152/214001 [20:01<17:49, 94.32it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113152/214001 [20:01<17:49, 94.32it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113216/214001 [20:01<18:01, 93.21it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113216/214001 [20:02<18:01, 93.21it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113280/214001 [20:02<17:57, 93.48it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113280/214001 [20:03<17:57, 93.48it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113344/214001 [20:03<17:57, 93.39it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113344/214001 [20:03<17:57, 93.39it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113408/214001 [20:03<18:05, 92.71it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113408/214001 [20:04<18:05, 92.71it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113472/214001 [20:04<17:54, 93.56it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113472/214001 [20:05<17:54, 93.56it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113536/214001 [20:05<17:53, 93.59it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113536/214001 [20:05<17:53, 93.59it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113600/214001 [20:05<17:55, 93.38it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113600/214001 [20:06<17:55, 93.38it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113664/214001 [20:06<17:47, 93.95it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113664/214001 [20:07<17:47, 93.95it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113728/214001 [20:07<17:43, 94.31it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113728/214001 [20:07<17:43, 94.31it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113792/214001 [20:07<17:54, 93.29it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113792/214001 [20:08<17:54, 93.29it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113856/214001 [20:08<17:48, 93.72it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113856/214001 [20:09<17:48, 93.72it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113920/214001 [20:09<17:43, 94.11it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113920/214001 [20:09<17:43, 94.11it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113984/214001 [20:10<17:45, 93.84it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 113984/214001 [20:10<17:45, 93.84it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114048/214001 [20:10<17:45, 93.77it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114048/214001 [20:11<17:45, 93.77it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114112/214001 [20:11<17:47, 93.56it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114112/214001 [20:12<17:47, 93.56it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114176/214001 [20:12<18:04, 92.02it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114176/214001 [20:12<18:04, 92.02it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114240/214001 [20:12<17:59, 92.39it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114240/214001 [20:13<17:59, 92.39it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114304/214001 [20:13<17:55, 92.71it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114304/214001 [20:14<17:55, 92.71it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114368/214001 [20:14<17:58, 92.41it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114368/214001 [20:14<17:58, 92.41it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114432/214001 [20:14<18:06, 91.67it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 114432/214001 [20:15<18:06, 91.67it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114496/214001 [20:15<18:04, 91.78it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114496/214001 [20:16<18:04, 91.78it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114560/214001 [20:16<18:00, 92.02it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114560/214001 [20:16<18:00, 92.02it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114624/214001 [20:16<17:48, 92.99it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114624/214001 [20:17<17:48, 92.99it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114688/214001 [20:17<17:46, 93.08it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114688/214001 [20:18<17:46, 93.08it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114752/214001 [20:18<17:51, 92.63it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114752/214001 [20:19<17:51, 92.63it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114816/214001 [20:19<17:51, 92.52it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114816/214001 [20:19<17:51, 92.52it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114880/214001 [20:19<17:44, 93.07it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114880/214001 [20:20<17:44, 93.07it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114944/214001 [20:20<17:50, 92.50it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 114944/214001 [20:21<17:50, 92.50it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 115008/214001 [20:21<18:06, 91.14it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 115008/214001 [20:21<18:06, 91.14it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115072/214001 [20:21<18:31, 89.00it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115072/214001 [20:22<18:31, 89.00it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115136/214001 [20:22<18:49, 87.55it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115136/214001 [20:23<18:49, 87.55it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115200/214001 [20:23<18:32, 88.84it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115200/214001 [20:24<18:32, 88.84it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115264/214001 [20:24<18:18, 89.88it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115264/214001 [20:24<18:18, 89.88it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115328/214001 [20:24<18:05, 90.89it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115328/214001 [20:25<18:05, 90.89it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115392/214001 [20:25<18:01, 91.20it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115392/214001 [20:26<18:01, 91.20it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115456/214001 [20:26<17:59, 91.25it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115456/214001 [20:26<17:59, 91.25it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115520/214001 [20:26<17:53, 91.75it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115520/214001 [20:27<17:53, 91.75it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115584/214001 [20:27<17:56, 91.44it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115584/214001 [20:28<17:56, 91.44it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115648/214001 [20:28<17:48, 92.02it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115648/214001 [20:28<17:48, 92.02it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115712/214001 [20:28<17:40, 92.66it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115712/214001 [20:29<17:40, 92.66it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115776/214001 [20:29<17:40, 92.61it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115776/214001 [20:30<17:40, 92.61it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115840/214001 [20:30<17:29, 93.57it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115840/214001 [20:30<17:29, 93.57it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115904/214001 [20:30<17:20, 94.24it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115904/214001 [20:31<17:20, 94.24it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115968/214001 [20:31<17:29, 93.38it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 115968/214001 [20:32<17:29, 93.38it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116032/214001 [20:32<17:27, 93.57it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116032/214001 [20:32<17:27, 93.57it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116096/214001 [20:32<17:16, 94.42it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116096/214001 [20:33<17:16, 94.42it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116160/214001 [20:33<17:12, 94.79it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116160/214001 [20:34<17:12, 94.79it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116224/214001 [20:34<17:15, 94.41it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116224/214001 [20:34<17:15, 94.41it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116288/214001 [20:34<17:18, 94.05it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116288/214001 [20:35<17:18, 94.05it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116352/214001 [20:35<17:31, 92.82it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116352/214001 [20:36<17:31, 92.82it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116416/214001 [20:36<17:36, 92.36it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116416/214001 [20:37<17:36, 92.36it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116480/214001 [20:37<17:28, 93.01it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116480/214001 [20:37<17:28, 93.01it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116544/214001 [20:37<17:31, 92.72it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116544/214001 [20:38<17:31, 92.72it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116608/214001 [20:38<17:33, 92.41it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 116608/214001 [20:39<17:33, 92.41it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116672/214001 [20:39<17:38, 91.98it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116672/214001 [20:39<17:38, 91.98it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116736/214001 [20:39<17:32, 92.37it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116736/214001 [20:40<17:32, 92.37it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116800/214001 [20:40<17:24, 93.07it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116800/214001 [20:41<17:24, 93.07it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116864/214001 [20:41<17:21, 93.29it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116864/214001 [20:41<17:21, 93.29it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116928/214001 [20:41<17:37, 91.79it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116928/214001 [20:42<17:37, 91.79it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116992/214001 [20:42<17:55, 90.21it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 116992/214001 [20:43<17:55, 90.21it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117056/214001 [20:43<17:52, 90.39it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117056/214001 [20:44<17:52, 90.39it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117120/214001 [20:44<17:55, 90.08it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117120/214001 [20:44<17:55, 90.08it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117184/214001 [20:44<17:41, 91.21it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117184/214001 [20:45<17:41, 91.21it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117248/214001 [20:45<17:36, 91.59it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117248/214001 [20:46<17:36, 91.59it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117312/214001 [20:46<17:32, 91.86it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117312/214001 [20:46<17:32, 91.86it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117376/214001 [20:46<17:33, 91.70it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117376/214001 [20:47<17:33, 91.70it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117440/214001 [20:47<17:31, 91.82it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117440/214001 [20:48<17:31, 91.82it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117504/214001 [20:48<17:31, 91.79it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117504/214001 [20:48<17:31, 91.79it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117568/214001 [20:48<17:20, 92.70it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117568/214001 [20:49<17:20, 92.70it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117632/214001 [20:49<17:12, 93.37it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117632/214001 [20:50<17:12, 93.37it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117696/214001 [20:50<17:08, 93.61it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 117696/214001 [20:50<17:08, 93.61it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117760/214001 [20:50<17:19, 92.55it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117760/214001 [20:51<17:19, 92.55it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117824/214001 [20:51<17:27, 91.83it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117824/214001 [20:52<17:27, 91.83it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117888/214001 [20:52<17:30, 91.50it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117888/214001 [20:53<17:30, 91.50it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117952/214001 [20:53<17:22, 92.16it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 117952/214001 [20:53<17:22, 92.16it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118016/214001 [20:53<17:21, 92.18it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118016/214001 [20:54<17:21, 92.18it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118080/214001 [20:54<17:22, 92.04it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118080/214001 [20:55<17:22, 92.04it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118144/214001 [20:55<17:20, 92.11it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118144/214001 [20:55<17:20, 92.11it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118208/214001 [20:55<17:21, 91.95it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118208/214001 [20:56<17:21, 91.95it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118272/214001 [20:56<17:22, 91.85it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118272/214001 [20:57<17:22, 91.85it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118336/214001 [20:57<17:17, 92.25it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118336/214001 [20:57<17:17, 92.25it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118400/214001 [20:57<17:09, 92.83it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118400/214001 [20:58<17:09, 92.83it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118464/214001 [20:58<17:05, 93.17it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118464/214001 [20:59<17:05, 93.17it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118528/214001 [20:59<17:13, 92.42it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118528/214001 [21:00<17:13, 92.42it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118592/214001 [21:00<17:13, 92.32it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118592/214001 [21:00<17:13, 92.32it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118656/214001 [21:00<16:58, 93.57it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118656/214001 [21:01<16:58, 93.57it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118720/214001 [21:01<16:48, 94.46it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 118720/214001 [21:02<16:48, 94.46it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118784/214001 [21:02<16:51, 94.16it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118784/214001 [21:02<16:51, 94.16it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118848/214001 [21:02<16:54, 93.77it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118848/214001 [21:03<16:54, 93.77it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118912/214001 [21:03<17:02, 92.96it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118912/214001 [21:04<17:02, 92.96it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118976/214001 [21:04<17:09, 92.31it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 118976/214001 [21:04<17:09, 92.31it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119040/214001 [21:04<17:15, 91.67it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119040/214001 [21:05<17:15, 91.67it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119104/214001 [21:05<17:19, 91.29it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119104/214001 [21:06<17:19, 91.29it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119168/214001 [21:06<17:13, 91.72it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119168/214001 [21:06<17:13, 91.72it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119232/214001 [21:06<17:06, 92.29it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119232/214001 [21:07<17:06, 92.29it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119296/214001 [21:07<17:11, 91.82it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119296/214001 [21:08<17:11, 91.82it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119360/214001 [21:08<17:10, 91.86it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119360/214001 [21:09<17:10, 91.86it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119424/214001 [21:09<17:10, 91.81it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119424/214001 [21:09<17:10, 91.81it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119488/214001 [21:09<17:04, 92.29it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119488/214001 [21:10<17:04, 92.29it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119552/214001 [21:10<17:03, 92.31it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119552/214001 [21:11<17:03, 92.31it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119616/214001 [21:11<16:56, 92.81it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119616/214001 [21:11<16:56, 92.81it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119680/214001 [21:11<16:54, 93.01it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119680/214001 [21:12<16:54, 93.01it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119744/214001 [21:12<17:01, 92.29it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119744/214001 [21:13<17:01, 92.29it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119808/214001 [21:13<17:17, 90.79it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119808/214001 [21:13<17:17, 90.79it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119872/214001 [21:13<17:03, 91.96it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119872/214001 [21:14<17:03, 91.96it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119936/214001 [21:14<17:08, 91.42it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 119936/214001 [21:15<17:08, 91.42it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120000/214001 [21:15<16:59, 92.17it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120000/214001 [21:15<16:59, 92.17it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120064/214001 [21:16<17:23, 90.00it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120064/214001 [21:16<17:23, 90.00it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120128/214001 [21:16<17:18, 90.38it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120128/214001 [21:17<17:18, 90.38it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120192/214001 [21:17<17:03, 91.66it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120192/214001 [21:18<17:03, 91.66it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120256/214001 [21:18<16:58, 92.06it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120256/214001 [21:18<16:58, 92.06it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120320/214001 [21:18<17:00, 91.80it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 120320/214001 [21:19<17:00, 91.80it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120384/214001 [21:19<17:06, 91.22it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120384/214001 [21:20<17:06, 91.22it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120448/214001 [21:20<17:01, 91.58it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120448/214001 [21:20<17:01, 91.58it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120512/214001 [21:20<16:55, 92.04it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120512/214001 [21:21<16:55, 92.04it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120576/214001 [21:21<16:47, 92.76it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120576/214001 [21:22<16:47, 92.76it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120640/214001 [21:22<16:48, 92.56it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120640/214001 [21:22<16:48, 92.56it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120704/214001 [21:22<16:38, 93.45it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120704/214001 [21:23<16:38, 93.45it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120768/214001 [21:23<16:36, 93.51it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120768/214001 [21:24<16:36, 93.51it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120832/214001 [21:24<16:44, 92.74it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120832/214001 [21:24<16:44, 92.74it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120896/214001 [21:24<16:47, 92.41it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 120896/214001 [21:25<16:47, 92.41it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 120960/214001 [21:25<16:40, 92.96it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 120960/214001 [21:26<16:40, 92.96it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121024/214001 [21:26<16:41, 92.85it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121024/214001 [21:27<16:41, 92.85it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121088/214001 [21:27<16:52, 91.78it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121088/214001 [21:27<16:52, 91.78it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121152/214001 [21:27<16:47, 92.13it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121152/214001 [21:28<16:47, 92.13it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121216/214001 [21:28<16:46, 92.19it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121216/214001 [21:29<16:46, 92.19it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121280/214001 [21:29<16:38, 92.81it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121280/214001 [21:29<16:38, 92.81it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121344/214001 [21:29<16:43, 92.34it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121344/214001 [21:30<16:43, 92.34it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121408/214001 [21:30<16:42, 92.37it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121408/214001 [21:31<16:42, 92.37it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121472/214001 [21:31<16:53, 91.28it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121472/214001 [21:31<16:53, 91.28it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121536/214001 [21:31<16:46, 91.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121536/214001 [21:32<16:46, 91.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121600/214001 [21:32<16:49, 91.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121600/214001 [21:33<16:49, 91.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121664/214001 [21:33<16:38, 92.46it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121664/214001 [21:34<16:38, 92.46it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121728/214001 [21:34<16:39, 92.32it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121728/214001 [21:34<16:39, 92.32it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121792/214001 [21:34<16:55, 90.81it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121792/214001 [21:35<16:55, 90.81it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121856/214001 [21:35<16:58, 90.49it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121856/214001 [21:36<16:58, 90.49it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121920/214001 [21:36<16:54, 90.77it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121920/214001 [21:36<16:54, 90.77it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121984/214001 [21:36<16:42, 91.77it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 121984/214001 [21:37<16:42, 91.77it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122048/214001 [21:37<16:37, 92.21it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122048/214001 [21:38<16:37, 92.21it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122112/214001 [21:38<16:27, 93.10it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122112/214001 [21:38<16:27, 93.10it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122176/214001 [21:38<16:39, 91.91it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122176/214001 [21:39<16:39, 91.91it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122240/214001 [21:39<16:34, 92.23it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122240/214001 [21:40<16:34, 92.23it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122304/214001 [21:40<16:30, 92.58it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122304/214001 [21:40<16:30, 92.58it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122368/214001 [21:40<16:27, 92.83it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122368/214001 [21:41<16:27, 92.83it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122432/214001 [21:41<16:19, 93.46it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122432/214001 [21:42<16:19, 93.46it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122496/214001 [21:42<16:13, 93.99it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122496/214001 [21:42<16:13, 93.99it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122560/214001 [21:43<16:13, 93.93it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122560/214001 [21:43<16:13, 93.93it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122624/214001 [21:43<16:09, 94.27it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122624/214001 [21:44<16:09, 94.27it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122688/214001 [21:44<16:24, 92.74it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122688/214001 [21:45<16:24, 92.74it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122752/214001 [21:45<16:23, 92.77it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122752/214001 [21:45<16:23, 92.77it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122816/214001 [21:45<16:13, 93.66it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122816/214001 [21:46<16:13, 93.66it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122880/214001 [21:46<16:16, 93.33it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122880/214001 [21:47<16:16, 93.33it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122944/214001 [21:47<16:15, 93.31it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 122944/214001 [21:47<16:15, 93.31it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 123008/214001 [21:47<16:19, 92.91it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 123008/214001 [21:48<16:19, 92.91it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123072/214001 [21:48<16:10, 93.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123072/214001 [21:49<16:10, 93.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123136/214001 [21:49<16:19, 92.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123136/214001 [21:49<16:19, 92.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123200/214001 [21:49<16:20, 92.61it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123200/214001 [21:50<16:20, 92.61it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123264/214001 [21:50<16:27, 91.88it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123264/214001 [21:51<16:27, 91.88it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123328/214001 [21:51<16:18, 92.65it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123328/214001 [21:51<16:18, 92.65it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123392/214001 [21:51<16:13, 93.10it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123392/214001 [21:52<16:13, 93.10it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123456/214001 [21:52<16:11, 93.24it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123456/214001 [21:53<16:11, 93.24it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123520/214001 [21:53<16:08, 93.38it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123520/214001 [21:54<16:08, 93.38it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123584/214001 [21:54<16:07, 93.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123584/214001 [21:54<16:07, 93.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123648/214001 [21:54<16:03, 93.74it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123648/214001 [21:55<16:03, 93.74it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123712/214001 [21:55<16:00, 93.99it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123712/214001 [21:56<16:00, 93.99it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123776/214001 [21:56<15:59, 94.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123776/214001 [21:56<15:59, 94.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123840/214001 [21:56<16:04, 93.46it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123840/214001 [21:57<16:04, 93.46it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123904/214001 [21:57<16:14, 92.48it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123904/214001 [21:58<16:14, 92.48it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123968/214001 [21:58<16:16, 92.21it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 123968/214001 [21:58<16:16, 92.21it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124032/214001 [21:58<16:08, 92.89it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124032/214001 [21:59<16:08, 92.89it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124096/214001 [21:59<16:12, 92.48it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124096/214001 [22:00<16:12, 92.48it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124160/214001 [22:00<16:10, 92.62it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124160/214001 [22:00<16:10, 92.62it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124224/214001 [22:00<16:00, 93.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124224/214001 [22:01<16:00, 93.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124288/214001 [22:01<16:03, 93.14it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124288/214001 [22:02<16:03, 93.14it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124352/214001 [22:02<16:13, 92.10it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124352/214001 [22:02<16:13, 92.10it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124416/214001 [22:02<16:01, 93.15it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124416/214001 [22:03<16:01, 93.15it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124480/214001 [22:03<16:01, 93.08it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124480/214001 [22:04<16:01, 93.08it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124544/214001 [22:04<16:01, 93.03it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124544/214001 [22:04<16:01, 93.03it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124608/214001 [22:05<15:54, 93.64it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124608/214001 [22:05<15:54, 93.64it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124672/214001 [22:05<15:58, 93.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124672/214001 [22:06<15:58, 93.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124736/214001 [22:06<15:55, 93.40it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124736/214001 [22:07<15:55, 93.40it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124800/214001 [22:07<16:04, 92.46it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124800/214001 [22:07<16:04, 92.46it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124864/214001 [22:07<16:14, 91.50it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124864/214001 [22:08<16:14, 91.50it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124928/214001 [22:08<16:10, 91.78it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124928/214001 [22:09<16:10, 91.78it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124992/214001 [22:09<16:08, 91.94it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 124992/214001 [22:09<16:08, 91.94it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 125056/214001 [22:09<16:06, 92.04it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 125056/214001 [22:10<16:06, 92.04it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 125120/214001 [22:10<16:03, 92.27it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 125120/214001 [22:11<16:03, 92.27it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 125184/214001 [22:11<15:59, 92.53it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 125184/214001 [22:11<15:59, 92.53it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125248/214001 [22:11<16:12, 91.30it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125248/214001 [22:12<16:12, 91.30it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125312/214001 [22:12<16:24, 90.10it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125312/214001 [22:13<16:24, 90.10it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125376/214001 [22:13<16:09, 91.38it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125376/214001 [22:14<16:09, 91.38it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125440/214001 [22:14<16:11, 91.18it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125440/214001 [22:14<16:11, 91.18it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125504/214001 [22:14<16:07, 91.47it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125504/214001 [22:15<16:07, 91.47it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125568/214001 [22:15<15:54, 92.62it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125568/214001 [22:16<15:54, 92.62it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125632/214001 [22:16<15:56, 92.43it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125632/214001 [22:16<15:56, 92.43it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125696/214001 [22:16<15:49, 92.96it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 125696/214001 [22:17<15:49, 92.96it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125760/214001 [22:17<15:46, 93.20it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125760/214001 [22:18<15:46, 93.20it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125824/214001 [22:18<16:10, 90.89it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125824/214001 [22:18<16:10, 90.89it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125888/214001 [22:18<16:10, 90.81it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125888/214001 [22:19<16:10, 90.81it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125952/214001 [22:19<16:03, 91.39it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 125952/214001 [22:20<16:03, 91.39it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126016/214001 [22:20<16:05, 91.13it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126016/214001 [22:21<16:05, 91.13it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126080/214001 [22:21<16:06, 90.96it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126080/214001 [22:21<16:06, 90.96it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126144/214001 [22:21<15:52, 92.26it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126144/214001 [22:22<15:52, 92.26it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126208/214001 [22:22<15:52, 92.15it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126208/214001 [22:23<15:52, 92.15it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126272/214001 [22:23<15:51, 92.21it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126272/214001 [22:23<15:51, 92.21it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126336/214001 [22:23<15:45, 92.73it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126336/214001 [22:24<15:45, 92.73it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126400/214001 [22:24<15:47, 92.46it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126400/214001 [22:25<15:47, 92.46it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126464/214001 [22:25<15:46, 92.46it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126464/214001 [22:25<15:46, 92.46it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126528/214001 [22:25<15:47, 92.33it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126528/214001 [22:26<15:47, 92.33it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126592/214001 [22:26<15:51, 91.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126592/214001 [22:27<15:51, 91.84it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126656/214001 [22:27<15:48, 92.09it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126656/214001 [22:27<15:48, 92.09it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126720/214001 [22:27<15:38, 92.98it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126720/214001 [22:28<15:38, 92.98it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126784/214001 [22:28<15:41, 92.67it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126784/214001 [22:29<15:41, 92.67it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126848/214001 [22:29<15:37, 92.98it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126848/214001 [22:30<15:37, 92.98it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126912/214001 [22:30<15:31, 93.48it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126912/214001 [22:30<15:31, 93.48it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126976/214001 [22:30<15:31, 93.43it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 126976/214001 [22:31<15:31, 93.43it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127040/214001 [22:31<15:35, 92.98it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127040/214001 [22:32<15:35, 92.98it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127104/214001 [22:32<15:30, 93.34it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127104/214001 [22:32<15:30, 93.34it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127168/214001 [22:32<15:32, 93.13it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127168/214001 [22:33<15:32, 93.13it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127232/214001 [22:33<15:35, 92.80it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127232/214001 [22:34<15:35, 92.80it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127296/214001 [22:34<15:30, 93.19it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 127296/214001 [22:34<15:30, 93.19it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127360/214001 [22:34<15:41, 92.01it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127360/214001 [22:35<15:41, 92.01it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127424/214001 [22:35<15:39, 92.11it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127424/214001 [22:36<15:39, 92.11it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127488/214001 [22:36<15:40, 91.96it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127488/214001 [22:36<15:40, 91.96it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127552/214001 [22:36<15:51, 90.83it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127552/214001 [22:37<15:51, 90.83it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127616/214001 [22:37<15:43, 91.60it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127616/214001 [22:38<15:43, 91.60it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127680/214001 [22:38<15:29, 92.90it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127680/214001 [22:39<15:29, 92.90it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127744/214001 [22:39<15:27, 93.04it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127744/214001 [22:39<15:27, 93.04it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127808/214001 [22:39<15:28, 92.79it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127808/214001 [22:40<15:28, 92.79it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127872/214001 [22:40<15:33, 92.28it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127872/214001 [22:41<15:33, 92.28it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127936/214001 [22:41<15:30, 92.54it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 127936/214001 [22:41<15:30, 92.54it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128000/214001 [22:41<15:21, 93.29it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128000/214001 [22:42<15:21, 93.29it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128064/214001 [22:42<15:13, 94.06it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128064/214001 [22:43<15:13, 94.06it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128128/214001 [22:43<15:20, 93.27it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128128/214001 [22:43<15:20, 93.27it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128192/214001 [22:43<15:21, 93.09it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128192/214001 [22:44<15:21, 93.09it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128256/214001 [22:44<15:23, 92.87it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128256/214001 [22:45<15:23, 92.87it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128320/214001 [22:45<15:19, 93.18it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128320/214001 [22:45<15:19, 93.18it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128384/214001 [22:45<15:22, 92.76it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 128384/214001 [22:46<15:22, 92.76it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128448/214001 [22:46<15:21, 92.83it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128448/214001 [22:47<15:21, 92.83it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128512/214001 [22:47<15:23, 92.55it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128512/214001 [22:48<15:23, 92.55it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128576/214001 [22:48<15:31, 91.69it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128576/214001 [22:48<15:31, 91.69it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128640/214001 [22:48<15:28, 91.95it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128640/214001 [22:49<15:28, 91.95it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128704/214001 [22:49<15:29, 91.78it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128704/214001 [22:50<15:29, 91.78it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128768/214001 [22:50<15:24, 92.24it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128768/214001 [22:50<15:24, 92.24it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128832/214001 [22:50<15:15, 93.00it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128832/214001 [22:51<15:15, 93.00it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128896/214001 [22:51<15:24, 92.01it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128896/214001 [22:52<15:24, 92.01it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128960/214001 [22:52<15:23, 92.05it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 128960/214001 [22:52<15:23, 92.05it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129024/214001 [22:52<15:17, 92.58it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129024/214001 [22:53<15:17, 92.58it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  60%|██████    | 129088/214001 [22:53<15:17, 92.59it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129088/214001 [22:54<15:17, 92.59it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129152/214001 [22:54<15:09, 93.29it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129152/214001 [22:54<15:09, 93.29it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129216/214001 [22:54<15:05, 93.67it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129216/214001 [22:55<15:05, 93.67it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129280/214001 [22:55<15:03, 93.74it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129280/214001 [22:56<15:03, 93.74it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129344/214001 [22:56<15:00, 93.98it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129344/214001 [22:56<15:00, 93.98it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129408/214001 [22:56<14:51, 94.85it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  60%|██████    | 129408/214001 [22:57<14:51, 94.85it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129472/214001 [22:57<14:58, 94.03it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129472/214001 [22:58<14:58, 94.03it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  61%|██████    | 129536/214001 [22:58<14:58, 94.00it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129536/214001 [22:58<14:58, 94.00it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129600/214001 [22:58<14:57, 94.01it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129600/214001 [22:59<14:57, 94.01it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129664/214001 [22:59<14:59, 93.81it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129664/214001 [23:00<14:59, 93.81it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129728/214001 [23:00<14:53, 94.29it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129728/214001 [23:00<14:53, 94.29it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129792/214001 [23:00<14:47, 94.93it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129792/214001 [23:01<14:47, 94.93it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129856/214001 [23:01<14:45, 95.02it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129856/214001 [23:02<14:45, 95.02it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  61%|██████    | 129920/214001 [23:02<14:47, 94.75it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129920/214001 [23:03<14:47, 94.75it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129984/214001 [23:03<14:53, 94.02it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 129984/214001 [23:03<14:53, 94.02it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130048/214001 [23:03<14:59, 93.33it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130048/214001 [23:04<14:59, 93.33it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130112/214001 [23:04<14:59, 93.21it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130112/214001 [23:05<14:59, 93.21it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130176/214001 [23:05<14:56, 93.50it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130176/214001 [23:05<14:56, 93.50it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130240/214001 [23:05<15:07, 92.28it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130240/214001 [23:06<15:07, 92.28it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  61%|██████    | 130304/214001 [23:06<15:19, 91.05it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130304/214001 [23:07<15:19, 91.05it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130368/214001 [23:07<15:09, 91.97it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130368/214001 [23:07<15:09, 91.97it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130432/214001 [23:07<15:20, 90.83it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130432/214001 [23:08<15:20, 90.83it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130496/214001 [23:08<15:20, 90.71it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130496/214001 [23:09<15:20, 90.71it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130560/214001 [23:09<15:16, 91.04it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130560/214001 [23:10<15:16, 91.04it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130624/214001 [23:10<15:20, 90.60it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130624/214001 [23:10<15:20, 90.60it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130688/214001 [23:10<15:10, 91.49it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130688/214001 [23:11<15:10, 91.49it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130752/214001 [23:11<15:03, 92.14it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130752/214001 [23:12<15:03, 92.14it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130816/214001 [23:12<15:04, 92.02it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130816/214001 [23:12<15:04, 92.02it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130880/214001 [23:12<14:55, 92.77it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130880/214001 [23:13<14:55, 92.77it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130944/214001 [23:13<14:45, 93.77it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 130944/214001 [23:14<14:45, 93.77it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 131008/214001 [23:14<14:37, 94.54it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 131008/214001 [23:14<14:37, 94.54it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 131072/214001 [23:14<14:37, 94.46it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████    | 131072/214001 [23:15<14:37, 94.46it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131136/214001 [23:15<14:43, 93.78it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131136/214001 [23:16<14:43, 93.78it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131200/214001 [23:16<14:43, 93.71it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131200/214001 [23:16<14:43, 93.71it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131264/214001 [23:16<14:46, 93.35it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131264/214001 [23:17<14:46, 93.35it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131328/214001 [23:17<14:51, 92.72it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131328/214001 [23:18<14:51, 92.72it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131392/214001 [23:18<15:04, 91.29it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131392/214001 [23:18<15:04, 91.29it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131456/214001 [23:19<15:02, 91.47it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131456/214001 [23:19<15:02, 91.47it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131520/214001 [23:19<15:00, 91.59it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131520/214001 [23:20<15:00, 91.59it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131584/214001 [23:20<14:50, 92.55it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 131584/214001 [23:21<14:50, 92.55it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131648/214001 [23:21<14:43, 93.17it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131648/214001 [23:21<14:43, 93.17it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131712/214001 [23:21<14:41, 93.35it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131712/214001 [23:22<14:41, 93.35it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131776/214001 [23:22<14:43, 93.07it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131776/214001 [23:23<14:43, 93.07it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131840/214001 [23:23<14:40, 93.26it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131840/214001 [23:23<14:40, 93.26it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131904/214001 [23:23<14:38, 93.42it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131904/214001 [23:24<14:38, 93.42it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131968/214001 [23:24<14:38, 93.36it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 131968/214001 [23:25<14:38, 93.36it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132032/214001 [23:25<14:34, 93.73it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132032/214001 [23:25<14:34, 93.73it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132096/214001 [23:25<14:32, 93.87it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132096/214001 [23:26<14:32, 93.87it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132160/214001 [23:26<14:39, 93.08it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132160/214001 [23:27<14:39, 93.08it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132224/214001 [23:27<14:38, 93.05it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132224/214001 [23:27<14:38, 93.05it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132288/214001 [23:27<14:44, 92.40it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132288/214001 [23:28<14:44, 92.40it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132352/214001 [23:28<14:48, 91.85it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132352/214001 [23:29<14:48, 91.85it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132416/214001 [23:29<14:47, 91.92it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132416/214001 [23:29<14:47, 91.92it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132480/214001 [23:30<14:37, 92.91it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132480/214001 [23:30<14:37, 92.91it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132544/214001 [23:30<14:38, 92.72it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132544/214001 [23:31<14:38, 92.72it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132608/214001 [23:31<14:40, 92.47it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132608/214001 [23:32<14:40, 92.47it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132672/214001 [23:32<14:39, 92.43it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132672/214001 [23:32<14:39, 92.43it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132736/214001 [23:32<14:42, 92.04it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132736/214001 [23:33<14:42, 92.04it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132800/214001 [23:33<14:41, 92.16it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132800/214001 [23:34<14:41, 92.16it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132864/214001 [23:34<14:37, 92.46it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132864/214001 [23:34<14:37, 92.46it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132928/214001 [23:34<14:45, 91.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132928/214001 [23:35<14:45, 91.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132992/214001 [23:35<14:50, 90.98it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 132992/214001 [23:36<14:50, 90.98it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133056/214001 [23:36<15:00, 89.94it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133056/214001 [23:37<15:00, 89.94it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133120/214001 [23:37<15:00, 89.80it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133120/214001 [23:37<15:00, 89.80it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133184/214001 [23:37<14:57, 90.06it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133184/214001 [23:38<14:57, 90.06it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133248/214001 [23:38<14:53, 90.41it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133248/214001 [23:39<14:53, 90.41it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133312/214001 [23:39<15:02, 89.41it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133312/214001 [23:39<15:02, 89.41it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133376/214001 [23:39<15:01, 89.41it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133376/214001 [23:40<15:01, 89.41it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133440/214001 [23:40<14:52, 90.30it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133440/214001 [23:41<14:52, 90.30it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133504/214001 [23:41<14:43, 91.15it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133504/214001 [23:41<14:43, 91.15it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133568/214001 [23:41<14:40, 91.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133568/214001 [23:42<14:40, 91.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133632/214001 [23:42<14:34, 91.93it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133632/214001 [23:43<14:34, 91.93it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133696/214001 [23:43<14:31, 92.14it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 133696/214001 [23:44<14:31, 92.14it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133760/214001 [23:44<14:45, 90.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133760/214001 [23:44<14:45, 90.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133824/214001 [23:44<14:39, 91.19it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133824/214001 [23:45<14:39, 91.19it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133888/214001 [23:45<14:33, 91.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133888/214001 [23:46<14:33, 91.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133952/214001 [23:46<14:25, 92.44it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 133952/214001 [23:46<14:25, 92.44it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134016/214001 [23:46<14:37, 91.14it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134016/214001 [23:47<14:37, 91.14it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134080/214001 [23:47<14:42, 90.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134080/214001 [23:48<14:42, 90.53it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134144/214001 [23:48<14:40, 90.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134144/214001 [23:49<14:40, 90.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134208/214001 [23:49<14:58, 88.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134208/214001 [23:49<14:58, 88.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134272/214001 [23:49<14:49, 89.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134272/214001 [23:50<14:49, 89.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134336/214001 [23:50<15:10, 87.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134336/214001 [23:51<15:10, 87.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134400/214001 [23:51<15:17, 86.76it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134400/214001 [23:51<15:17, 86.76it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134464/214001 [23:51<15:06, 87.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134464/214001 [23:52<15:06, 87.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134528/214001 [23:52<14:57, 88.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134528/214001 [23:53<14:57, 88.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134592/214001 [23:53<14:55, 88.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134592/214001 [23:54<14:55, 88.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134656/214001 [23:54<15:04, 87.71it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134656/214001 [23:54<15:04, 87.71it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134720/214001 [23:54<15:06, 87.48it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134720/214001 [23:55<15:06, 87.48it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134784/214001 [23:55<15:05, 87.44it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134784/214001 [23:56<15:05, 87.44it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134848/214001 [23:56<14:58, 88.14it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134848/214001 [23:57<14:58, 88.14it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134912/214001 [23:57<14:49, 88.89it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134912/214001 [23:57<14:49, 88.89it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134976/214001 [23:57<14:50, 88.71it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 134976/214001 [23:58<14:50, 88.71it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135040/214001 [23:58<14:55, 88.22it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135040/214001 [23:59<14:55, 88.22it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135104/214001 [23:59<15:10, 86.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135104/214001 [23:59<15:10, 86.67it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135168/214001 [23:59<15:04, 87.13it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135168/214001 [24:00<15:04, 87.13it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135232/214001 [24:00<14:48, 88.60it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135232/214001 [24:01<14:48, 88.60it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135296/214001 [24:01<14:33, 90.11it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135296/214001 [24:02<14:33, 90.11it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135360/214001 [24:02<14:37, 89.66it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135360/214001 [24:02<14:37, 89.66it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135424/214001 [24:02<14:47, 88.52it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135424/214001 [24:03<14:47, 88.52it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135488/214001 [24:03<14:42, 88.92it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135488/214001 [24:04<14:42, 88.92it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135552/214001 [24:04<14:28, 90.29it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135552/214001 [24:04<14:28, 90.29it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135616/214001 [24:04<14:26, 90.50it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135616/214001 [24:05<14:26, 90.50it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135680/214001 [24:05<14:18, 91.28it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135680/214001 [24:06<14:18, 91.28it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135744/214001 [24:06<14:12, 91.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135744/214001 [24:06<14:12, 91.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135808/214001 [24:06<14:07, 92.31it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135808/214001 [24:07<14:07, 92.31it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135872/214001 [24:07<14:04, 92.48it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 135872/214001 [24:08<14:04, 92.48it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 135936/214001 [24:08<13:54, 93.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 135936/214001 [24:09<13:54, 93.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136000/214001 [24:09<14:00, 92.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136000/214001 [24:09<14:00, 92.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136064/214001 [24:09<14:11, 91.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136064/214001 [24:10<14:11, 91.54it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136128/214001 [24:10<14:17, 90.81it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136128/214001 [24:11<14:17, 90.81it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136192/214001 [24:11<14:15, 90.93it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136192/214001 [24:11<14:15, 90.93it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136256/214001 [24:11<14:16, 90.77it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136256/214001 [24:12<14:16, 90.77it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136320/214001 [24:12<14:10, 91.36it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136320/214001 [24:13<14:10, 91.36it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136384/214001 [24:13<14:02, 92.16it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 136384/214001 [24:13<14:02, 92.16it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136448/214001 [24:13<14:07, 91.46it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136448/214001 [24:14<14:07, 91.46it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136512/214001 [24:14<14:03, 91.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136512/214001 [24:15<14:03, 91.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136576/214001 [24:15<14:11, 90.97it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136576/214001 [24:16<14:11, 90.97it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136640/214001 [24:16<14:08, 91.21it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136640/214001 [24:16<14:08, 91.21it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136704/214001 [24:16<14:04, 91.56it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136704/214001 [24:17<14:04, 91.56it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136768/214001 [24:17<14:22, 89.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136768/214001 [24:18<14:22, 89.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136832/214001 [24:18<14:20, 89.69it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136832/214001 [24:18<14:20, 89.69it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136896/214001 [24:18<14:17, 89.94it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136896/214001 [24:19<14:17, 89.94it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136960/214001 [24:19<14:05, 91.07it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 136960/214001 [24:20<14:05, 91.07it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137024/214001 [24:20<14:05, 91.05it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137024/214001 [24:21<14:05, 91.05it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137088/214001 [24:21<15:05, 84.94it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137088/214001 [24:22<15:05, 84.94it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137152/214001 [24:22<16:46, 76.37it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137152/214001 [24:23<16:46, 76.37it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137216/214001 [24:23<18:02, 70.92it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137216/214001 [24:24<18:02, 70.92it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137280/214001 [24:24<19:03, 67.11it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137280/214001 [24:25<19:03, 67.11it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137344/214001 [24:25<19:39, 64.96it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137344/214001 [24:26<19:39, 64.96it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137408/214001 [24:26<19:50, 64.36it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137408/214001 [24:27<19:50, 64.36it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137472/214001 [24:27<20:12, 63.13it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137472/214001 [24:28<20:12, 63.13it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137536/214001 [24:28<18:12, 70.00it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137536/214001 [24:28<18:12, 70.00it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137600/214001 [24:28<17:09, 74.24it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137600/214001 [24:29<17:09, 74.24it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137664/214001 [24:29<16:24, 77.50it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137664/214001 [24:30<16:24, 77.50it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137728/214001 [24:30<15:39, 81.21it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137728/214001 [24:31<15:39, 81.21it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137792/214001 [24:31<15:04, 84.26it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137792/214001 [24:31<15:04, 84.26it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137856/214001 [24:31<14:43, 86.22it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137856/214001 [24:32<14:43, 86.22it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137920/214001 [24:32<14:33, 87.14it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137920/214001 [24:33<14:33, 87.14it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137984/214001 [24:33<14:32, 87.16it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 137984/214001 [24:33<14:32, 87.16it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138048/214001 [24:33<14:18, 88.45it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138048/214001 [24:34<14:18, 88.45it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138112/214001 [24:34<14:02, 90.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138112/214001 [24:35<14:02, 90.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138176/214001 [24:35<13:52, 91.13it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138176/214001 [24:35<13:52, 91.13it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138240/214001 [24:35<13:49, 91.36it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138240/214001 [24:36<13:49, 91.36it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138304/214001 [24:36<13:58, 90.27it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138304/214001 [24:37<13:58, 90.27it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138368/214001 [24:37<13:57, 90.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138368/214001 [24:38<13:57, 90.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138432/214001 [24:38<13:47, 91.29it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138432/214001 [24:38<13:47, 91.29it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138496/214001 [24:38<13:41, 91.96it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138496/214001 [24:39<13:41, 91.96it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138560/214001 [24:39<13:36, 92.39it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138560/214001 [24:40<13:36, 92.39it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138624/214001 [24:40<13:42, 91.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138624/214001 [24:40<13:42, 91.64it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138688/214001 [24:40<13:37, 92.10it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138688/214001 [24:41<13:37, 92.10it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138752/214001 [24:41<13:30, 92.79it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138752/214001 [24:42<13:30, 92.79it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138816/214001 [24:42<13:35, 92.16it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138816/214001 [24:42<13:35, 92.16it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138880/214001 [24:42<13:45, 90.96it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138880/214001 [24:43<13:45, 90.96it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138944/214001 [24:43<13:41, 91.39it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 138944/214001 [24:44<13:41, 91.39it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 139008/214001 [24:44<13:37, 91.70it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 139008/214001 [24:45<13:37, 91.70it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 139072/214001 [24:45<13:41, 91.23it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 139072/214001 [24:45<13:41, 91.23it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139136/214001 [24:45<13:43, 90.95it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139136/214001 [24:46<13:43, 90.95it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139200/214001 [24:46<13:35, 91.70it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139200/214001 [24:47<13:35, 91.70it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139264/214001 [24:47<13:30, 92.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139264/214001 [24:47<13:30, 92.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139328/214001 [24:47<13:29, 92.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139328/214001 [24:48<13:29, 92.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139392/214001 [24:48<13:28, 92.32it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139392/214001 [24:49<13:28, 92.32it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139456/214001 [24:49<13:26, 92.40it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139456/214001 [24:49<13:26, 92.40it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139520/214001 [24:49<13:26, 92.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139520/214001 [24:50<13:26, 92.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139584/214001 [24:50<13:24, 92.47it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139584/214001 [24:51<13:24, 92.47it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139648/214001 [24:51<13:24, 92.39it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139648/214001 [24:51<13:24, 92.39it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139712/214001 [24:51<13:22, 92.62it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139712/214001 [24:52<13:22, 92.62it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139776/214001 [24:52<13:32, 91.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139776/214001 [24:53<13:32, 91.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139840/214001 [24:53<13:31, 91.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139840/214001 [24:54<13:31, 91.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139904/214001 [24:54<13:21, 92.40it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139904/214001 [24:54<13:21, 92.40it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139968/214001 [24:54<13:19, 92.65it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 139968/214001 [24:55<13:19, 92.65it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 140032/214001 [24:55<13:22, 92.19it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 140032/214001 [24:56<13:22, 92.19it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 140096/214001 [24:56<13:22, 92.10it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 140096/214001 [24:56<13:22, 92.10it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 140160/214001 [24:56<13:44, 89.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 140160/214001 [24:57<13:44, 89.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140224/214001 [24:57<13:46, 89.28it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140224/214001 [24:58<13:46, 89.28it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140288/214001 [24:58<13:34, 90.50it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140288/214001 [24:59<13:34, 90.50it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140352/214001 [24:59<13:31, 90.73it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140352/214001 [24:59<13:31, 90.73it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140416/214001 [24:59<13:39, 89.80it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140416/214001 [25:00<13:39, 89.80it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140480/214001 [25:00<13:49, 88.66it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140480/214001 [25:01<13:49, 88.66it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140544/214001 [25:01<13:50, 88.47it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140544/214001 [25:01<13:50, 88.47it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140608/214001 [25:01<13:49, 88.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140608/214001 [25:02<13:49, 88.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140672/214001 [25:02<13:57, 87.51it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140672/214001 [25:03<13:57, 87.51it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140736/214001 [25:03<13:47, 88.53it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140736/214001 [25:04<13:47, 88.53it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140800/214001 [25:04<13:41, 89.12it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140800/214001 [25:04<13:41, 89.12it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140864/214001 [25:04<13:40, 89.17it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140864/214001 [25:05<13:40, 89.17it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140928/214001 [25:05<13:29, 90.25it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140928/214001 [25:06<13:29, 90.25it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140992/214001 [25:06<13:26, 90.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 140992/214001 [25:06<13:26, 90.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141056/214001 [25:06<13:28, 90.25it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141056/214001 [25:07<13:28, 90.25it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141120/214001 [25:07<13:19, 91.20it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141120/214001 [25:08<13:19, 91.20it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141184/214001 [25:08<13:14, 91.61it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141184/214001 [25:08<13:14, 91.61it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141248/214001 [25:09<13:12, 91.83it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141248/214001 [25:09<13:12, 91.83it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141312/214001 [25:09<13:19, 90.88it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141312/214001 [25:10<13:19, 90.88it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141376/214001 [25:10<13:20, 90.73it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141376/214001 [25:11<13:20, 90.73it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141440/214001 [25:11<13:18, 90.82it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141440/214001 [25:11<13:18, 90.82it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141504/214001 [25:11<13:15, 91.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141504/214001 [25:12<13:15, 91.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141568/214001 [25:12<13:13, 91.28it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141568/214001 [25:13<13:13, 91.28it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141632/214001 [25:13<13:10, 91.60it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141632/214001 [25:13<13:10, 91.60it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141696/214001 [25:13<13:08, 91.66it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141696/214001 [25:14<13:08, 91.66it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141760/214001 [25:14<13:05, 91.99it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 141760/214001 [25:15<13:05, 91.99it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 141824/214001 [25:15<13:00, 92.51it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 141824/214001 [25:15<13:00, 92.51it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 141888/214001 [25:15<12:54, 93.14it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 141888/214001 [25:16<12:54, 93.14it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 141952/214001 [25:16<12:56, 92.84it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 141952/214001 [25:17<12:56, 92.84it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142016/214001 [25:17<12:54, 92.96it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142016/214001 [25:18<12:54, 92.96it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142080/214001 [25:18<12:51, 93.22it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142080/214001 [25:18<12:51, 93.22it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142144/214001 [25:18<12:50, 93.30it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142144/214001 [25:19<12:50, 93.30it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142208/214001 [25:19<13:00, 91.98it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142208/214001 [25:20<13:00, 91.98it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142272/214001 [25:20<12:59, 92.05it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 142272/214001 [25:20<12:59, 92.05it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142336/214001 [25:20<12:49, 93.08it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142336/214001 [25:21<12:49, 93.08it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142400/214001 [25:21<12:45, 93.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142400/214001 [25:22<12:45, 93.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142464/214001 [25:22<12:44, 93.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142464/214001 [25:22<12:44, 93.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142528/214001 [25:22<12:50, 92.76it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142528/214001 [25:23<12:50, 92.76it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142592/214001 [25:23<12:48, 92.90it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142592/214001 [25:24<12:48, 92.90it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142656/214001 [25:24<12:47, 92.92it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142656/214001 [25:24<12:47, 92.92it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142720/214001 [25:24<12:38, 93.94it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142720/214001 [25:25<12:38, 93.94it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142784/214001 [25:25<12:37, 94.01it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142784/214001 [25:26<12:37, 94.01it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142848/214001 [25:26<12:36, 94.03it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142848/214001 [25:26<12:36, 94.03it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142912/214001 [25:26<12:39, 93.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142912/214001 [25:27<12:39, 93.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142976/214001 [25:27<12:43, 92.98it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 142976/214001 [25:28<12:43, 92.98it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143040/214001 [25:28<12:39, 93.46it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143040/214001 [25:29<12:39, 93.46it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143104/214001 [25:29<12:37, 93.53it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143104/214001 [25:29<12:37, 93.53it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143168/214001 [25:29<12:43, 92.80it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143168/214001 [25:30<12:43, 92.80it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143232/214001 [25:30<12:40, 93.03it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143232/214001 [25:31<12:40, 93.03it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143296/214001 [25:31<12:36, 93.43it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143296/214001 [25:31<12:36, 93.43it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143360/214001 [25:31<12:39, 92.95it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143360/214001 [25:32<12:39, 92.95it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143424/214001 [25:32<12:38, 93.05it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143424/214001 [25:33<12:38, 93.05it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143488/214001 [25:33<12:35, 93.35it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143488/214001 [25:33<12:35, 93.35it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143552/214001 [25:33<12:36, 93.12it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143552/214001 [25:34<12:36, 93.12it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143616/214001 [25:34<12:35, 93.11it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143616/214001 [25:35<12:35, 93.11it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143680/214001 [25:35<12:39, 92.56it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143680/214001 [25:35<12:39, 92.56it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143744/214001 [25:35<12:54, 90.70it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143744/214001 [25:36<12:54, 90.70it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143808/214001 [25:36<12:56, 90.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143808/214001 [25:37<12:56, 90.44it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143872/214001 [25:37<12:43, 91.82it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143872/214001 [25:38<12:43, 91.82it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143936/214001 [25:38<12:39, 92.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 143936/214001 [25:38<12:39, 92.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144000/214001 [25:38<12:35, 92.70it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144000/214001 [25:39<12:35, 92.70it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144064/214001 [25:39<12:32, 92.88it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144064/214001 [25:40<12:32, 92.88it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144128/214001 [25:40<12:39, 92.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144128/214001 [25:40<12:39, 92.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144192/214001 [25:40<12:36, 92.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144192/214001 [25:41<12:36, 92.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144256/214001 [25:41<12:30, 92.97it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144256/214001 [25:42<12:30, 92.97it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144320/214001 [25:42<12:28, 93.06it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144320/214001 [25:42<12:28, 93.06it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144384/214001 [25:42<12:32, 92.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144384/214001 [25:43<12:32, 92.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144448/214001 [25:43<12:30, 92.68it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 144448/214001 [25:44<12:30, 92.68it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144512/214001 [25:44<12:37, 91.72it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144512/214001 [25:44<12:37, 91.72it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144576/214001 [25:44<12:40, 91.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144576/214001 [25:45<12:40, 91.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144640/214001 [25:45<12:34, 91.94it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144640/214001 [25:46<12:34, 91.94it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144704/214001 [25:46<12:32, 92.09it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144704/214001 [25:47<12:32, 92.09it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144768/214001 [25:47<12:41, 90.95it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144768/214001 [25:47<12:41, 90.95it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144832/214001 [25:47<12:51, 89.62it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144832/214001 [25:48<12:51, 89.62it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144896/214001 [25:48<13:08, 87.68it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144896/214001 [25:49<13:08, 87.68it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144960/214001 [25:49<13:00, 88.50it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 144960/214001 [25:49<13:00, 88.50it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145024/214001 [25:49<12:51, 89.41it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145024/214001 [25:50<12:51, 89.41it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145088/214001 [25:50<12:48, 89.62it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145088/214001 [25:51<12:48, 89.62it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145152/214001 [25:51<12:56, 88.65it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145152/214001 [25:52<12:56, 88.65it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145216/214001 [25:52<13:02, 87.88it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145216/214001 [25:52<13:02, 87.88it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145280/214001 [25:52<12:55, 88.60it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145280/214001 [25:53<12:55, 88.60it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145344/214001 [25:53<12:47, 89.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145344/214001 [25:54<12:47, 89.49it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145408/214001 [25:54<12:42, 89.92it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145408/214001 [25:54<12:42, 89.92it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145472/214001 [25:54<12:40, 90.15it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145472/214001 [25:55<12:40, 90.15it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145536/214001 [25:55<12:38, 90.31it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145536/214001 [25:56<12:38, 90.31it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145600/214001 [25:56<12:33, 90.82it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145600/214001 [25:57<12:33, 90.82it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145664/214001 [25:57<12:21, 92.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145664/214001 [25:57<12:21, 92.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145728/214001 [25:57<12:28, 91.24it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145728/214001 [25:58<12:28, 91.24it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145792/214001 [25:58<12:26, 91.40it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145792/214001 [25:59<12:26, 91.40it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145856/214001 [25:59<12:23, 91.68it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145856/214001 [25:59<12:23, 91.68it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145920/214001 [25:59<12:32, 90.45it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145920/214001 [26:00<12:32, 90.45it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145984/214001 [26:00<12:26, 91.15it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 145984/214001 [26:01<12:26, 91.15it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146048/214001 [26:01<12:18, 92.02it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146048/214001 [26:01<12:18, 92.02it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146112/214001 [26:01<12:15, 92.28it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146112/214001 [26:02<12:15, 92.28it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146176/214001 [26:02<12:17, 91.93it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146176/214001 [26:03<12:17, 91.93it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146240/214001 [26:03<12:23, 91.16it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146240/214001 [26:04<12:23, 91.16it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146304/214001 [26:04<12:20, 91.43it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146304/214001 [26:04<12:20, 91.43it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146368/214001 [26:04<12:19, 91.43it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146368/214001 [26:05<12:19, 91.43it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146432/214001 [26:05<12:15, 91.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146432/214001 [26:06<12:15, 91.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146496/214001 [26:06<12:20, 91.14it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146496/214001 [26:06<12:20, 91.14it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146560/214001 [26:06<12:27, 90.27it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 146560/214001 [26:07<12:27, 90.27it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146624/214001 [26:07<12:28, 90.02it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146624/214001 [26:08<12:28, 90.02it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146688/214001 [26:08<12:20, 90.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146688/214001 [26:09<12:20, 90.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146752/214001 [26:09<12:19, 91.00it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146752/214001 [26:09<12:19, 91.00it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146816/214001 [26:09<12:21, 90.60it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146816/214001 [26:10<12:21, 90.60it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146880/214001 [26:10<12:24, 90.19it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146880/214001 [26:11<12:24, 90.19it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146944/214001 [26:11<12:31, 89.29it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 146944/214001 [26:11<12:31, 89.29it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 147008/214001 [26:11<12:28, 89.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 147008/214001 [26:12<12:28, 89.55it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 147072/214001 [26:12<12:29, 89.35it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 147072/214001 [26:13<12:29, 89.35it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147136/214001 [26:13<12:23, 89.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147136/214001 [26:14<12:23, 89.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147200/214001 [26:14<12:29, 89.12it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147200/214001 [26:14<12:29, 89.12it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147264/214001 [26:14<12:25, 89.47it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147264/214001 [26:15<12:25, 89.47it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147328/214001 [26:15<12:21, 89.94it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147328/214001 [26:16<12:21, 89.94it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147392/214001 [26:16<12:10, 91.13it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147392/214001 [26:16<12:10, 91.13it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147456/214001 [26:16<12:04, 91.84it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147456/214001 [26:17<12:04, 91.84it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147520/214001 [26:17<12:06, 91.54it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147520/214001 [26:18<12:06, 91.54it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147584/214001 [26:18<12:09, 91.02it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147584/214001 [26:18<12:09, 91.02it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147648/214001 [26:18<12:05, 91.46it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147648/214001 [26:19<12:05, 91.46it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147712/214001 [26:19<12:06, 91.24it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147712/214001 [26:20<12:06, 91.24it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147776/214001 [26:20<12:03, 91.57it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147776/214001 [26:20<12:03, 91.57it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147840/214001 [26:20<11:54, 92.59it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147840/214001 [26:21<11:54, 92.59it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147904/214001 [26:21<11:55, 92.35it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147904/214001 [26:22<11:55, 92.35it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147968/214001 [26:22<11:57, 92.10it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 147968/214001 [26:23<11:57, 92.10it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148032/214001 [26:23<11:53, 92.44it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148032/214001 [26:23<11:53, 92.44it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148096/214001 [26:23<11:55, 92.17it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148096/214001 [26:24<11:55, 92.17it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148160/214001 [26:24<12:00, 91.44it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148160/214001 [26:25<12:00, 91.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148224/214001 [26:25<11:59, 91.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148224/214001 [26:25<11:59, 91.44it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148288/214001 [26:25<11:57, 91.62it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148288/214001 [26:26<11:57, 91.62it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148352/214001 [26:26<12:02, 90.85it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148352/214001 [26:27<12:02, 90.85it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148416/214001 [26:27<12:11, 89.67it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148416/214001 [26:28<12:11, 89.67it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148480/214001 [26:28<12:02, 90.67it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148480/214001 [26:28<12:02, 90.67it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148544/214001 [26:28<12:03, 90.47it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148544/214001 [26:29<12:03, 90.47it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148608/214001 [26:29<12:13, 89.10it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148608/214001 [26:30<12:13, 89.10it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148672/214001 [26:30<12:10, 89.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 148672/214001 [26:30<12:10, 89.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148736/214001 [26:30<12:22, 87.93it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148736/214001 [26:31<12:22, 87.93it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148800/214001 [26:31<12:22, 87.84it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148800/214001 [26:32<12:22, 87.84it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148864/214001 [26:32<12:28, 87.05it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148864/214001 [26:33<12:28, 87.05it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148928/214001 [26:33<12:34, 86.25it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148928/214001 [26:33<12:34, 86.25it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148992/214001 [26:33<12:37, 85.83it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 148992/214001 [26:34<12:37, 85.83it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149056/214001 [26:34<12:33, 86.21it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149056/214001 [26:35<12:33, 86.21it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149120/214001 [26:35<12:51, 84.11it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149120/214001 [26:36<12:51, 84.11it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149184/214001 [26:36<12:48, 84.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149184/214001 [26:36<12:48, 84.31it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149248/214001 [26:36<12:32, 86.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149248/214001 [26:37<12:32, 86.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149312/214001 [26:37<12:33, 85.81it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149312/214001 [26:38<12:33, 85.81it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149376/214001 [26:38<12:31, 86.02it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149376/214001 [26:39<12:31, 86.02it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149440/214001 [26:39<12:28, 86.22it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149440/214001 [26:39<12:28, 86.22it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149504/214001 [26:39<12:18, 87.29it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149504/214001 [26:40<12:18, 87.29it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149568/214001 [26:40<12:05, 88.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149568/214001 [26:41<12:05, 88.84it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149632/214001 [26:41<11:58, 89.53it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149632/214001 [26:41<11:58, 89.53it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149696/214001 [26:41<11:57, 89.61it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149696/214001 [26:42<11:57, 89.61it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149760/214001 [26:42<11:49, 90.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 149760/214001 [26:43<11:49, 90.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 149824/214001 [26:43<11:47, 90.67it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 149824/214001 [26:44<11:47, 90.67it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 149888/214001 [26:44<11:43, 91.14it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 149888/214001 [26:44<11:43, 91.14it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 149952/214001 [26:44<11:35, 92.15it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 149952/214001 [26:45<11:35, 92.15it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150016/214001 [26:45<11:38, 91.63it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150016/214001 [26:46<11:38, 91.63it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150080/214001 [26:46<11:31, 92.48it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150080/214001 [26:46<11:31, 92.48it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150144/214001 [26:46<11:29, 92.66it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150144/214001 [26:47<11:29, 92.66it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150208/214001 [26:47<11:29, 92.47it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150208/214001 [26:48<11:29, 92.47it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150272/214001 [26:48<11:30, 92.30it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150272/214001 [26:48<11:30, 92.30it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150336/214001 [26:48<11:29, 92.34it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150336/214001 [26:49<11:29, 92.34it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150400/214001 [26:49<11:30, 92.16it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150400/214001 [26:50<11:30, 92.16it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150464/214001 [26:50<11:26, 92.59it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150464/214001 [26:50<11:26, 92.59it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150528/214001 [26:50<11:20, 93.26it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150528/214001 [26:51<11:20, 93.26it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150592/214001 [26:51<11:19, 93.37it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150592/214001 [26:52<11:19, 93.37it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150656/214001 [26:52<11:32, 91.41it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150656/214001 [26:53<11:32, 91.41it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150720/214001 [26:53<11:27, 92.04it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150720/214001 [26:53<11:27, 92.04it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150784/214001 [26:53<11:26, 92.15it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150784/214001 [26:54<11:26, 92.15it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150848/214001 [26:54<11:26, 91.96it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  70%|███████   | 150848/214001 [26:55<11:26, 91.96it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████   | 150912/214001 [26:55<11:25, 91.97it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████   | 150912/214001 [26:55<11:25, 91.97it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████   | 150976/214001 [26:55<11:25, 91.99it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████   | 150976/214001 [26:56<11:25, 91.99it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151040/214001 [26:56<11:20, 92.48it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151040/214001 [26:57<11:20, 92.48it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151104/214001 [26:57<11:16, 92.95it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151104/214001 [26:57<11:16, 92.95it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151168/214001 [26:57<11:18, 92.62it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151168/214001 [26:58<11:18, 92.62it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151232/214001 [26:58<11:25, 91.58it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151232/214001 [26:59<11:25, 91.58it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151296/214001 [26:59<11:20, 92.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151296/214001 [26:59<11:20, 92.18it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151360/214001 [27:00<11:19, 92.16it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151360/214001 [27:00<11:19, 92.16it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151424/214001 [27:00<11:18, 92.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151424/214001 [27:01<11:18, 92.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151488/214001 [27:01<11:15, 92.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151488/214001 [27:02<11:15, 92.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151552/214001 [27:02<11:17, 92.19it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151552/214001 [27:02<11:17, 92.19it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151616/214001 [27:02<11:19, 91.82it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151616/214001 [27:03<11:19, 91.82it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151680/214001 [27:03<11:14, 92.45it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151680/214001 [27:04<11:14, 92.45it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151744/214001 [27:04<11:10, 92.83it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151744/214001 [27:04<11:10, 92.83it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151808/214001 [27:04<11:07, 93.18it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151808/214001 [27:05<11:07, 93.18it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151872/214001 [27:05<11:02, 93.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151872/214001 [27:06<11:02, 93.75it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151936/214001 [27:06<10:59, 94.07it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  71%|███████   | 151936/214001 [27:06<10:59, 94.07it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152000/214001 [27:06<11:04, 93.37it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152000/214001 [27:07<11:04, 93.37it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152064/214001 [27:07<11:03, 93.37it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152064/214001 [27:08<11:03, 93.37it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152128/214001 [27:08<11:00, 93.67it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152128/214001 [27:08<11:00, 93.67it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152192/214001 [27:08<11:02, 93.23it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152192/214001 [27:09<11:02, 93.23it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152256/214001 [27:09<11:01, 93.40it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152256/214001 [27:10<11:01, 93.40it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152320/214001 [27:10<11:03, 92.91it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152320/214001 [27:10<11:03, 92.91it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152384/214001 [27:11<11:03, 92.94it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152384/214001 [27:11<11:03, 92.94it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152448/214001 [27:11<10:59, 93.38it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████   | 152448/214001 [27:12<10:59, 93.38it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152512/214001 [27:12<11:01, 92.93it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152512/214001 [27:13<11:01, 92.93it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152576/214001 [27:13<11:09, 91.74it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152576/214001 [27:13<11:09, 91.74it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152640/214001 [27:13<11:06, 92.02it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152640/214001 [27:14<11:06, 92.02it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152704/214001 [27:14<11:07, 91.78it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152704/214001 [27:15<11:07, 91.78it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152768/214001 [27:15<11:04, 92.15it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152768/214001 [27:15<11:04, 92.15it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152832/214001 [27:15<11:01, 92.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152832/214001 [27:16<11:01, 92.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152896/214001 [27:16<11:02, 92.23it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152896/214001 [27:17<11:02, 92.23it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152960/214001 [27:17<10:58, 92.63it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 152960/214001 [27:17<10:58, 92.63it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153024/214001 [27:17<10:59, 92.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153024/214001 [27:18<10:59, 92.52it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153088/214001 [27:18<11:06, 91.35it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153088/214001 [27:19<11:06, 91.35it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153152/214001 [27:19<11:06, 91.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153152/214001 [27:20<11:06, 91.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153216/214001 [27:20<11:00, 92.08it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153216/214001 [27:20<11:00, 92.08it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153280/214001 [27:20<11:00, 91.93it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153280/214001 [27:21<11:00, 91.93it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153344/214001 [27:21<10:57, 92.26it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153344/214001 [27:22<10:57, 92.26it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153408/214001 [27:22<10:54, 92.56it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153408/214001 [27:22<10:54, 92.56it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153472/214001 [27:22<10:57, 92.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153472/214001 [27:23<10:57, 92.00it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153536/214001 [27:23<11:00, 91.50it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153536/214001 [27:24<11:00, 91.50it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153600/214001 [27:24<10:53, 92.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153600/214001 [27:24<10:53, 92.49it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153664/214001 [27:24<10:52, 92.44it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153664/214001 [27:25<10:52, 92.44it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153728/214001 [27:25<10:50, 92.66it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153728/214001 [27:26<10:50, 92.66it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153792/214001 [27:26<10:47, 92.94it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153792/214001 [27:26<10:47, 92.94it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153856/214001 [27:26<10:51, 92.39it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153856/214001 [27:27<10:51, 92.39it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153920/214001 [27:27<10:55, 91.68it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153920/214001 [27:28<10:55, 91.68it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153984/214001 [27:28<10:53, 91.86it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 153984/214001 [27:29<10:53, 91.86it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154048/214001 [27:29<10:50, 92.11it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154048/214001 [27:29<10:50, 92.11it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154112/214001 [27:29<10:59, 90.87it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154112/214001 [27:30<10:59, 90.87it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154176/214001 [27:30<10:58, 90.92it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154176/214001 [27:31<10:58, 90.92it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154240/214001 [27:31<10:52, 91.60it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154240/214001 [27:31<10:52, 91.60it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154304/214001 [27:31<10:56, 90.89it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154304/214001 [27:32<10:56, 90.89it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154368/214001 [27:32<11:12, 88.74it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154368/214001 [27:33<11:12, 88.74it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154432/214001 [27:33<11:10, 88.85it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154432/214001 [27:34<11:10, 88.85it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154496/214001 [27:34<11:03, 89.75it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154496/214001 [27:34<11:03, 89.75it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154560/214001 [27:34<10:58, 90.24it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154560/214001 [27:35<10:58, 90.24it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154624/214001 [27:35<11:07, 88.95it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154624/214001 [27:36<11:07, 88.95it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154688/214001 [27:36<11:18, 87.46it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154688/214001 [27:37<11:18, 87.46it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154752/214001 [27:37<11:18, 87.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154752/214001 [27:37<11:18, 87.31it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154816/214001 [27:37<11:08, 88.56it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154816/214001 [27:38<11:08, 88.56it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154880/214001 [27:38<11:03, 89.15it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154880/214001 [27:39<11:03, 89.15it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154944/214001 [27:39<10:58, 89.73it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 154944/214001 [27:39<10:58, 89.73it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 155008/214001 [27:39<10:56, 89.84it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 155008/214001 [27:40<10:56, 89.84it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 155072/214001 [27:40<10:52, 90.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 155072/214001 [27:41<10:52, 90.27it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 155136/214001 [27:41<10:46, 91.05it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 155136/214001 [27:41<10:46, 91.05it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155200/214001 [27:41<10:42, 91.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155200/214001 [27:42<10:42, 91.54it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155264/214001 [27:42<10:48, 90.55it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155264/214001 [27:43<10:48, 90.55it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155328/214001 [27:43<10:52, 89.97it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155328/214001 [27:44<10:52, 89.97it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155392/214001 [27:44<10:47, 90.57it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155392/214001 [27:44<10:47, 90.57it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155456/214001 [27:44<10:46, 90.61it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155456/214001 [27:45<10:46, 90.61it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155520/214001 [27:45<10:41, 91.17it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155520/214001 [27:46<10:41, 91.17it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155584/214001 [27:46<10:40, 91.14it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155584/214001 [27:46<10:40, 91.14it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155648/214001 [27:46<10:44, 90.52it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155648/214001 [27:47<10:44, 90.52it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155712/214001 [27:47<10:47, 90.02it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155712/214001 [27:48<10:47, 90.02it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155776/214001 [27:48<10:41, 90.70it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155776/214001 [27:48<10:41, 90.70it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155840/214001 [27:48<10:38, 91.13it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155840/214001 [27:49<10:38, 91.13it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155904/214001 [27:49<10:38, 90.93it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155904/214001 [27:50<10:38, 90.93it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155968/214001 [27:50<10:40, 90.60it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 155968/214001 [27:51<10:40, 90.60it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156032/214001 [27:51<10:38, 90.74it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156032/214001 [27:51<10:38, 90.74it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156096/214001 [27:51<10:37, 90.82it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156096/214001 [27:52<10:37, 90.82it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156160/214001 [27:52<10:41, 90.15it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156160/214001 [27:53<10:41, 90.15it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156224/214001 [27:53<10:42, 89.92it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156224/214001 [27:53<10:42, 89.92it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156288/214001 [27:53<10:40, 90.17it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156288/214001 [27:54<10:40, 90.17it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156352/214001 [27:54<10:38, 90.34it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156352/214001 [27:55<10:38, 90.34it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156416/214001 [27:55<10:40, 89.97it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156416/214001 [27:56<10:40, 89.97it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156480/214001 [27:56<10:31, 91.02it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156480/214001 [27:56<10:31, 91.02it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156544/214001 [27:56<10:26, 91.71it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156544/214001 [27:57<10:26, 91.71it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156608/214001 [27:57<10:28, 91.33it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156608/214001 [27:58<10:28, 91.33it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156672/214001 [27:58<10:23, 91.97it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156672/214001 [27:58<10:23, 91.97it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156736/214001 [27:58<10:21, 92.14it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156736/214001 [27:59<10:21, 92.14it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156800/214001 [27:59<10:18, 92.48it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156800/214001 [28:00<10:18, 92.48it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156864/214001 [28:00<10:15, 92.78it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156864/214001 [28:00<10:15, 92.78it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156928/214001 [28:00<10:16, 92.61it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156928/214001 [28:01<10:16, 92.61it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156992/214001 [28:01<10:20, 91.84it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 156992/214001 [28:02<10:20, 91.84it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157056/214001 [28:02<10:20, 91.82it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157056/214001 [28:02<10:20, 91.82it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157120/214001 [28:02<10:17, 92.06it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157120/214001 [28:03<10:17, 92.06it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157184/214001 [28:03<10:17, 92.03it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157184/214001 [28:04<10:17, 92.03it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157248/214001 [28:04<10:13, 92.58it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 157248/214001 [28:05<10:13, 92.58it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157312/214001 [28:05<10:18, 91.71it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157312/214001 [28:05<10:18, 91.71it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157376/214001 [28:05<10:21, 91.10it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157376/214001 [28:06<10:21, 91.10it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157440/214001 [28:06<10:17, 91.55it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157440/214001 [28:07<10:17, 91.55it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157504/214001 [28:07<10:16, 91.61it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157504/214001 [28:07<10:16, 91.61it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157568/214001 [28:07<10:19, 91.14it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157568/214001 [28:08<10:19, 91.14it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157632/214001 [28:08<10:19, 91.05it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157632/214001 [28:09<10:19, 91.05it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157696/214001 [28:09<10:28, 89.63it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157696/214001 [28:10<10:28, 89.63it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157760/214001 [28:10<10:29, 89.39it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157760/214001 [28:10<10:29, 89.39it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157824/214001 [28:10<10:24, 89.94it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 157824/214001 [28:11<10:24, 89.94it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  74%|███████▍  | 157888/214001 [28:11<10:18, 90.74it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 157888/214001 [28:12<10:18, 90.74it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 157952/214001 [28:12<10:19, 90.44it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 157952/214001 [28:12<10:19, 90.44it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158016/214001 [28:12<10:16, 90.81it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158016/214001 [28:13<10:16, 90.81it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158080/214001 [28:13<10:15, 90.90it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158080/214001 [28:14<10:15, 90.90it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158144/214001 [28:14<10:11, 91.33it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158144/214001 [28:14<10:11, 91.33it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158208/214001 [28:14<10:07, 91.85it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158208/214001 [28:15<10:07, 91.85it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158272/214001 [28:15<10:08, 91.65it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158272/214001 [28:16<10:08, 91.65it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158336/214001 [28:16<10:08, 91.52it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158336/214001 [28:17<10:08, 91.52it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158400/214001 [28:17<10:04, 91.96it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158400/214001 [28:17<10:04, 91.96it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158464/214001 [28:17<10:07, 91.42it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158464/214001 [28:18<10:07, 91.42it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158528/214001 [28:18<10:08, 91.19it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158528/214001 [28:19<10:08, 91.19it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158592/214001 [28:19<10:18, 89.64it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158592/214001 [28:19<10:18, 89.64it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158656/214001 [28:19<10:09, 90.84it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158656/214001 [28:20<10:09, 90.84it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158720/214001 [28:20<10:05, 91.31it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158720/214001 [28:21<10:05, 91.31it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158784/214001 [28:21<10:03, 91.52it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158784/214001 [28:21<10:03, 91.52it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158848/214001 [28:21<09:58, 92.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158848/214001 [28:22<09:58, 92.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158912/214001 [28:22<10:06, 90.80it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158912/214001 [28:23<10:06, 90.80it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158976/214001 [28:23<10:02, 91.35it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 158976/214001 [28:24<10:02, 91.35it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159040/214001 [28:24<10:01, 91.43it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159040/214001 [28:24<10:01, 91.43it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159104/214001 [28:24<10:05, 90.74it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159104/214001 [28:25<10:05, 90.74it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159168/214001 [28:25<10:06, 90.38it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159168/214001 [28:26<10:06, 90.38it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159232/214001 [28:26<10:02, 90.86it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159232/214001 [28:26<10:02, 90.86it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159296/214001 [28:26<10:01, 91.02it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159296/214001 [28:27<10:01, 91.02it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159360/214001 [28:27<09:59, 91.18it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159360/214001 [28:28<09:59, 91.18it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159424/214001 [28:28<10:00, 90.91it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 159424/214001 [28:29<10:00, 90.91it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159488/214001 [28:29<10:03, 90.33it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159488/214001 [28:29<10:03, 90.33it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159552/214001 [28:29<10:01, 90.48it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159552/214001 [28:30<10:01, 90.48it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159616/214001 [28:30<09:56, 91.24it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159616/214001 [28:31<09:56, 91.24it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159680/214001 [28:31<09:58, 90.75it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159680/214001 [28:31<09:58, 90.75it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159744/214001 [28:31<09:57, 90.78it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159744/214001 [28:32<09:57, 90.78it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159808/214001 [28:32<09:56, 90.80it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159808/214001 [28:33<09:56, 90.80it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159872/214001 [28:33<09:53, 91.17it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159872/214001 [28:33<09:53, 91.17it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159936/214001 [28:33<09:55, 90.73it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 159936/214001 [28:34<09:55, 90.73it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160000/214001 [28:34<09:58, 90.16it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160000/214001 [28:35<09:58, 90.16it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160064/214001 [28:35<09:54, 90.72it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160064/214001 [28:36<09:54, 90.72it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160128/214001 [28:36<09:57, 90.11it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160128/214001 [28:36<09:57, 90.11it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160192/214001 [28:36<10:02, 89.24it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160192/214001 [28:37<10:02, 89.24it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160256/214001 [28:37<10:01, 89.30it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160256/214001 [28:38<10:01, 89.30it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160320/214001 [28:38<09:59, 89.49it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160320/214001 [28:38<09:59, 89.49it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160384/214001 [28:38<10:03, 88.90it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160384/214001 [28:39<10:03, 88.90it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160448/214001 [28:39<10:04, 88.53it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 160448/214001 [28:40<10:04, 88.53it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160512/214001 [28:40<10:03, 88.57it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160512/214001 [28:41<10:03, 88.57it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160576/214001 [28:41<10:01, 88.88it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160576/214001 [28:41<10:01, 88.88it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160640/214001 [28:41<10:03, 88.38it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160640/214001 [28:42<10:03, 88.38it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160704/214001 [28:42<10:04, 88.24it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160704/214001 [28:43<10:04, 88.24it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160768/214001 [28:43<10:13, 86.81it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160768/214001 [28:44<10:13, 86.81it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160832/214001 [28:44<10:07, 87.54it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160832/214001 [28:44<10:07, 87.54it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160896/214001 [28:44<10:06, 87.63it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160896/214001 [28:45<10:06, 87.63it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160960/214001 [28:45<10:04, 87.81it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 160960/214001 [28:46<10:04, 87.81it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161024/214001 [28:46<10:01, 88.09it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161024/214001 [28:46<10:01, 88.09it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161088/214001 [28:47<10:06, 87.28it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161088/214001 [28:47<10:06, 87.28it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161152/214001 [28:47<10:26, 84.36it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161152/214001 [28:48<10:26, 84.36it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161216/214001 [28:48<10:30, 83.66it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161216/214001 [28:49<10:30, 83.66it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161280/214001 [28:49<10:31, 83.45it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161280/214001 [28:50<10:31, 83.45it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161344/214001 [28:50<10:12, 85.91it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161344/214001 [28:50<10:12, 85.91it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161408/214001 [28:50<10:12, 85.84it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161408/214001 [28:51<10:12, 85.84it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161472/214001 [28:51<10:11, 85.85it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161472/214001 [28:52<10:11, 85.85it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161536/214001 [28:52<10:06, 86.53it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 161536/214001 [28:52<10:06, 86.53it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161600/214001 [28:52<09:55, 87.95it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161600/214001 [28:53<09:55, 87.95it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161664/214001 [28:53<09:49, 88.86it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161664/214001 [28:54<09:49, 88.86it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161728/214001 [28:54<09:44, 89.49it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161728/214001 [28:55<09:44, 89.49it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161792/214001 [28:55<09:37, 90.42it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161792/214001 [28:55<09:37, 90.42it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161856/214001 [28:55<09:39, 90.04it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161856/214001 [28:56<09:39, 90.04it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161920/214001 [28:56<09:39, 89.92it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161920/214001 [28:57<09:39, 89.92it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161984/214001 [28:57<09:31, 90.97it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 161984/214001 [28:57<09:31, 90.97it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162048/214001 [28:57<09:30, 91.14it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162048/214001 [28:58<09:30, 91.14it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162112/214001 [28:58<09:27, 91.42it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162112/214001 [28:59<09:27, 91.42it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162176/214001 [28:59<09:20, 92.43it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162176/214001 [28:59<09:20, 92.43it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162240/214001 [28:59<09:19, 92.57it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162240/214001 [29:00<09:19, 92.57it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162304/214001 [29:00<09:23, 91.71it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162304/214001 [29:01<09:23, 91.71it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162368/214001 [29:01<09:23, 91.57it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162368/214001 [29:02<09:23, 91.57it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162432/214001 [29:02<09:25, 91.25it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162432/214001 [29:02<09:25, 91.25it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162496/214001 [29:02<09:23, 91.34it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162496/214001 [29:03<09:23, 91.34it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162560/214001 [29:03<09:28, 90.41it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162560/214001 [29:04<09:28, 90.41it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162624/214001 [29:04<09:30, 90.08it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162624/214001 [29:04<09:30, 90.08it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162688/214001 [29:04<09:26, 90.58it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162688/214001 [29:05<09:26, 90.58it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162752/214001 [29:05<09:21, 91.30it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162752/214001 [29:06<09:21, 91.30it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162816/214001 [29:06<09:21, 91.14it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162816/214001 [29:06<09:21, 91.14it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162880/214001 [29:07<09:19, 91.44it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162880/214001 [29:07<09:19, 91.44it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162944/214001 [29:07<09:19, 91.20it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 162944/214001 [29:08<09:19, 91.20it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 163008/214001 [29:08<09:18, 91.27it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 163008/214001 [29:09<09:18, 91.27it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 163072/214001 [29:09<09:17, 91.40it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 163072/214001 [29:09<09:17, 91.40it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 163136/214001 [29:09<09:15, 91.58it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 163136/214001 [29:10<09:15, 91.58it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163200/214001 [29:10<09:15, 91.51it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163200/214001 [29:11<09:15, 91.51it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163264/214001 [29:11<09:14, 91.51it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163264/214001 [29:11<09:14, 91.51it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163328/214001 [29:11<09:14, 91.37it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163328/214001 [29:12<09:14, 91.37it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163392/214001 [29:12<09:14, 91.20it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163392/214001 [29:13<09:14, 91.20it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163456/214001 [29:13<09:15, 91.04it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163456/214001 [29:14<09:15, 91.04it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163520/214001 [29:14<09:19, 90.30it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163520/214001 [29:14<09:19, 90.30it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163584/214001 [29:14<09:16, 90.63it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163584/214001 [29:15<09:16, 90.63it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163648/214001 [29:15<09:12, 91.11it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 163648/214001 [29:16<09:12, 91.11it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163712/214001 [29:16<09:10, 91.35it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163712/214001 [29:16<09:10, 91.35it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163776/214001 [29:16<09:04, 92.28it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163776/214001 [29:17<09:04, 92.28it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163840/214001 [29:17<09:04, 92.14it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163840/214001 [29:18<09:04, 92.14it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163904/214001 [29:18<09:01, 92.54it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163904/214001 [29:18<09:01, 92.54it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163968/214001 [29:18<08:58, 92.87it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 163968/214001 [29:19<08:58, 92.87it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164032/214001 [29:19<09:06, 91.50it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164032/214001 [29:20<09:06, 91.50it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164096/214001 [29:20<09:04, 91.62it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164096/214001 [29:20<09:04, 91.62it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164160/214001 [29:20<09:03, 91.78it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164160/214001 [29:21<09:03, 91.78it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164224/214001 [29:21<09:04, 91.42it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164224/214001 [29:22<09:04, 91.42it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164288/214001 [29:22<09:06, 90.96it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164288/214001 [29:23<09:06, 90.96it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164352/214001 [29:23<09:05, 91.10it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164352/214001 [29:23<09:05, 91.10it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164416/214001 [29:23<09:05, 90.88it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164416/214001 [29:24<09:05, 90.88it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164480/214001 [29:24<09:07, 90.39it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164480/214001 [29:25<09:07, 90.39it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164544/214001 [29:25<09:02, 91.14it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164544/214001 [29:25<09:02, 91.14it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164608/214001 [29:25<09:12, 89.48it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164608/214001 [29:26<09:12, 89.48it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164672/214001 [29:26<09:08, 90.00it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164672/214001 [29:27<09:08, 90.00it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164736/214001 [29:27<09:01, 91.00it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164736/214001 [29:28<09:01, 91.00it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164800/214001 [29:28<09:02, 90.73it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164800/214001 [29:28<09:02, 90.73it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164864/214001 [29:28<09:03, 90.47it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164864/214001 [29:29<09:03, 90.47it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164928/214001 [29:29<09:04, 90.12it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164928/214001 [29:30<09:04, 90.12it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164992/214001 [29:30<09:07, 89.47it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 164992/214001 [29:30<09:07, 89.47it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165056/214001 [29:30<09:07, 89.41it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165056/214001 [29:31<09:07, 89.41it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165120/214001 [29:31<09:11, 88.61it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165120/214001 [29:32<09:11, 88.61it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165184/214001 [29:32<09:09, 88.77it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165184/214001 [29:33<09:09, 88.77it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165248/214001 [29:33<09:14, 87.98it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165248/214001 [29:33<09:14, 87.98it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165312/214001 [29:33<09:08, 88.79it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165312/214001 [29:34<09:08, 88.79it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165376/214001 [29:34<09:06, 88.97it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165376/214001 [29:35<09:06, 88.97it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165440/214001 [29:35<09:11, 88.05it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165440/214001 [29:36<09:11, 88.05it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165504/214001 [29:36<09:10, 88.10it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165504/214001 [29:36<09:10, 88.10it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165568/214001 [29:36<09:15, 87.23it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165568/214001 [29:37<09:15, 87.23it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165632/214001 [29:37<09:07, 88.34it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165632/214001 [29:38<09:07, 88.34it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165696/214001 [29:38<09:01, 89.18it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165696/214001 [29:38<09:01, 89.18it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165760/214001 [29:38<09:02, 88.90it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165760/214001 [29:39<09:02, 88.90it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165824/214001 [29:39<08:59, 89.36it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 165824/214001 [29:40<08:59, 89.36it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 165888/214001 [29:40<08:54, 90.03it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 165888/214001 [29:41<08:54, 90.03it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 165952/214001 [29:41<08:50, 90.64it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 165952/214001 [29:41<08:50, 90.64it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166016/214001 [29:41<08:52, 90.04it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166016/214001 [29:42<08:52, 90.04it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166080/214001 [29:42<08:58, 89.04it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166080/214001 [29:43<08:58, 89.04it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166144/214001 [29:43<09:08, 87.23it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166144/214001 [29:43<09:08, 87.23it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166208/214001 [29:43<09:14, 86.27it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166208/214001 [29:44<09:14, 86.27it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166272/214001 [29:44<09:08, 86.95it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166272/214001 [29:45<09:08, 86.95it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166336/214001 [29:45<09:00, 88.17it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166336/214001 [29:46<09:00, 88.17it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166400/214001 [29:46<09:03, 87.64it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166400/214001 [29:46<09:03, 87.64it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166464/214001 [29:46<08:57, 88.41it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166464/214001 [29:47<08:57, 88.41it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166528/214001 [29:47<08:53, 88.95it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166528/214001 [29:48<08:53, 88.95it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166592/214001 [29:48<08:51, 89.26it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166592/214001 [29:48<08:51, 89.26it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166656/214001 [29:48<08:41, 90.73it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166656/214001 [29:49<08:41, 90.73it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166720/214001 [29:49<08:41, 90.71it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166720/214001 [29:50<08:41, 90.71it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166784/214001 [29:50<08:39, 90.92it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166784/214001 [29:51<08:39, 90.92it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166848/214001 [29:51<08:36, 91.26it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166848/214001 [29:51<08:36, 91.26it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166912/214001 [29:51<08:35, 91.38it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166912/214001 [29:52<08:35, 91.38it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166976/214001 [29:52<08:40, 90.40it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 166976/214001 [29:53<08:40, 90.40it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167040/214001 [29:53<08:38, 90.65it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167040/214001 [29:53<08:38, 90.65it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167104/214001 [29:53<08:39, 90.29it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167104/214001 [29:54<08:39, 90.29it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167168/214001 [29:54<08:35, 90.85it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167168/214001 [29:55<08:35, 90.85it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167232/214001 [29:55<08:32, 91.20it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167232/214001 [29:56<08:32, 91.20it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167296/214001 [29:56<08:39, 89.94it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167296/214001 [29:56<08:39, 89.94it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167360/214001 [29:56<08:41, 89.46it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167360/214001 [29:57<08:41, 89.46it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167424/214001 [29:57<08:42, 89.11it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167424/214001 [29:58<08:42, 89.11it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167488/214001 [29:58<08:37, 89.82it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167488/214001 [29:58<08:37, 89.82it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167552/214001 [29:58<08:33, 90.43it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167552/214001 [29:59<08:33, 90.43it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167616/214001 [29:59<08:34, 90.10it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167616/214001 [30:00<08:34, 90.10it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167680/214001 [30:00<08:33, 90.19it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167680/214001 [30:00<08:33, 90.19it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167744/214001 [30:00<08:29, 90.74it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167744/214001 [30:01<08:29, 90.74it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167808/214001 [30:01<08:29, 90.64it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167808/214001 [30:02<08:29, 90.64it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167872/214001 [30:02<08:27, 90.91it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167872/214001 [30:03<08:27, 90.91it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167936/214001 [30:03<08:28, 90.63it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 167936/214001 [30:03<08:28, 90.63it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168000/214001 [30:03<08:32, 89.77it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168000/214001 [30:04<08:32, 89.77it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168064/214001 [30:04<08:37, 88.75it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168064/214001 [30:05<08:37, 88.75it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168128/214001 [30:05<08:45, 87.27it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168128/214001 [30:06<08:45, 87.27it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168192/214001 [30:06<08:59, 84.84it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168192/214001 [30:06<08:59, 84.84it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168256/214001 [30:06<08:55, 85.45it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168256/214001 [30:07<08:55, 85.45it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168320/214001 [30:07<08:54, 85.53it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168320/214001 [30:08<08:54, 85.53it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168384/214001 [30:08<08:45, 86.85it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168384/214001 [30:09<08:45, 86.85it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168448/214001 [30:09<08:51, 85.76it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168448/214001 [30:09<08:51, 85.76it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168512/214001 [30:09<08:56, 84.81it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 168512/214001 [30:10<08:56, 84.81it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168576/214001 [30:10<08:46, 86.30it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168576/214001 [30:11<08:46, 86.30it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168640/214001 [30:11<08:41, 86.99it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168640/214001 [30:12<08:41, 86.99it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168704/214001 [30:12<08:33, 88.15it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168704/214001 [30:12<08:33, 88.15it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168768/214001 [30:12<08:29, 88.74it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168768/214001 [30:13<08:29, 88.74it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168832/214001 [30:13<08:28, 88.79it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168832/214001 [30:14<08:28, 88.79it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168896/214001 [30:14<08:29, 88.57it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168896/214001 [30:14<08:29, 88.57it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168960/214001 [30:14<08:24, 89.34it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 168960/214001 [30:15<08:24, 89.34it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169024/214001 [30:15<08:23, 89.34it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169024/214001 [30:16<08:23, 89.34it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169088/214001 [30:16<08:18, 90.07it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169088/214001 [30:17<08:18, 90.07it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169152/214001 [30:17<08:21, 89.49it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169152/214001 [30:17<08:21, 89.49it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169216/214001 [30:17<08:23, 88.97it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169216/214001 [30:18<08:23, 88.97it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169280/214001 [30:18<08:22, 88.96it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169280/214001 [30:19<08:22, 88.96it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169344/214001 [30:19<08:15, 90.05it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169344/214001 [30:19<08:15, 90.05it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169408/214001 [30:19<08:16, 89.80it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169408/214001 [30:20<08:16, 89.80it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169472/214001 [30:20<08:18, 89.29it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169472/214001 [30:21<08:18, 89.29it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169536/214001 [30:21<08:18, 89.22it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169536/214001 [30:22<08:18, 89.22it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169600/214001 [30:22<08:14, 89.77it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169600/214001 [30:22<08:14, 89.77it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169664/214001 [30:22<08:13, 89.90it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169664/214001 [30:23<08:13, 89.90it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169728/214001 [30:23<08:08, 90.60it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169728/214001 [30:24<08:08, 90.60it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169792/214001 [30:24<08:06, 90.95it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169792/214001 [30:24<08:06, 90.95it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169856/214001 [30:24<08:13, 89.45it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169856/214001 [30:25<08:13, 89.45it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169920/214001 [30:25<08:15, 88.93it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169920/214001 [30:26<08:15, 88.93it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169984/214001 [30:26<08:11, 89.56it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 169984/214001 [30:27<08:11, 89.56it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 170048/214001 [30:27<08:10, 89.55it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 170048/214001 [30:27<08:10, 89.55it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 170112/214001 [30:27<08:20, 87.66it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 170112/214001 [30:28<08:20, 87.66it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170176/214001 [30:28<09:26, 77.41it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170176/214001 [30:29<09:26, 77.41it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170240/214001 [30:29<10:16, 71.02it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170240/214001 [30:30<10:16, 71.02it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170304/214001 [30:30<10:51, 67.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170304/214001 [30:32<10:51, 67.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170368/214001 [30:32<11:12, 64.90it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170368/214001 [30:33<11:12, 64.90it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170432/214001 [30:33<11:44, 61.84it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170432/214001 [30:34<11:44, 61.84it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170496/214001 [30:34<11:53, 60.94it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170496/214001 [30:35<11:53, 60.94it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170560/214001 [30:35<11:05, 65.31it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170560/214001 [30:35<11:05, 65.31it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170624/214001 [30:35<10:08, 71.32it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170624/214001 [30:36<10:08, 71.32it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170688/214001 [30:36<09:35, 75.28it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170688/214001 [30:37<09:35, 75.28it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170752/214001 [30:37<09:14, 77.94it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170752/214001 [30:38<09:14, 77.94it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170816/214001 [30:38<09:04, 79.27it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170816/214001 [30:38<09:04, 79.27it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170880/214001 [30:38<08:44, 82.23it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170880/214001 [30:39<08:44, 82.23it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170944/214001 [30:39<08:29, 84.45it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 170944/214001 [30:40<08:29, 84.45it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171008/214001 [30:40<08:21, 85.79it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171008/214001 [30:40<08:21, 85.79it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171072/214001 [30:40<08:17, 86.36it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171072/214001 [30:41<08:17, 86.36it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171136/214001 [30:41<08:10, 87.37it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171136/214001 [30:42<08:10, 87.37it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171200/214001 [30:42<08:03, 88.44it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 171200/214001 [30:43<08:03, 88.44it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171264/214001 [30:43<08:03, 88.47it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171264/214001 [30:43<08:03, 88.47it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171328/214001 [30:43<08:02, 88.36it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171328/214001 [30:44<08:02, 88.36it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171392/214001 [30:44<08:05, 87.80it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171392/214001 [30:45<08:05, 87.80it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171456/214001 [30:45<08:02, 88.11it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171456/214001 [30:45<08:02, 88.11it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171520/214001 [30:45<07:55, 89.36it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171520/214001 [30:46<07:55, 89.36it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171584/214001 [30:46<07:52, 89.76it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171584/214001 [30:47<07:52, 89.76it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171648/214001 [30:47<07:48, 90.44it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171648/214001 [30:48<07:48, 90.44it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171712/214001 [30:48<07:43, 91.28it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171712/214001 [30:48<07:43, 91.28it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171776/214001 [30:48<07:47, 90.35it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171776/214001 [30:49<07:47, 90.35it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171840/214001 [30:49<07:47, 90.24it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171840/214001 [30:50<07:47, 90.24it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171904/214001 [30:50<07:42, 90.97it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171904/214001 [30:50<07:42, 90.97it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171968/214001 [30:50<07:42, 90.95it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  80%|████████  | 171968/214001 [30:51<07:42, 90.95it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172032/214001 [30:51<07:38, 91.44it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172032/214001 [30:52<07:38, 91.44it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172096/214001 [30:52<07:39, 91.10it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172096/214001 [30:52<07:39, 91.10it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172160/214001 [30:52<07:42, 90.55it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172160/214001 [30:53<07:42, 90.55it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172224/214001 [30:53<07:42, 90.40it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  80%|████████  | 172224/214001 [30:54<07:42, 90.40it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  81%|████████  | 172288/214001 [30:54<07:43, 90.05it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172288/214001 [30:55<07:43, 90.05it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172352/214001 [30:55<07:44, 89.76it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172352/214001 [30:55<07:44, 89.76it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172416/214001 [30:55<07:45, 89.43it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172416/214001 [30:56<07:45, 89.43it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172480/214001 [30:56<07:48, 88.64it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172480/214001 [30:57<07:48, 88.64it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172544/214001 [30:57<07:45, 89.05it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172544/214001 [30:58<07:45, 89.05it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172608/214001 [30:58<07:47, 88.56it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172608/214001 [30:58<07:47, 88.56it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172672/214001 [30:58<07:46, 88.65it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172672/214001 [30:59<07:46, 88.65it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172736/214001 [30:59<07:49, 87.86it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172736/214001 [31:00<07:49, 87.86it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172800/214001 [31:00<07:52, 87.14it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172800/214001 [31:00<07:52, 87.14it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172864/214001 [31:00<07:48, 87.87it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172864/214001 [31:01<07:48, 87.87it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172928/214001 [31:01<07:41, 88.92it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172928/214001 [31:02<07:41, 88.92it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172992/214001 [31:02<07:42, 88.67it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 172992/214001 [31:03<07:42, 88.67it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173056/214001 [31:03<07:39, 89.10it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173056/214001 [31:03<07:39, 89.10it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173120/214001 [31:03<07:33, 90.23it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173120/214001 [31:04<07:33, 90.23it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173184/214001 [31:04<07:34, 89.84it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173184/214001 [31:05<07:34, 89.84it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173248/214001 [31:05<07:30, 90.41it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173248/214001 [31:05<07:30, 90.41it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173312/214001 [31:05<07:27, 90.85it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173312/214001 [31:06<07:27, 90.85it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173376/214001 [31:06<07:30, 90.12it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173376/214001 [31:07<07:30, 90.12it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173440/214001 [31:07<07:29, 90.25it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173440/214001 [31:08<07:29, 90.25it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173504/214001 [31:08<07:29, 90.04it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173504/214001 [31:08<07:29, 90.04it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173568/214001 [31:08<07:29, 89.95it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173568/214001 [31:09<07:29, 89.95it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173632/214001 [31:09<07:36, 88.44it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173632/214001 [31:10<07:36, 88.44it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173696/214001 [31:10<07:38, 87.83it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173696/214001 [31:10<07:38, 87.83it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173760/214001 [31:10<07:33, 88.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173760/214001 [31:11<07:33, 88.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173824/214001 [31:11<07:33, 88.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████  | 173824/214001 [31:12<07:33, 88.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 173888/214001 [31:12<07:28, 89.44it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 173888/214001 [31:13<07:28, 89.44it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 173952/214001 [31:13<07:22, 90.49it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 173952/214001 [31:13<07:22, 90.49it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174016/214001 [31:13<07:24, 89.97it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174016/214001 [31:14<07:24, 89.97it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174080/214001 [31:14<07:20, 90.72it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174080/214001 [31:15<07:20, 90.72it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174144/214001 [31:15<07:14, 91.83it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174144/214001 [31:15<07:14, 91.83it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174208/214001 [31:15<07:15, 91.38it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174208/214001 [31:16<07:15, 91.38it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174272/214001 [31:16<07:13, 91.57it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174272/214001 [31:17<07:13, 91.57it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174336/214001 [31:17<07:10, 92.04it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174336/214001 [31:17<07:10, 92.04it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174400/214001 [31:17<07:12, 91.48it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 174400/214001 [31:18<07:12, 91.48it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174464/214001 [31:18<07:12, 91.36it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174464/214001 [31:19<07:12, 91.36it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174528/214001 [31:19<07:09, 91.93it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174528/214001 [31:20<07:09, 91.93it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174592/214001 [31:20<07:10, 91.63it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174592/214001 [31:20<07:10, 91.63it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174656/214001 [31:20<07:10, 91.34it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174656/214001 [31:21<07:10, 91.34it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174720/214001 [31:21<07:12, 90.86it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174720/214001 [31:22<07:12, 90.86it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174784/214001 [31:22<07:10, 91.10it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174784/214001 [31:22<07:10, 91.10it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174848/214001 [31:22<07:09, 91.11it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174848/214001 [31:23<07:09, 91.11it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174912/214001 [31:23<07:07, 91.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174912/214001 [31:24<07:07, 91.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174976/214001 [31:24<07:07, 91.24it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 174976/214001 [31:24<07:07, 91.24it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175040/214001 [31:24<07:11, 90.24it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175040/214001 [31:25<07:11, 90.24it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175104/214001 [31:25<07:22, 87.99it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175104/214001 [31:26<07:22, 87.99it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175168/214001 [31:26<07:31, 85.97it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175168/214001 [31:27<07:31, 85.97it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175232/214001 [31:27<07:37, 84.78it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175232/214001 [31:28<07:37, 84.78it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175296/214001 [31:28<07:50, 82.25it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175296/214001 [31:28<07:50, 82.25it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175360/214001 [31:28<07:56, 81.04it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175360/214001 [31:29<07:56, 81.04it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175424/214001 [31:29<07:45, 82.81it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175424/214001 [31:30<07:45, 82.81it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175488/214001 [31:30<07:40, 83.64it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175488/214001 [31:31<07:40, 83.64it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175552/214001 [31:31<07:32, 84.95it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175552/214001 [31:31<07:32, 84.95it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175616/214001 [31:31<07:25, 86.19it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175616/214001 [31:32<07:25, 86.19it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175680/214001 [31:32<07:18, 87.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175680/214001 [31:33<07:18, 87.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175744/214001 [31:33<07:17, 87.36it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175744/214001 [31:34<07:17, 87.36it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175808/214001 [31:34<07:12, 88.35it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175808/214001 [31:34<07:12, 88.35it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175872/214001 [31:34<07:07, 89.28it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175872/214001 [31:35<07:07, 89.28it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175936/214001 [31:35<07:07, 89.07it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 175936/214001 [31:36<07:07, 89.07it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176000/214001 [31:36<07:03, 89.76it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176000/214001 [31:36<07:03, 89.76it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176064/214001 [31:36<07:04, 89.46it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176064/214001 [31:37<07:04, 89.46it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176128/214001 [31:37<07:03, 89.47it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176128/214001 [31:38<07:03, 89.47it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176192/214001 [31:38<07:00, 90.02it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176192/214001 [31:39<07:00, 90.02it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176256/214001 [31:39<06:57, 90.47it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176256/214001 [31:39<06:57, 90.47it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176320/214001 [31:39<06:53, 91.18it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176320/214001 [31:40<06:53, 91.18it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176384/214001 [31:40<06:50, 91.53it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176384/214001 [31:41<06:50, 91.53it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176448/214001 [31:41<06:55, 90.34it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176448/214001 [31:41<06:55, 90.34it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176512/214001 [31:41<06:55, 90.30it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 176512/214001 [31:42<06:55, 90.30it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176576/214001 [31:42<06:55, 90.09it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176576/214001 [31:43<06:55, 90.09it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176640/214001 [31:43<06:54, 90.06it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176640/214001 [31:43<06:54, 90.06it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176704/214001 [31:43<06:52, 90.39it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176704/214001 [31:44<06:52, 90.39it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176768/214001 [31:44<06:53, 90.03it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176768/214001 [31:45<06:53, 90.03it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176832/214001 [31:45<06:53, 89.80it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176832/214001 [31:46<06:53, 89.80it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176896/214001 [31:46<06:51, 90.19it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176896/214001 [31:46<06:51, 90.19it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176960/214001 [31:46<06:53, 89.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 176960/214001 [31:47<06:53, 89.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177024/214001 [31:47<06:52, 89.56it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177024/214001 [31:48<06:52, 89.56it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177088/214001 [31:48<06:48, 90.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177088/214001 [31:48<06:48, 90.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177152/214001 [31:48<06:46, 90.68it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177152/214001 [31:49<06:46, 90.68it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177216/214001 [31:49<06:45, 90.77it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177216/214001 [31:50<06:45, 90.77it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177280/214001 [31:50<06:41, 91.49it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177280/214001 [31:51<06:41, 91.49it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177344/214001 [31:51<06:42, 91.12it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177344/214001 [31:51<06:42, 91.12it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177408/214001 [31:51<06:42, 90.95it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177408/214001 [31:52<06:42, 90.95it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177472/214001 [31:52<06:39, 91.41it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177472/214001 [31:53<06:39, 91.41it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177536/214001 [31:53<06:40, 90.95it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177536/214001 [31:53<06:40, 90.95it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177600/214001 [31:53<06:41, 90.67it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177600/214001 [31:54<06:41, 90.67it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177664/214001 [31:54<06:42, 90.24it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177664/214001 [31:55<06:42, 90.24it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177728/214001 [31:55<06:41, 90.33it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177728/214001 [31:55<06:41, 90.33it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177792/214001 [31:55<06:43, 89.76it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177792/214001 [31:56<06:43, 89.76it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177856/214001 [31:56<06:42, 89.82it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177856/214001 [31:57<06:42, 89.82it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177920/214001 [31:57<06:39, 90.33it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177920/214001 [31:58<06:39, 90.33it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177984/214001 [31:58<06:39, 90.08it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 177984/214001 [31:58<06:39, 90.08it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178048/214001 [31:58<06:37, 90.45it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178048/214001 [31:59<06:37, 90.45it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178112/214001 [31:59<06:32, 91.47it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178112/214001 [32:00<06:32, 91.47it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178176/214001 [32:00<06:35, 90.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178176/214001 [32:00<06:35, 90.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178240/214001 [32:00<06:32, 91.01it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178240/214001 [32:01<06:32, 91.01it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178304/214001 [32:01<06:34, 90.49it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178304/214001 [32:02<06:34, 90.49it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178368/214001 [32:02<06:49, 86.95it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178368/214001 [32:03<06:49, 86.95it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178432/214001 [32:03<06:42, 88.32it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178432/214001 [32:03<06:42, 88.32it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178496/214001 [32:03<06:40, 88.66it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178496/214001 [32:04<06:40, 88.66it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178560/214001 [32:04<06:41, 88.20it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178560/214001 [32:05<06:41, 88.20it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178624/214001 [32:05<06:42, 87.95it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178624/214001 [32:06<06:42, 87.95it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178688/214001 [32:06<06:36, 89.06it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 178688/214001 [32:06<06:36, 89.06it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178752/214001 [32:06<06:37, 88.65it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178752/214001 [32:07<06:37, 88.65it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178816/214001 [32:07<06:35, 88.96it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178816/214001 [32:08<06:35, 88.96it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178880/214001 [32:08<06:34, 89.11it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178880/214001 [32:08<06:34, 89.11it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178944/214001 [32:08<06:31, 89.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 178944/214001 [32:09<06:31, 89.64it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179008/214001 [32:09<06:28, 89.96it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179008/214001 [32:10<06:28, 89.96it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179072/214001 [32:10<06:26, 90.48it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179072/214001 [32:10<06:26, 90.48it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179136/214001 [32:10<06:25, 90.51it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179136/214001 [32:11<06:25, 90.51it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179200/214001 [32:11<06:24, 90.53it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 179200/214001 [32:12<06:24, 90.53it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179264/214001 [32:12<06:22, 90.81it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179264/214001 [32:13<06:22, 90.81it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179328/214001 [32:13<06:17, 91.77it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179328/214001 [32:13<06:17, 91.77it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179392/214001 [32:13<06:21, 90.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179392/214001 [32:14<06:21, 90.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179456/214001 [32:14<06:20, 90.82it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179456/214001 [32:15<06:20, 90.82it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179520/214001 [32:15<06:18, 91.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179520/214001 [32:15<06:18, 91.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179584/214001 [32:15<06:20, 90.56it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179584/214001 [32:16<06:20, 90.56it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179648/214001 [32:16<06:20, 90.23it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179648/214001 [32:17<06:20, 90.23it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179712/214001 [32:17<06:19, 90.47it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179712/214001 [32:18<06:19, 90.47it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179776/214001 [32:18<06:18, 90.31it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179776/214001 [32:18<06:18, 90.31it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179840/214001 [32:18<06:18, 90.16it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179840/214001 [32:19<06:18, 90.16it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179904/214001 [32:19<06:18, 90.10it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179904/214001 [32:20<06:18, 90.10it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179968/214001 [32:20<06:18, 90.03it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 179968/214001 [32:20<06:18, 90.03it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180032/214001 [32:20<06:19, 89.50it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180032/214001 [32:21<06:19, 89.50it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180096/214001 [32:21<06:18, 89.46it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180096/214001 [32:22<06:18, 89.46it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180160/214001 [32:22<06:13, 90.60it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180160/214001 [32:22<06:13, 90.60it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180224/214001 [32:23<06:10, 91.20it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180224/214001 [32:23<06:10, 91.20it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180288/214001 [32:23<06:09, 91.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180288/214001 [32:24<06:09, 91.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180352/214001 [32:24<06:11, 90.53it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180352/214001 [32:25<06:11, 90.53it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180416/214001 [32:25<06:12, 90.11it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180416/214001 [32:25<06:12, 90.11it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180480/214001 [32:25<06:09, 90.83it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180480/214001 [32:26<06:09, 90.83it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180544/214001 [32:26<06:01, 92.58it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180544/214001 [32:27<06:01, 92.58it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180608/214001 [32:27<05:59, 92.86it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180608/214001 [32:27<05:59, 92.86it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180672/214001 [32:27<06:01, 92.09it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180672/214001 [32:28<06:01, 92.09it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180736/214001 [32:28<06:02, 91.76it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180736/214001 [32:29<06:02, 91.76it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180800/214001 [32:29<06:03, 91.35it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 180800/214001 [32:29<06:03, 91.35it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 180864/214001 [32:30<06:03, 91.18it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 180864/214001 [32:30<06:03, 91.18it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 180928/214001 [32:30<05:58, 92.30it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 180928/214001 [32:31<05:58, 92.30it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 180992/214001 [32:31<05:57, 92.26it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 180992/214001 [32:32<05:57, 92.26it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181056/214001 [32:32<05:56, 92.39it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181056/214001 [32:32<05:56, 92.39it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181120/214001 [32:32<05:56, 92.18it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181120/214001 [32:33<05:56, 92.18it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181184/214001 [32:33<05:54, 92.68it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181184/214001 [32:34<05:54, 92.68it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181248/214001 [32:34<05:53, 92.78it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181248/214001 [32:34<05:53, 92.78it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181312/214001 [32:34<05:51, 92.89it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181312/214001 [32:35<05:51, 92.89it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181376/214001 [32:35<05:52, 92.44it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181376/214001 [32:36<05:52, 92.44it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181440/214001 [32:36<05:55, 91.70it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181440/214001 [32:36<05:55, 91.70it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181504/214001 [32:36<05:55, 91.40it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181504/214001 [32:37<05:55, 91.40it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181568/214001 [32:37<05:55, 91.35it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181568/214001 [32:38<05:55, 91.35it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181632/214001 [32:38<05:54, 91.29it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181632/214001 [32:39<05:54, 91.29it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181696/214001 [32:39<05:50, 92.08it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181696/214001 [32:39<05:50, 92.08it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181760/214001 [32:39<05:49, 92.21it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181760/214001 [32:40<05:49, 92.21it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181824/214001 [32:40<05:47, 92.49it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181824/214001 [32:41<05:47, 92.49it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181888/214001 [32:41<05:47, 92.40it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 181888/214001 [32:41<05:47, 92.40it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 181952/214001 [32:41<05:49, 91.61it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 181952/214001 [32:42<05:49, 91.61it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182016/214001 [32:42<05:47, 92.12it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182016/214001 [32:43<05:47, 92.12it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182080/214001 [32:43<05:45, 92.33it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182080/214001 [32:43<05:45, 92.33it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182144/214001 [32:43<05:46, 92.00it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182144/214001 [32:44<05:46, 92.00it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182208/214001 [32:44<05:47, 91.58it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182208/214001 [32:45<05:47, 91.58it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182272/214001 [32:45<05:47, 91.18it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182272/214001 [32:45<05:47, 91.18it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182336/214001 [32:46<05:48, 90.93it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182336/214001 [32:46<05:48, 90.93it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182400/214001 [32:46<05:49, 90.46it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182400/214001 [32:47<05:49, 90.46it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182464/214001 [32:47<05:48, 90.54it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182464/214001 [32:48<05:48, 90.54it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182528/214001 [32:48<05:46, 90.72it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182528/214001 [32:48<05:46, 90.72it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182592/214001 [32:48<05:45, 90.92it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182592/214001 [32:49<05:45, 90.92it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182656/214001 [32:49<05:45, 90.77it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182656/214001 [32:50<05:45, 90.77it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182720/214001 [32:50<05:44, 90.68it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182720/214001 [32:50<05:44, 90.68it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182784/214001 [32:50<05:43, 90.85it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182784/214001 [32:51<05:43, 90.85it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182848/214001 [32:51<05:41, 91.15it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182848/214001 [32:52<05:41, 91.15it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182912/214001 [32:52<05:41, 91.11it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 182912/214001 [32:53<05:41, 91.11it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 182976/214001 [32:53<05:41, 90.88it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 182976/214001 [32:53<05:41, 90.88it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183040/214001 [32:53<05:38, 91.42it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183040/214001 [32:54<05:38, 91.42it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183104/214001 [32:54<05:37, 91.64it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183104/214001 [32:55<05:37, 91.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183168/214001 [32:55<05:35, 91.92it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183168/214001 [32:55<05:35, 91.92it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183232/214001 [32:55<05:33, 92.13it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183232/214001 [32:56<05:33, 92.13it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183296/214001 [32:56<05:31, 92.51it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183296/214001 [32:57<05:31, 92.51it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183360/214001 [32:57<05:32, 92.05it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183360/214001 [32:57<05:32, 92.05it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183424/214001 [32:57<05:32, 92.03it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183424/214001 [32:58<05:32, 92.03it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183488/214001 [32:58<05:29, 92.49it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183488/214001 [32:59<05:29, 92.49it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183552/214001 [32:59<05:29, 92.31it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183552/214001 [32:59<05:29, 92.31it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183616/214001 [32:59<05:28, 92.47it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183616/214001 [33:00<05:28, 92.47it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183680/214001 [33:00<05:28, 92.35it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183680/214001 [33:01<05:28, 92.35it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183744/214001 [33:01<05:27, 92.26it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183744/214001 [33:02<05:27, 92.26it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183808/214001 [33:02<05:28, 91.91it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183808/214001 [33:02<05:28, 91.91it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183872/214001 [33:02<05:27, 92.12it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183872/214001 [33:03<05:27, 92.12it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183936/214001 [33:03<05:27, 91.75it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 183936/214001 [33:04<05:27, 91.75it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184000/214001 [33:04<05:28, 91.26it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184000/214001 [33:04<05:28, 91.26it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184064/214001 [33:04<05:26, 91.59it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184064/214001 [33:05<05:26, 91.59it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184128/214001 [33:05<05:33, 89.59it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184128/214001 [33:06<05:33, 89.59it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184192/214001 [33:06<05:32, 89.72it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184192/214001 [33:07<05:32, 89.72it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184256/214001 [33:07<05:28, 90.58it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184256/214001 [33:07<05:28, 90.58it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184320/214001 [33:07<05:31, 89.49it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184320/214001 [33:08<05:31, 89.49it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184384/214001 [33:08<05:32, 89.09it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184384/214001 [33:09<05:32, 89.09it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184448/214001 [33:09<05:28, 89.92it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184448/214001 [33:09<05:28, 89.92it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184512/214001 [33:09<05:23, 91.06it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 184512/214001 [33:10<05:23, 91.06it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184576/214001 [33:10<05:23, 91.08it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184576/214001 [33:11<05:23, 91.08it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184640/214001 [33:11<05:23, 90.77it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184640/214001 [33:11<05:23, 90.77it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184704/214001 [33:11<05:22, 90.79it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184704/214001 [33:12<05:22, 90.79it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184768/214001 [33:12<05:26, 89.58it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184768/214001 [33:13<05:26, 89.58it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184832/214001 [33:13<05:23, 90.12it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184832/214001 [33:14<05:23, 90.12it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184896/214001 [33:14<05:19, 91.15it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184896/214001 [33:14<05:19, 91.15it/s, train_loss=0.5]  \u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184960/214001 [33:14<05:19, 90.96it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 184960/214001 [33:15<05:19, 90.96it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 185024/214001 [33:15<05:22, 89.97it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 185024/214001 [33:16<05:22, 89.97it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 185088/214001 [33:16<05:26, 88.63it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 185088/214001 [33:16<05:26, 88.63it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185152/214001 [33:16<05:23, 89.31it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185152/214001 [33:17<05:23, 89.31it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185216/214001 [33:17<05:19, 90.14it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185216/214001 [33:18<05:19, 90.14it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185280/214001 [33:18<05:20, 89.58it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185280/214001 [33:19<05:20, 89.58it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185344/214001 [33:19<05:17, 90.17it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185344/214001 [33:19<05:17, 90.17it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185408/214001 [33:19<05:15, 90.62it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185408/214001 [33:20<05:15, 90.62it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185472/214001 [33:20<05:15, 90.56it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185472/214001 [33:21<05:15, 90.56it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185536/214001 [33:21<05:21, 88.50it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185536/214001 [33:22<05:21, 88.50it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185600/214001 [33:22<05:23, 87.66it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185600/214001 [33:22<05:23, 87.66it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185664/214001 [33:22<05:22, 87.79it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185664/214001 [33:23<05:22, 87.79it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185728/214001 [33:23<05:20, 88.28it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185728/214001 [33:24<05:20, 88.28it/s, train_loss=0.5]  \u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185792/214001 [33:24<05:20, 88.14it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185792/214001 [33:24<05:20, 88.14it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185856/214001 [33:24<05:17, 88.59it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185856/214001 [33:25<05:17, 88.59it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185920/214001 [33:25<05:12, 89.82it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185920/214001 [33:26<05:12, 89.82it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185984/214001 [33:26<05:10, 90.09it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 185984/214001 [33:26<05:10, 90.09it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186048/214001 [33:27<05:09, 90.18it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186048/214001 [33:27<05:09, 90.18it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186112/214001 [33:27<05:09, 90.02it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186112/214001 [33:28<05:09, 90.02it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186176/214001 [33:28<05:09, 90.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186176/214001 [33:29<05:09, 90.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186240/214001 [33:29<05:06, 90.70it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186240/214001 [33:29<05:06, 90.70it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186304/214001 [33:29<05:03, 91.15it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186304/214001 [33:30<05:03, 91.15it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186368/214001 [33:30<05:02, 91.49it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186368/214001 [33:31<05:02, 91.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186432/214001 [33:31<05:00, 91.83it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186432/214001 [33:31<05:00, 91.83it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186496/214001 [33:31<04:58, 92.08it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186496/214001 [33:32<04:58, 92.08it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186560/214001 [33:32<04:58, 91.83it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186560/214001 [33:33<04:58, 91.83it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186624/214001 [33:33<04:58, 91.63it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186624/214001 [33:33<04:58, 91.63it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186688/214001 [33:33<04:57, 91.83it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186688/214001 [33:34<04:57, 91.83it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186752/214001 [33:34<04:56, 91.95it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186752/214001 [33:35<04:56, 91.95it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186816/214001 [33:35<04:55, 92.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186816/214001 [33:36<04:55, 92.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186880/214001 [33:36<04:55, 91.71it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186880/214001 [33:36<04:55, 91.71it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186944/214001 [33:36<04:54, 91.89it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 186944/214001 [33:37<04:54, 91.89it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187008/214001 [33:37<04:54, 91.78it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187008/214001 [33:38<04:54, 91.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187072/214001 [33:38<04:56, 90.90it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187072/214001 [33:38<04:56, 90.90it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187136/214001 [33:38<04:55, 90.76it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187136/214001 [33:39<04:55, 90.76it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187200/214001 [33:39<04:55, 90.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 187200/214001 [33:40<04:55, 90.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187264/214001 [33:40<04:55, 90.52it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187264/214001 [33:40<04:55, 90.52it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187328/214001 [33:41<04:52, 91.32it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187328/214001 [33:41<04:52, 91.32it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187392/214001 [33:41<04:54, 90.48it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187392/214001 [33:42<04:54, 90.48it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187456/214001 [33:42<04:57, 89.33it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187456/214001 [33:43<04:57, 89.33it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187520/214001 [33:43<04:59, 88.36it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187520/214001 [33:43<04:59, 88.36it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187584/214001 [33:43<04:55, 89.26it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187584/214001 [33:44<04:55, 89.26it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187648/214001 [33:44<04:52, 90.09it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187648/214001 [33:45<04:52, 90.09it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187712/214001 [33:45<04:51, 90.06it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187712/214001 [33:45<04:51, 90.06it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187776/214001 [33:46<04:48, 90.76it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187776/214001 [33:46<04:48, 90.76it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187840/214001 [33:46<04:47, 91.02it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187840/214001 [33:47<04:47, 91.02it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187904/214001 [33:47<04:45, 91.26it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187904/214001 [33:48<04:45, 91.26it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187968/214001 [33:48<04:43, 91.80it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 187968/214001 [33:48<04:43, 91.80it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188032/214001 [33:48<04:44, 91.38it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188032/214001 [33:49<04:44, 91.38it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188096/214001 [33:49<04:44, 91.07it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188096/214001 [33:50<04:44, 91.07it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188160/214001 [33:50<04:43, 91.14it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188160/214001 [33:50<04:43, 91.14it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188224/214001 [33:50<04:42, 91.21it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188224/214001 [33:51<04:42, 91.21it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188288/214001 [33:51<04:44, 90.29it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188288/214001 [33:52<04:44, 90.29it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188352/214001 [33:52<04:47, 89.36it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188352/214001 [33:53<04:47, 89.36it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188416/214001 [33:53<04:48, 88.74it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188416/214001 [33:53<04:48, 88.74it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188480/214001 [33:53<04:44, 89.61it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188480/214001 [33:54<04:44, 89.61it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188544/214001 [33:54<04:40, 90.75it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188544/214001 [33:55<04:40, 90.75it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188608/214001 [33:55<04:38, 91.10it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188608/214001 [33:55<04:38, 91.10it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188672/214001 [33:55<04:39, 90.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188672/214001 [33:56<04:39, 90.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188736/214001 [33:56<04:40, 89.93it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188736/214001 [33:57<04:40, 89.93it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188800/214001 [33:57<04:40, 89.87it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188800/214001 [33:58<04:40, 89.87it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188864/214001 [33:58<04:37, 90.67it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188864/214001 [33:58<04:37, 90.67it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188928/214001 [33:58<04:36, 90.62it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188928/214001 [33:59<04:36, 90.62it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188992/214001 [33:59<04:35, 90.67it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 188992/214001 [34:00<04:35, 90.67it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189056/214001 [34:00<04:36, 90.29it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189056/214001 [34:00<04:36, 90.29it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189120/214001 [34:00<04:33, 90.94it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189120/214001 [34:01<04:33, 90.94it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189184/214001 [34:01<04:31, 91.28it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189184/214001 [34:02<04:31, 91.28it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189248/214001 [34:02<04:31, 91.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189248/214001 [34:02<04:31, 91.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189312/214001 [34:02<04:32, 90.46it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189312/214001 [34:03<04:32, 90.46it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189376/214001 [34:03<04:32, 90.34it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 189376/214001 [34:04<04:32, 90.34it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189440/214001 [34:04<04:31, 90.55it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189440/214001 [34:05<04:31, 90.55it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189504/214001 [34:05<04:28, 91.35it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189504/214001 [34:05<04:28, 91.35it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189568/214001 [34:05<04:25, 91.86it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189568/214001 [34:06<04:25, 91.86it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189632/214001 [34:06<04:26, 91.42it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189632/214001 [34:07<04:26, 91.42it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189696/214001 [34:07<04:25, 91.55it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189696/214001 [34:07<04:25, 91.55it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189760/214001 [34:07<04:23, 91.84it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189760/214001 [34:08<04:23, 91.84it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189824/214001 [34:08<04:25, 91.16it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189824/214001 [34:09<04:25, 91.16it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189888/214001 [34:09<04:23, 91.63it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 189888/214001 [34:09<04:23, 91.63it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 189952/214001 [34:09<04:20, 92.23it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 189952/214001 [34:10<04:20, 92.23it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190016/214001 [34:10<04:20, 91.92it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190016/214001 [34:11<04:20, 91.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190080/214001 [34:11<04:23, 90.86it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190080/214001 [34:12<04:23, 90.86it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190144/214001 [34:12<04:19, 91.91it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190144/214001 [34:12<04:19, 91.91it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190208/214001 [34:12<04:20, 91.35it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190208/214001 [34:13<04:20, 91.35it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190272/214001 [34:13<04:21, 90.72it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190272/214001 [34:14<04:21, 90.72it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190336/214001 [34:14<04:20, 90.70it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190336/214001 [34:14<04:20, 90.70it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190400/214001 [34:14<04:19, 91.06it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190400/214001 [34:15<04:19, 91.06it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190464/214001 [34:15<04:20, 90.41it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190464/214001 [34:16<04:20, 90.41it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190528/214001 [34:16<04:15, 91.94it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190528/214001 [34:16<04:15, 91.94it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190592/214001 [34:16<04:16, 91.36it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190592/214001 [34:17<04:16, 91.36it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190656/214001 [34:17<04:14, 91.65it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190656/214001 [34:18<04:14, 91.65it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190720/214001 [34:18<04:12, 92.09it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190720/214001 [34:19<04:12, 92.09it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190784/214001 [34:19<04:12, 91.89it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190784/214001 [34:19<04:12, 91.89it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190848/214001 [34:19<04:11, 92.12it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190848/214001 [34:20<04:11, 92.12it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190912/214001 [34:20<04:10, 92.34it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190912/214001 [34:21<04:10, 92.34it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190976/214001 [34:21<04:11, 91.61it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 190976/214001 [34:21<04:11, 91.61it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191040/214001 [34:21<04:11, 91.45it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191040/214001 [34:22<04:11, 91.45it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191104/214001 [34:22<04:08, 92.07it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191104/214001 [34:23<04:08, 92.07it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191168/214001 [34:23<04:09, 91.51it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191168/214001 [34:23<04:09, 91.51it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191232/214001 [34:23<04:08, 91.76it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191232/214001 [34:24<04:08, 91.76it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191296/214001 [34:24<04:07, 91.57it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191296/214001 [34:25<04:07, 91.57it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191360/214001 [34:25<04:05, 92.09it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191360/214001 [34:25<04:05, 92.09it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191424/214001 [34:25<04:03, 92.54it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191424/214001 [34:26<04:03, 92.54it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191488/214001 [34:26<04:03, 92.62it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 191488/214001 [34:27<04:03, 92.62it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191552/214001 [34:27<04:01, 92.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191552/214001 [34:28<04:01, 92.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191616/214001 [34:28<04:00, 92.88it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191616/214001 [34:28<04:00, 92.88it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191680/214001 [34:28<04:02, 91.93it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191680/214001 [34:29<04:02, 91.93it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191744/214001 [34:29<04:01, 92.16it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191744/214001 [34:30<04:01, 92.16it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191808/214001 [34:30<04:02, 91.33it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191808/214001 [34:30<04:02, 91.33it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191872/214001 [34:30<04:03, 90.82it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191872/214001 [34:31<04:03, 90.82it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191936/214001 [34:31<04:01, 91.47it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 191936/214001 [34:32<04:01, 91.47it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192000/214001 [34:32<03:59, 91.97it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192000/214001 [34:32<03:59, 91.97it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192064/214001 [34:33<04:02, 90.28it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192064/214001 [34:33<04:02, 90.28it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192128/214001 [34:33<04:03, 89.87it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192128/214001 [34:34<04:03, 89.87it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192192/214001 [34:34<04:02, 89.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192192/214001 [34:35<04:02, 89.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192256/214001 [34:35<03:59, 90.76it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192256/214001 [34:35<03:59, 90.76it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192320/214001 [34:35<03:57, 91.12it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192320/214001 [34:36<03:57, 91.12it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192384/214001 [34:36<03:58, 90.56it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192384/214001 [34:37<03:58, 90.56it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192448/214001 [34:37<04:04, 88.22it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192448/214001 [34:37<04:04, 88.22it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192512/214001 [34:38<04:00, 89.23it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192512/214001 [34:38<04:00, 89.23it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192576/214001 [34:38<03:59, 89.59it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 192576/214001 [34:39<03:59, 89.59it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192640/214001 [34:39<03:55, 90.67it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192640/214001 [34:40<03:55, 90.67it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192704/214001 [34:40<03:52, 91.78it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192704/214001 [34:40<03:52, 91.78it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192768/214001 [34:40<03:50, 92.06it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192768/214001 [34:41<03:50, 92.06it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192832/214001 [34:41<03:49, 92.10it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192832/214001 [34:42<03:49, 92.10it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192896/214001 [34:42<03:47, 92.68it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192896/214001 [34:42<03:47, 92.68it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192960/214001 [34:42<03:49, 91.76it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 192960/214001 [34:43<03:49, 91.76it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193024/214001 [34:43<03:47, 92.06it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193024/214001 [34:44<03:47, 92.06it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193088/214001 [34:44<03:45, 92.55it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193088/214001 [34:44<03:45, 92.55it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193152/214001 [34:44<03:45, 92.45it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193152/214001 [34:45<03:45, 92.45it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193216/214001 [34:45<03:47, 91.50it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193216/214001 [34:46<03:47, 91.50it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193280/214001 [34:46<03:46, 91.49it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193280/214001 [34:47<03:46, 91.49it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193344/214001 [34:47<03:45, 91.49it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193344/214001 [34:47<03:45, 91.49it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193408/214001 [34:47<03:46, 91.01it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193408/214001 [34:48<03:46, 91.01it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193472/214001 [34:48<03:47, 90.19it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193472/214001 [34:49<03:47, 90.19it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193536/214001 [34:49<03:54, 87.43it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193536/214001 [34:49<03:54, 87.43it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193600/214001 [34:49<03:53, 87.35it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193600/214001 [34:50<03:53, 87.35it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193664/214001 [34:50<03:52, 87.57it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 193664/214001 [34:51<03:52, 87.57it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193728/214001 [34:51<03:47, 89.26it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193728/214001 [34:52<03:47, 89.26it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193792/214001 [34:52<03:43, 90.23it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193792/214001 [34:52<03:43, 90.23it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193856/214001 [34:52<03:43, 90.08it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193856/214001 [34:53<03:43, 90.08it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193920/214001 [34:53<03:41, 90.78it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193920/214001 [34:54<03:41, 90.78it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193984/214001 [34:54<03:39, 91.13it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 193984/214001 [34:54<03:39, 91.13it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194048/214001 [34:54<03:38, 91.42it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194048/214001 [34:55<03:38, 91.42it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194112/214001 [34:55<03:37, 91.61it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194112/214001 [34:56<03:37, 91.61it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194176/214001 [34:56<03:35, 91.98it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194176/214001 [34:56<03:35, 91.98it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194240/214001 [34:56<03:35, 91.89it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194240/214001 [34:57<03:35, 91.89it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194304/214001 [34:57<03:36, 90.83it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194304/214001 [34:58<03:36, 90.83it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194368/214001 [34:58<03:34, 91.39it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194368/214001 [34:59<03:34, 91.39it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194432/214001 [34:59<03:34, 91.21it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194432/214001 [34:59<03:34, 91.21it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194496/214001 [34:59<03:34, 91.04it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194496/214001 [35:00<03:34, 91.04it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194560/214001 [35:00<03:32, 91.30it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194560/214001 [35:01<03:32, 91.30it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194624/214001 [35:01<03:34, 90.48it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194624/214001 [35:01<03:34, 90.48it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194688/214001 [35:01<03:35, 89.54it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194688/214001 [35:02<03:35, 89.54it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194752/214001 [35:02<03:33, 90.16it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194752/214001 [35:03<03:33, 90.16it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194816/214001 [35:03<03:33, 89.76it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194816/214001 [35:04<03:33, 89.76it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194880/214001 [35:04<03:32, 89.93it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194880/214001 [35:04<03:32, 89.93it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194944/214001 [35:04<03:32, 89.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 194944/214001 [35:05<03:32, 89.86it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195008/214001 [35:05<03:31, 89.67it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195008/214001 [35:06<03:31, 89.67it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195072/214001 [35:06<03:31, 89.38it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195072/214001 [35:06<03:31, 89.38it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195136/214001 [35:06<03:29, 89.97it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195136/214001 [35:07<03:29, 89.97it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195200/214001 [35:07<03:26, 91.11it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195200/214001 [35:08<03:26, 91.11it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195264/214001 [35:08<03:24, 91.65it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 195264/214001 [35:08<03:24, 91.65it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195328/214001 [35:08<03:23, 91.84it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195328/214001 [35:09<03:23, 91.84it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195392/214001 [35:09<03:22, 91.75it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195392/214001 [35:10<03:22, 91.75it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195456/214001 [35:10<03:23, 91.21it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195456/214001 [35:11<03:23, 91.21it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195520/214001 [35:11<03:21, 91.83it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195520/214001 [35:11<03:21, 91.83it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195584/214001 [35:11<03:18, 92.64it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195584/214001 [35:12<03:18, 92.64it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195648/214001 [35:12<03:18, 92.30it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195648/214001 [35:13<03:18, 92.30it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195712/214001 [35:13<03:19, 91.84it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195712/214001 [35:13<03:19, 91.84it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195776/214001 [35:13<03:18, 91.75it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 195776/214001 [35:14<03:18, 91.75it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 195840/214001 [35:14<03:19, 90.84it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 195840/214001 [35:15<03:19, 90.84it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 195904/214001 [35:15<03:18, 91.22it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 195904/214001 [35:15<03:18, 91.22it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 195968/214001 [35:15<03:17, 91.38it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 195968/214001 [35:16<03:17, 91.38it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196032/214001 [35:16<03:16, 91.31it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196032/214001 [35:17<03:16, 91.31it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196096/214001 [35:17<03:16, 90.95it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196096/214001 [35:18<03:16, 90.95it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196160/214001 [35:18<03:15, 91.14it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196160/214001 [35:18<03:15, 91.14it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196224/214001 [35:18<03:15, 91.08it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196224/214001 [35:19<03:15, 91.08it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196288/214001 [35:19<03:15, 90.51it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196288/214001 [35:20<03:15, 90.51it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196352/214001 [35:20<03:14, 90.68it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196352/214001 [35:20<03:14, 90.68it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196416/214001 [35:20<03:14, 90.52it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196416/214001 [35:21<03:14, 90.52it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196480/214001 [35:21<03:13, 90.38it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196480/214001 [35:22<03:13, 90.38it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196544/214001 [35:22<03:11, 91.16it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196544/214001 [35:23<03:11, 91.16it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196608/214001 [35:23<03:10, 91.16it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196608/214001 [35:23<03:10, 91.16it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196672/214001 [35:23<03:10, 90.94it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196672/214001 [35:24<03:10, 90.94it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196736/214001 [35:24<03:09, 90.91it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196736/214001 [35:25<03:09, 90.91it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196800/214001 [35:25<03:09, 90.75it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196800/214001 [35:25<03:09, 90.75it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196864/214001 [35:25<03:08, 90.76it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196864/214001 [35:26<03:08, 90.76it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196928/214001 [35:26<03:06, 91.32it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196928/214001 [35:27<03:06, 91.32it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196992/214001 [35:27<03:06, 91.16it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 196992/214001 [35:27<03:06, 91.16it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197056/214001 [35:27<03:07, 90.14it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197056/214001 [35:28<03:07, 90.14it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197120/214001 [35:28<03:06, 90.41it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197120/214001 [35:29<03:06, 90.41it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197184/214001 [35:29<03:05, 90.64it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197184/214001 [35:30<03:05, 90.64it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197248/214001 [35:30<03:05, 90.24it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197248/214001 [35:30<03:05, 90.24it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197312/214001 [35:30<03:05, 89.76it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197312/214001 [35:31<03:05, 89.76it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197376/214001 [35:31<03:04, 90.03it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197376/214001 [35:32<03:04, 90.03it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197440/214001 [35:32<03:04, 89.91it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197440/214001 [35:32<03:04, 89.91it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197504/214001 [35:32<03:03, 90.13it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197504/214001 [35:33<03:03, 90.13it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197568/214001 [35:33<03:01, 90.75it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197568/214001 [35:34<03:01, 90.75it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197632/214001 [35:34<02:59, 91.20it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197632/214001 [35:35<02:59, 91.20it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197696/214001 [35:35<02:58, 91.29it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197696/214001 [35:35<02:58, 91.29it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197760/214001 [35:35<02:58, 90.94it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197760/214001 [35:36<02:58, 90.94it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197824/214001 [35:36<02:57, 91.18it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197824/214001 [35:37<02:57, 91.18it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197888/214001 [35:37<02:58, 90.29it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 197888/214001 [35:37<02:58, 90.29it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 197952/214001 [35:37<02:55, 91.21it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 197952/214001 [35:38<02:55, 91.21it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198016/214001 [35:38<02:55, 91.24it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198016/214001 [35:39<02:55, 91.24it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198080/214001 [35:39<02:53, 91.51it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198080/214001 [35:39<02:53, 91.51it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198144/214001 [35:39<02:52, 91.89it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198144/214001 [35:40<02:52, 91.89it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198208/214001 [35:40<02:52, 91.72it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198208/214001 [35:41<02:52, 91.72it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198272/214001 [35:41<02:50, 92.39it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198272/214001 [35:41<02:50, 92.39it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198336/214001 [35:42<02:49, 92.65it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198336/214001 [35:42<02:49, 92.65it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198400/214001 [35:42<02:49, 92.08it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198400/214001 [35:43<02:49, 92.08it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198464/214001 [35:43<02:49, 91.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198464/214001 [35:44<02:49, 91.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198528/214001 [35:44<02:47, 92.54it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198528/214001 [35:44<02:47, 92.54it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198592/214001 [35:44<02:46, 92.71it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198592/214001 [35:45<02:46, 92.71it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198656/214001 [35:45<02:45, 92.58it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198656/214001 [35:46<02:45, 92.58it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198720/214001 [35:46<02:45, 92.32it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198720/214001 [35:46<02:45, 92.32it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198784/214001 [35:46<02:44, 92.37it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198784/214001 [35:47<02:44, 92.37it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198848/214001 [35:47<02:45, 91.50it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198848/214001 [35:48<02:45, 91.50it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198912/214001 [35:48<02:44, 91.78it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198912/214001 [35:48<02:44, 91.78it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198976/214001 [35:48<02:42, 92.56it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 198976/214001 [35:49<02:42, 92.56it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199040/214001 [35:49<02:42, 92.33it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199040/214001 [35:50<02:42, 92.33it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199104/214001 [35:50<02:41, 92.47it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199104/214001 [35:50<02:41, 92.47it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199168/214001 [35:51<02:39, 93.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199168/214001 [35:51<02:39, 93.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199232/214001 [35:51<02:39, 92.66it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199232/214001 [35:52<02:39, 92.66it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199296/214001 [35:52<02:40, 91.86it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199296/214001 [35:53<02:40, 91.86it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199360/214001 [35:53<02:38, 92.32it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199360/214001 [35:53<02:38, 92.32it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199424/214001 [35:53<02:38, 92.21it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199424/214001 [35:54<02:38, 92.21it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199488/214001 [35:54<02:38, 91.73it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199488/214001 [35:55<02:38, 91.73it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199552/214001 [35:55<02:37, 91.82it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199552/214001 [35:55<02:37, 91.82it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199616/214001 [35:55<02:37, 91.52it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199616/214001 [35:56<02:37, 91.52it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199680/214001 [35:56<02:36, 91.32it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199680/214001 [35:57<02:36, 91.32it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199744/214001 [35:57<02:36, 91.05it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199744/214001 [35:58<02:36, 91.05it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199808/214001 [35:58<02:36, 90.79it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199808/214001 [35:58<02:36, 90.79it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199872/214001 [35:58<02:35, 90.60it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199872/214001 [35:59<02:35, 90.60it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199936/214001 [35:59<02:34, 91.07it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 199936/214001 [36:00<02:34, 91.07it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 200000/214001 [36:00<02:33, 91.12it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 200000/214001 [36:00<02:33, 91.12it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 200064/214001 [36:00<02:32, 91.24it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 200064/214001 [36:01<02:32, 91.24it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200128/214001 [36:01<02:32, 91.11it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200128/214001 [36:02<02:32, 91.11it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200192/214001 [36:02<02:31, 91.01it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200192/214001 [36:02<02:31, 91.01it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200256/214001 [36:02<02:29, 91.80it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200256/214001 [36:03<02:29, 91.80it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200320/214001 [36:03<02:28, 92.21it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200320/214001 [36:04<02:28, 92.21it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200384/214001 [36:04<02:27, 92.11it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200384/214001 [36:04<02:27, 92.11it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200448/214001 [36:04<02:26, 92.59it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200448/214001 [36:05<02:26, 92.59it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200512/214001 [36:05<02:25, 92.68it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200512/214001 [36:06<02:25, 92.68it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200576/214001 [36:06<02:25, 92.12it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 200576/214001 [36:07<02:25, 92.12it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200640/214001 [36:07<02:25, 92.11it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200640/214001 [36:07<02:25, 92.11it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200704/214001 [36:07<02:23, 92.70it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200704/214001 [36:08<02:23, 92.70it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200768/214001 [36:08<02:22, 92.79it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200768/214001 [36:09<02:22, 92.79it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200832/214001 [36:09<02:22, 92.35it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200832/214001 [36:09<02:22, 92.35it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200896/214001 [36:09<02:21, 92.57it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200896/214001 [36:10<02:21, 92.57it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200960/214001 [36:10<02:21, 92.14it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 200960/214001 [36:11<02:21, 92.14it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201024/214001 [36:11<02:21, 91.78it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201024/214001 [36:11<02:21, 91.78it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201088/214001 [36:11<02:19, 92.36it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201088/214001 [36:12<02:19, 92.36it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201152/214001 [36:12<02:18, 92.54it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201152/214001 [36:13<02:18, 92.54it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201216/214001 [36:13<02:18, 92.33it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201216/214001 [36:13<02:18, 92.33it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201280/214001 [36:13<02:17, 92.61it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201280/214001 [36:14<02:17, 92.61it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201344/214001 [36:14<02:17, 92.14it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201344/214001 [36:15<02:17, 92.14it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201408/214001 [36:15<02:16, 92.59it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201408/214001 [36:16<02:16, 92.59it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201472/214001 [36:16<02:14, 93.04it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201472/214001 [36:16<02:14, 93.04it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201536/214001 [36:16<02:14, 92.41it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201536/214001 [36:17<02:14, 92.41it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201600/214001 [36:17<02:13, 92.56it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201600/214001 [36:18<02:13, 92.56it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201664/214001 [36:18<02:13, 92.61it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201664/214001 [36:18<02:13, 92.61it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201728/214001 [36:18<02:13, 91.86it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201728/214001 [36:19<02:13, 91.86it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201792/214001 [36:19<02:13, 91.64it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201792/214001 [36:20<02:13, 91.64it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201856/214001 [36:20<02:12, 91.35it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201856/214001 [36:20<02:12, 91.35it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201920/214001 [36:20<02:12, 91.40it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201920/214001 [36:21<02:12, 91.40it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201984/214001 [36:21<02:11, 91.51it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 201984/214001 [36:22<02:11, 91.51it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 202048/214001 [36:22<02:10, 91.50it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 202048/214001 [36:23<02:10, 91.50it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 202112/214001 [36:23<02:09, 91.85it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 202112/214001 [36:23<02:09, 91.85it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 202176/214001 [36:23<02:09, 91.20it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 202176/214001 [36:24<02:09, 91.20it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202240/214001 [36:24<02:08, 91.23it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202240/214001 [36:25<02:08, 91.23it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202304/214001 [36:25<02:07, 91.51it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202304/214001 [36:25<02:07, 91.51it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202368/214001 [36:25<02:07, 90.96it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202368/214001 [36:26<02:07, 90.96it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202432/214001 [36:26<02:07, 90.41it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202432/214001 [36:27<02:07, 90.41it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202496/214001 [36:27<02:06, 91.21it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202496/214001 [36:27<02:06, 91.21it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202560/214001 [36:27<02:04, 91.60it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202560/214001 [36:28<02:04, 91.60it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202624/214001 [36:28<02:04, 91.72it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202624/214001 [36:29<02:04, 91.72it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202688/214001 [36:29<02:03, 91.84it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202688/214001 [36:30<02:03, 91.84it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202752/214001 [36:30<02:03, 90.77it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202752/214001 [36:30<02:03, 90.77it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202816/214001 [36:30<02:03, 90.78it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202816/214001 [36:31<02:03, 90.78it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202880/214001 [36:31<02:01, 91.38it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202880/214001 [36:32<02:01, 91.38it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202944/214001 [36:32<02:01, 91.21it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 202944/214001 [36:32<02:01, 91.21it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203008/214001 [36:32<01:59, 91.66it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203008/214001 [36:33<01:59, 91.66it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203072/214001 [36:33<01:59, 91.58it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203072/214001 [36:34<01:59, 91.58it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203136/214001 [36:34<01:58, 91.66it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203136/214001 [36:34<01:58, 91.66it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203200/214001 [36:34<01:58, 91.06it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203200/214001 [36:35<01:58, 91.06it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203264/214001 [36:35<01:57, 91.32it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 203264/214001 [36:36<01:57, 91.32it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203328/214001 [36:36<01:56, 91.79it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203328/214001 [36:37<01:56, 91.79it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203392/214001 [36:37<01:55, 91.65it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203392/214001 [36:37<01:55, 91.65it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203456/214001 [36:37<01:54, 91.83it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203456/214001 [36:38<01:54, 91.83it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203520/214001 [36:38<01:55, 90.72it/s, train_loss=0.492]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203520/214001 [36:39<01:55, 90.72it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203584/214001 [36:39<01:55, 89.94it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203584/214001 [36:39<01:55, 89.94it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203648/214001 [36:39<01:53, 91.06it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203648/214001 [36:40<01:53, 91.06it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203712/214001 [36:40<01:52, 91.52it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203712/214001 [36:41<01:52, 91.52it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203776/214001 [36:41<01:51, 91.52it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203776/214001 [36:41<01:51, 91.52it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203840/214001 [36:42<01:51, 90.87it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203840/214001 [36:42<01:51, 90.87it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203904/214001 [36:42<01:50, 91.24it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203904/214001 [36:43<01:50, 91.24it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203968/214001 [36:43<01:50, 90.68it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 203968/214001 [36:44<01:50, 90.68it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204032/214001 [36:44<01:48, 91.76it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204032/214001 [36:44<01:48, 91.76it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204096/214001 [36:44<01:49, 90.35it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204096/214001 [36:45<01:49, 90.35it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204160/214001 [36:45<01:51, 88.30it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204160/214001 [36:46<01:51, 88.30it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204224/214001 [36:46<01:51, 88.07it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204224/214001 [36:46<01:51, 88.07it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204288/214001 [36:47<01:48, 89.66it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204288/214001 [36:47<01:48, 89.66it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204352/214001 [36:47<01:46, 90.22it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 204352/214001 [36:48<01:46, 90.22it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204416/214001 [36:48<01:45, 90.51it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204416/214001 [36:49<01:45, 90.51it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204480/214001 [36:49<01:46, 89.36it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204480/214001 [36:49<01:46, 89.36it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204544/214001 [36:49<01:49, 86.42it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204544/214001 [36:50<01:49, 86.42it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204608/214001 [36:50<01:50, 84.71it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204608/214001 [36:51<01:50, 84.71it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204672/214001 [36:51<01:48, 85.77it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204672/214001 [36:52<01:48, 85.77it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204736/214001 [36:52<01:48, 85.18it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204736/214001 [36:52<01:48, 85.18it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204800/214001 [36:52<01:48, 85.12it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204800/214001 [36:54<01:48, 85.12it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204864/214001 [36:54<02:00, 75.55it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204864/214001 [36:55<02:00, 75.55it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204928/214001 [36:55<02:09, 70.06it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204928/214001 [36:56<02:09, 70.06it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204992/214001 [36:56<02:13, 67.69it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 204992/214001 [36:57<02:13, 67.69it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205056/214001 [36:57<02:15, 65.91it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205056/214001 [36:58<02:15, 65.91it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205120/214001 [36:58<02:18, 64.20it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205120/214001 [36:58<02:18, 64.20it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205184/214001 [36:58<02:07, 69.19it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205184/214001 [36:59<02:07, 69.19it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205248/214001 [36:59<01:59, 73.30it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205248/214001 [37:00<01:59, 73.30it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205312/214001 [37:00<01:53, 76.65it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205312/214001 [37:01<01:53, 76.65it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205376/214001 [37:01<01:47, 80.30it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205376/214001 [37:01<01:47, 80.30it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205440/214001 [37:01<01:43, 82.91it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205440/214001 [37:02<01:43, 82.91it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205504/214001 [37:02<01:39, 85.08it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205504/214001 [37:03<01:39, 85.08it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205568/214001 [37:03<01:37, 86.60it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205568/214001 [37:04<01:37, 86.60it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205632/214001 [37:04<01:35, 87.38it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205632/214001 [37:04<01:35, 87.38it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205696/214001 [37:04<01:33, 88.69it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205696/214001 [37:05<01:33, 88.69it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205760/214001 [37:05<01:33, 87.86it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205760/214001 [37:06<01:33, 87.86it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205824/214001 [37:06<01:33, 87.26it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205824/214001 [37:06<01:33, 87.26it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205888/214001 [37:06<01:32, 87.56it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205888/214001 [37:07<01:32, 87.56it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205952/214001 [37:07<01:32, 87.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 205952/214001 [37:08<01:32, 87.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206016/214001 [37:08<01:31, 87.19it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206016/214001 [37:09<01:31, 87.19it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206080/214001 [37:09<01:30, 87.10it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206080/214001 [37:09<01:30, 87.10it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206144/214001 [37:09<01:29, 87.32it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206144/214001 [37:10<01:29, 87.32it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206208/214001 [37:10<01:28, 88.39it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206208/214001 [37:11<01:28, 88.39it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206272/214001 [37:11<01:27, 88.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206272/214001 [37:12<01:27, 88.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206336/214001 [37:12<01:26, 88.47it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206336/214001 [37:12<01:26, 88.47it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206400/214001 [37:12<01:26, 87.72it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206400/214001 [37:13<01:26, 87.72it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206464/214001 [37:13<01:26, 87.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 206464/214001 [37:14<01:26, 87.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206528/214001 [37:14<01:25, 87.58it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206528/214001 [37:14<01:25, 87.58it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206592/214001 [37:14<01:24, 87.64it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206592/214001 [37:15<01:24, 87.64it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206656/214001 [37:15<01:23, 88.31it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206656/214001 [37:16<01:23, 88.31it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206720/214001 [37:16<01:22, 88.75it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206720/214001 [37:17<01:22, 88.75it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206784/214001 [37:17<01:20, 89.33it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206784/214001 [37:17<01:20, 89.33it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206848/214001 [37:17<01:20, 89.04it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206848/214001 [37:18<01:20, 89.04it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206912/214001 [37:18<01:19, 89.16it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206912/214001 [37:19<01:19, 89.16it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206976/214001 [37:19<01:18, 89.51it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 206976/214001 [37:19<01:18, 89.51it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207040/214001 [37:19<01:17, 89.56it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207040/214001 [37:20<01:17, 89.56it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207104/214001 [37:20<01:17, 88.86it/s, train_loss=0.491]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207104/214001 [37:21<01:17, 88.86it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207168/214001 [37:21<01:17, 88.28it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207168/214001 [37:22<01:17, 88.28it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207232/214001 [37:22<01:16, 88.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207232/214001 [37:22<01:16, 88.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207296/214001 [37:22<01:15, 89.34it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207296/214001 [37:23<01:15, 89.34it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207360/214001 [37:23<01:13, 90.52it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207360/214001 [37:24<01:13, 90.52it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207424/214001 [37:24<01:13, 89.58it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207424/214001 [37:25<01:13, 89.58it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207488/214001 [37:25<01:13, 88.37it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207488/214001 [37:25<01:13, 88.37it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207552/214001 [37:25<01:13, 87.88it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207552/214001 [37:26<01:13, 87.88it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207616/214001 [37:26<01:14, 86.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207616/214001 [37:27<01:14, 86.17it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207680/214001 [37:27<01:13, 86.28it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207680/214001 [37:28<01:13, 86.28it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207744/214001 [37:28<01:13, 85.33it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207744/214001 [37:28<01:13, 85.33it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207808/214001 [37:28<01:12, 85.59it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207808/214001 [37:29<01:12, 85.59it/s, train_loss=0.49] \u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207872/214001 [37:29<01:12, 84.67it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207872/214001 [37:30<01:12, 84.67it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207936/214001 [37:30<01:12, 83.97it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 207936/214001 [37:31<01:12, 83.97it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208000/214001 [37:31<01:11, 83.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208000/214001 [37:31<01:11, 83.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208064/214001 [37:31<01:10, 84.35it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208064/214001 [37:32<01:10, 84.35it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208128/214001 [37:32<01:08, 85.12it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208128/214001 [37:33<01:08, 85.12it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208192/214001 [37:33<01:07, 86.04it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208192/214001 [37:34<01:07, 86.04it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208256/214001 [37:34<01:05, 87.05it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208256/214001 [37:34<01:05, 87.05it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208320/214001 [37:34<01:05, 87.07it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208320/214001 [37:35<01:05, 87.07it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208384/214001 [37:35<01:05, 86.16it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208384/214001 [37:36<01:05, 86.16it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208448/214001 [37:36<01:05, 85.25it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208448/214001 [37:37<01:05, 85.25it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208512/214001 [37:37<01:04, 85.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208512/214001 [37:37<01:04, 85.65it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208576/214001 [37:37<01:02, 86.64it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208576/214001 [37:38<01:02, 86.64it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208640/214001 [37:38<01:01, 87.23it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 208640/214001 [37:39<01:01, 87.23it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208704/214001 [37:39<01:00, 87.29it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208704/214001 [37:39<01:00, 87.29it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208768/214001 [37:39<00:59, 88.53it/s, train_loss=0.49]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208768/214001 [37:40<00:59, 88.53it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208832/214001 [37:40<00:58, 88.66it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208832/214001 [37:41<00:58, 88.66it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208896/214001 [37:41<00:56, 89.89it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208896/214001 [37:41<00:56, 89.89it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208960/214001 [37:41<00:55, 90.70it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 208960/214001 [37:42<00:55, 90.70it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209024/214001 [37:42<00:54, 90.74it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209024/214001 [37:43<00:54, 90.74it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209088/214001 [37:43<00:54, 90.63it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209088/214001 [37:44<00:54, 90.63it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209152/214001 [37:44<00:53, 90.76it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209152/214001 [37:44<00:53, 90.76it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209216/214001 [37:44<00:53, 88.66it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209216/214001 [37:45<00:53, 88.66it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209280/214001 [37:45<00:52, 89.49it/s, train_loss=0.489]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209280/214001 [37:46<00:52, 89.49it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209344/214001 [37:46<00:51, 91.08it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209344/214001 [37:46<00:51, 91.08it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209408/214001 [37:46<00:50, 90.90it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209408/214001 [37:47<00:50, 90.90it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209472/214001 [37:47<00:49, 91.45it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209472/214001 [37:48<00:49, 91.45it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209536/214001 [37:48<00:48, 91.45it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209536/214001 [37:49<00:48, 91.45it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209600/214001 [37:49<00:48, 91.30it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209600/214001 [37:49<00:48, 91.30it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209664/214001 [37:49<00:47, 91.60it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209664/214001 [37:50<00:47, 91.60it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209728/214001 [37:50<00:46, 91.68it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209728/214001 [37:51<00:46, 91.68it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209792/214001 [37:51<00:46, 91.42it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209792/214001 [37:51<00:46, 91.42it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209856/214001 [37:51<00:46, 89.90it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209856/214001 [37:52<00:46, 89.90it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209920/214001 [37:52<00:45, 90.41it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209920/214001 [37:53<00:45, 90.41it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209984/214001 [37:53<00:44, 90.70it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 209984/214001 [37:53<00:44, 90.70it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210048/214001 [37:53<00:43, 90.35it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210048/214001 [37:54<00:43, 90.35it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210112/214001 [37:54<00:43, 89.39it/s, train_loss=0.488]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210112/214001 [37:55<00:43, 89.39it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210176/214001 [37:55<00:42, 89.63it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210176/214001 [37:56<00:42, 89.63it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210240/214001 [37:56<00:42, 89.50it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210240/214001 [37:56<00:42, 89.50it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210304/214001 [37:56<00:41, 89.90it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210304/214001 [37:57<00:41, 89.90it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210368/214001 [37:57<00:40, 90.69it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210368/214001 [37:58<00:40, 90.69it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210432/214001 [37:58<00:39, 90.81it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210432/214001 [37:58<00:39, 90.81it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210496/214001 [37:58<00:38, 91.03it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210496/214001 [37:59<00:38, 91.03it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210560/214001 [37:59<00:37, 91.08it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210560/214001 [38:00<00:37, 91.08it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210624/214001 [38:00<00:37, 90.94it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210624/214001 [38:01<00:37, 90.94it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210688/214001 [38:01<00:36, 90.14it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210688/214001 [38:01<00:36, 90.14it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210752/214001 [38:01<00:35, 90.59it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 210752/214001 [38:02<00:35, 90.59it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 210816/214001 [38:02<00:35, 90.87it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 210816/214001 [38:03<00:35, 90.87it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 210880/214001 [38:03<00:34, 90.17it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 210880/214001 [38:03<00:34, 90.17it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 210944/214001 [38:03<00:34, 88.63it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 210944/214001 [38:04<00:34, 88.63it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211008/214001 [38:04<00:33, 88.58it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211008/214001 [38:05<00:33, 88.58it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211072/214001 [38:05<00:32, 89.61it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211072/214001 [38:06<00:32, 89.61it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211136/214001 [38:06<00:31, 90.79it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211136/214001 [38:06<00:31, 90.79it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211200/214001 [38:06<00:31, 89.24it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211200/214001 [38:07<00:31, 89.24it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211264/214001 [38:07<00:30, 88.33it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 211264/214001 [38:08<00:30, 88.33it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211328/214001 [38:08<00:29, 89.28it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211328/214001 [38:08<00:29, 89.28it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211392/214001 [38:08<00:29, 89.72it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211392/214001 [38:09<00:29, 89.72it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211456/214001 [38:09<00:28, 89.34it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211456/214001 [38:10<00:28, 89.34it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211520/214001 [38:10<00:27, 88.78it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211520/214001 [38:11<00:27, 88.78it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211584/214001 [38:11<00:27, 88.78it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211584/214001 [38:11<00:27, 88.78it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211648/214001 [38:11<00:26, 88.74it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211648/214001 [38:12<00:26, 88.74it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211712/214001 [38:12<00:25, 89.52it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211712/214001 [38:13<00:25, 89.52it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211776/214001 [38:13<00:24, 89.99it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211776/214001 [38:13<00:24, 89.99it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211840/214001 [38:13<00:24, 89.77it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211840/214001 [38:14<00:24, 89.77it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211904/214001 [38:14<00:23, 89.40it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211904/214001 [38:15<00:23, 89.40it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211968/214001 [38:15<00:22, 89.56it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 211968/214001 [38:16<00:22, 89.56it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212032/214001 [38:16<00:22, 88.96it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212032/214001 [38:16<00:22, 88.96it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212096/214001 [38:16<00:21, 88.35it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212096/214001 [38:17<00:21, 88.35it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212160/214001 [38:17<00:20, 88.72it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212160/214001 [38:18<00:20, 88.72it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212224/214001 [38:18<00:19, 89.15it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212224/214001 [38:19<00:19, 89.15it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212288/214001 [38:19<00:19, 89.14it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212288/214001 [38:19<00:19, 89.14it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212352/214001 [38:19<00:18, 88.72it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212352/214001 [38:20<00:18, 88.72it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212416/214001 [38:20<00:17, 89.63it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212416/214001 [38:21<00:17, 89.63it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212480/214001 [38:21<00:16, 90.40it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212480/214001 [38:21<00:16, 90.40it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212544/214001 [38:21<00:16, 90.96it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212544/214001 [38:22<00:16, 90.96it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212608/214001 [38:22<00:15, 90.33it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212608/214001 [38:23<00:15, 90.33it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212672/214001 [38:23<00:14, 89.77it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212672/214001 [38:23<00:14, 89.77it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212736/214001 [38:23<00:14, 89.79it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212736/214001 [38:24<00:14, 89.79it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212800/214001 [38:24<00:13, 89.11it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212800/214001 [38:25<00:13, 89.11it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212864/214001 [38:25<00:12, 88.56it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212864/214001 [38:26<00:12, 88.56it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212928/214001 [38:26<00:12, 88.24it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 212928/214001 [38:26<00:12, 88.24it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 212992/214001 [38:26<00:11, 88.58it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 212992/214001 [38:27<00:11, 88.58it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213056/214001 [38:27<00:10, 89.00it/s, train_loss=0.485]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213056/214001 [38:28<00:10, 89.00it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213120/214001 [38:28<00:09, 89.83it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213120/214001 [38:29<00:09, 89.83it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213184/214001 [38:29<00:09, 89.44it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213184/214001 [38:29<00:09, 89.44it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213248/214001 [38:29<00:08, 88.20it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213248/214001 [38:30<00:08, 88.20it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213312/214001 [38:30<00:07, 86.51it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213312/214001 [38:31<00:07, 86.51it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213376/214001 [38:31<00:07, 87.32it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213376/214001 [38:31<00:07, 87.32it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213440/214001 [38:31<00:06, 87.76it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213440/214001 [38:32<00:06, 87.76it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213504/214001 [38:32<00:05, 87.46it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213504/214001 [38:33<00:05, 87.46it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213568/214001 [38:33<00:05, 86.00it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213568/214001 [38:34<00:05, 86.00it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213632/214001 [38:34<00:04, 85.31it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213632/214001 [38:35<00:04, 85.31it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213696/214001 [38:35<00:03, 83.61it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213696/214001 [38:35<00:03, 83.61it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213760/214001 [38:35<00:02, 83.60it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213760/214001 [38:36<00:02, 83.60it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213824/214001 [38:36<00:02, 85.40it/s, train_loss=0.487]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213824/214001 [38:37<00:02, 85.40it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213888/214001 [38:37<00:01, 85.17it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213888/214001 [38:38<00:01, 85.17it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213952/214001 [38:38<00:00, 86.11it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 213952/214001 [38:38<00:00, 86.11it/s, train_loss=0.486]\u001b[A\n",
            "Epoch 1: 100%|██████████| 214001/214001 [38:38<00:00, 92.30it/s, train_loss=0.486]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.588, test - 0.483\n",
            "F1 test - 0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [37:15<00:00, 95.71it/s, train_loss=0.452]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.472, test - 0.466\n",
            "F1 test - 0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [37:28<00:00, 95.16it/s, train_loss=0.433]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.449, test - 0.459\n",
            "F1 test - 0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [37:22<00:00, 95.44it/s, train_loss=0.415]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.430, test - 0.456\n",
            "F1 test - 0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [35:07<00:00, 101.55it/s, train_loss=0.396]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.412, test - 0.466\n",
            "F1 test - 0.834\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты получились схожими с начальной тетрадкой\n",
        "\n",
        "Было:\n",
        "\n",
        "- F1 test - 0.827\n",
        "\n",
        "- F1 test - 0.830\n",
        "\n",
        "- F1 test - 0.836\n",
        "\n",
        "- F1 test - 0.836"
      ],
      "metadata": {
        "id": "Qhcv1_iTJ7VG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CN0gxTR2KWzp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}